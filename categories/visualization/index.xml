<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Visualization on Dash</title>
    <link>http://purplepalmdash.github.io/categories/visualization/</link>
    <description>Recent content in Visualization on Dash</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Dec 2015 16:29:43 +0000</lastBuildDate>
    
	<atom:link href="http://purplepalmdash.github.io/categories/visualization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>用Graphite呈现广州空气质量(4)</title>
      <link>http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-4/</link>
      <pubDate>Wed, 16 Dec 2015 16:29:43 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-4/</guid>
      <description>Tessera 直接导入Graphite中定义好的dashboard即可，值得注意的是，如何创建模板，或者说，如何创建一 个template用于渲染我们导入的各个数据？
导入的时候出现了如下的问题:
可见tessera中对数据的定制化是必须的。
Grafana 安装及配置为自动启动:
$ wget https://grafanarel.s3.amazonaws.com/builds/grafana_2.6.0_amd64.deb $ sudo dpkg -i grafana_2.6.0_amd64.deb $ sudo service grafana-server start $ sudo update-rc.d grafana-server defaults 95 10  默认用户名/密码为 admin/admin.
现在添加graphite数据源，例如：</description>
    </item>
    
    <item>
      <title>用Graphite呈现广州空气质量(3)</title>
      <link>http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-3/</link>
      <pubDate>Wed, 16 Dec 2015 14:18:25 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-3/</guid>
      <description>当前节点无数据 我们的脚本加入crontab运行后，最开始是可以得到数据的，后面两小时它挂了，查原因，有以下的 报错信息:
# /home/adminubuntu/GuangzhouPM25.py Traceback (most recent call last): File &amp;quot;/home/adminubuntu/GuangzhouPM25.py&amp;quot;, line 112, in &amp;lt;module&amp;gt; airdata = get_air_data(positionsets) File &amp;quot;/home/adminubuntu/GuangzhouPM25.py&amp;quot;, line 80, in get_air_data PM25 = int(pattern.match(soup.find(&#39;td&#39;,{&#39;id&#39;: &#39;pmtow&#39;}).contents[0]).group()) ValueError: invalid literal for int() with base 10: &#39;&#39;  此时selenium控制的浏览器停在以下图例:
可以看到，如果当前节点的数据为--， 则我们的python脚本运行会出现问题。因而我们在代码中 要加入少量修改。
错误处理 以下的代码更改添加了错误处理，如果该监测点的数值为空，则不提交任何数据:
@@ -66,9 +66,9 @@ def get_air_data(positionsets): hourdata = {} # Calling selenium, need linux X browser = Firefox() - # Added 10 seconds for waiting page for loading.</description>
    </item>
    
    <item>
      <title>用Graphite呈现广州空气质量(2)</title>
      <link>http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-2/</link>
      <pubDate>Wed, 16 Dec 2015 12:11:21 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-2/</guid>
      <description>更改后的脚本 以下脚本可以用于取回网页上的数据，并将其写入到Graphite远程服务器。
#!/usr/bin/env python #-*-coding:utf-8 -*- ################################################################################## # For fetching back the Air Quality Data and write it into Graphite on local server # Graphite Data Definition, this is the general definition among every city # air.city.citypoint.so2 # air.city.citypoint.no2 # air.city.citypoint.pm10 # air.city.citypoint.co # air.city.citypoint.o38h # air.city.citypoint.pm25 # air.city.citypoint.aqi # air.city.citypoint.firstp # air.city.citypoint.overp # When running this script in crontab, be sure to give it a display # Example, execute this script every hour at xx:05 # 5 */1 * * * export DISPLAY=:0;/home/adminubuntu/GuangzhouPM25.</description>
    </item>
    
    <item>
      <title>用Graphite呈现广州空气质量</title>
      <link>http://purplepalmdash.github.io/2015/12/15/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang/</link>
      <pubDate>Tue, 15 Dec 2015 10:05:39 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2015/12/15/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang/</guid>
      <description>数据源准备 数据源地址在:
http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html
但是这个地址取回数据比较困难。而在http://www.gzepb.gov.cn/ 右侧的栏里可以通过点击，打开某个监测点当前的空气质量指数,例如海珠湖的数据位于:
http://210.72.1.216:8080/gzaqi_new/DataList2.html?EPNAME=%E6%B5%B7%E7%8F%A0%E6%B9%96
Beautiful Soup Beautiful Soup可以被理解为网页爬虫，用于爬取某个页面并取回所需信息。在Ubuntu/Debian系统 中，安装命令如下。同时为了使用对XML解析速度更快的lxml解析器，我们安装python-lxml:
$ sudo apt-get install -y python-bs4 $ sudo apt-get install -y python-lxml  现在我们打开某个终端，开始用命令行交互的方式，取回海珠湖监测点的数据:
首先，引入所需的库：
# python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information. &amp;gt;&amp;gt;&amp;gt; from bs4 import BeautifulSoup &amp;gt;&amp;gt;&amp;gt; import urllib2 &amp;gt;&amp;gt;&amp;gt; response = urllib2.urlopen(&#39;http://210.72.1.216:8080/gzaqi_new/DataList2.html?EPNAME=%E6%B5%B7%E7%8F%A0%E6%B9%96&#39;) &amp;gt;&amp;gt;&amp;gt; print response.info() Content-Length: 10216 Content-Type: text/html Last-Modified: Wed, 13 May 2015 08:12:28 GMT Accept-Ranges: bytes ETag: &amp;quot;b680828d548dd01:da2&amp;quot; Server: Microsoft-IIS/6.</description>
    </item>
    
  </channel>
</rss>