<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.17-DEV" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Dash &middot; Dash</title>

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/poole.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde-a.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/custom-additions.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/highlight/googlecode.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124">
  <link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel="icon">

  
  
  
  <link href="http://purplepalmdash.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Dash &middot; Dash" />

  <meta name="description" content="Get busy living, or get busy dying.">
  <meta name="keywords" content="unix,virtualization,embedded,linux">
  <link rel="author" href="http://plus.google.com/106572959364703833986">
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-42175003-1', 'auto');
      ga('send', 'pageview');
  </script>

</head>
<body class="theme-base-0c">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <img src="https://www.gravatar.com/avatar/49381c0004d32c0a4296b92dff0c0ae5?s=200" alt="gravatar">
      <h1><a href="http://purplepalmdash.github.io/">Get busy living, or get busy dying.</a></h1>
      <a href="http://purplepalmdash.github.io/"><p>Dash</p></a>
    </div>

    <ul class="sidebar-nav">
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/">First Page</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/post/">All Posts</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/linux/">Linux</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/embedded/">Embedded System</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="https://github.com/purplepalmdash"><i class="fa fa-github-square fa-3x"></i></a>
      
      <a href="https://cn.linkedin.com/in/yang-feipeng-1b909319"><i class="fa fa-linkedin-square fa-3x"></i></a>
      <a href="https://plus.google.com/u/0/106572959364703833986"><i class="fa fa-google-plus-square fa-3x"></i></a>
      <a href="https://www.facebook.com/yang.feipeng"><i class="fa fa-facebook-square fa-3x"></i></a>
      <a href="https://twitter.com/dashwillfly"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="http://purplepalmdash.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/12/17/netscaler-vpxchu-shi-hua-pei-zhi/">NetScaler VPX初始化配置</a>
      </h1>
      <span class="post-date">Dec 17, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/12/17/netscaler-vpxchu-shi-hua-pei-zhi/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a>
        
      </span>
      
      

<h3 id="初始化配置">初始化配置</h3>

<p>启动虚拟机以后，通过nsroot/nsroot登录入VPX.</p>

<p>清除所有配置:</p>

<p><img src="/images/2015_12_17_14_20_54_580x93.jpg" alt="/images/2015_12_17_14_20_54_580x93.jpg" /></p>

<p>如下，做IP配置:</p>

<p><img src="/images/2015_12_17_14_23_29_728x153.jpg" alt="/images/2015_12_17_14_23_29_728x153.jpg" /></p>

<p>初始化配置完毕以后，即可在web后台进行配置。</p>

<h3 id="license">License</h3>

<p>申请license的时候注意，选择的MAC地址不能有任何的<code>:</code>符号， 例如52:54:00:这种就不能通过成
功。 在Netscaler上可以通过以下命令查看host id:</p>

<pre><code>root@ns# lmutil lmhostid 
lmutil - Copyright (c) 1989-2013 Flexera Software LLC. All Rights Reserved. 
The FlexNet host ID of this machine is &quot;xxxxxxx&quot;
</code></pre>

<p>查看激活后的license情形:</p>

<pre><code>&gt; sh license
        License status:
                           Web Logging: YES
                      Surge Protection: YES
                        Load Balancing: YES
                     Content Switching: YES
....
</code></pre>

<p>参考:<br />
<a href="http://sam.yeung.blog.163.com/blog/static/222663482013811102013782/">http://sam.yeung.blog.163.com/blog/static/222663482013811102013782/</a></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-4/">用Graphite呈现广州空气质量(4)</a>
      </h1>
      <span class="post-date">Dec 16, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-4/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/visualization">Visualization</a>
        
      </span>
      
      

<h3 id="tessera">Tessera</h3>

<p>直接导入Graphite中定义好的dashboard即可，值得注意的是，如何创建模板，或者说，如何创建一
个template用于渲染我们导入的各个数据？</p>

<p>导入的时候出现了如下的问题:</p>

<p><img src="/images/2015_12_16_18_34_44_701x483.jpg" alt="/images/2015_12_16_18_34_44_701x483.jpg" /></p>

<p>可见tessera中对数据的定制化是必须的。</p>

<h3 id="grafana">Grafana</h3>

<p>安装及配置为自动启动:</p>

<pre><code>$ wget https://grafanarel.s3.amazonaws.com/builds/grafana_2.6.0_amd64.deb
$ sudo dpkg -i grafana_2.6.0_amd64.deb
$ sudo service grafana-server start
$ sudo update-rc.d grafana-server defaults 95 10
</code></pre>

<p>默认用户名/密码为 admin/admin.</p>

<p>现在添加graphite数据源，例如：</p>

<p><img src="/images/2015_12_16_19_20_33_703x484.jpg" alt="/images/2015_12_16_19_20_33_703x484.jpg" /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-3/">用Graphite呈现广州空气质量(3)</a>
      </h1>
      <span class="post-date">Dec 16, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-3/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/visualization">visualization</a>
        
      </span>
      
      

<h3 id="当前节点无数据">当前节点无数据</h3>

<p>我们的脚本加入crontab运行后，最开始是可以得到数据的，后面两小时它挂了，查原因，有以下的
报错信息:</p>

<pre><code># /home/adminubuntu/GuangzhouPM25.py 
Traceback (most recent call last):
  File &quot;/home/adminubuntu/GuangzhouPM25.py&quot;, line 112, in &lt;module&gt;
    airdata = get_air_data(positionsets)
  File &quot;/home/adminubuntu/GuangzhouPM25.py&quot;, line 80, in get_air_data
    PM25 = int(pattern.match(soup.find('td',{'id': 'pmtow'}).contents[0]).group())
ValueError: invalid literal for int() with base 10: ''
</code></pre>

<p>此时selenium控制的浏览器停在以下图例:</p>

<p><img src="/images/2015_12_16_14_21_03_497x301.jpg" alt="/images/2015_12_16_14_21_03_497x301.jpg" /></p>

<p>可以看到，如果当前节点的数据为<code>--</code>， 则我们的python脚本运行会出现问题。因而我们在代码中
要加入少量修改。</p>

<h3 id="错误处理">错误处理</h3>

<p>以下的代码更改添加了错误处理，如果该监测点的数值为空，则不提交任何数据:</p>

<pre><code>@@ -66,9 +66,9 @@ def get_air_data(positionsets):
   hourdata = {}
   # Calling selenium, need linux X
   browser = Firefox()
-  # Added 10 seconds for waiting page for loading.
-  time.delay(10)
   browser.get(URL)
+  # Added 10 seconds for waiting page for loading.
+  time.sleep(10)
   # Click button one-by-one
   for position in positionsets:
     # After clicking, should re-get the page_source.
@@ -78,33 +78,37 @@ def get_air_data(positionsets):
     soup = BeautifulSoup(page_source, 'html.parser')
     # pm2.5 value would be something like xx 微克/立方米, so we need an regex for
     # matching, example: print int(pattern.match(input).group())
-    PM25 = int(pattern.match(soup.find('td',{'id': 'pmtow'}).contents[0]).group())
-    PM25_iaqi = int(pattern.match(soup.find('td',{'id': 'pmtow_iaqi'}).contents[0]).group())
-    PM10 = int(pattern.match(soup.find('td',{'id': 'pmten'}).contents[0]).group())
-    PM10_iaqi = int(pattern.match(soup.find('td',{'id': 'pmten_iaqi'}).contents[0]).group())
-    SO2 = int(pattern.match(soup.find('td',{'id': 'sotwo'}).contents[0]).group())
-    SO2_iaqi = int(pattern.match(soup.find('td',{'id': 'sotwo_iaqi'}).contents[0]).group())
-    NO2 = int(pattern.match(soup.find('td',{'id': 'notwo'}).contents[0]).group())
-    NO2_iaqi = int(pattern.match(soup.find('td',{'id': 'notwo_iaqi'}).contents[0]).group())
-    # Special notice the CO would be float value
-    CO = float(floatpattern.match(soup.find('td',{'id': 'co'}).contents[0]).group())
-    CO_iaqi = int(pattern.match(soup.find('td',{'id': 'co_iaqi'}).contents[0]).group())
-    O3 = int(pattern.match(soup.find('td',{'id': 'othree'}).contents[0]).group())
-    O3_iaqi = int(pattern.match(soup.find('td',{'id': 'othree_iaqi'}).contents[0]).group())
-    hourdata_key = pinyin.get(position)
-    hourdata[hourdata_key] = []
-    hourdata[hourdata_key].append(PM25)
-    hourdata[hourdata_key].append(PM25_iaqi)
-    hourdata[hourdata_key].append(PM10)
-    hourdata[hourdata_key].append(PM10_iaqi)
-    hourdata[hourdata_key].append(SO2)
-    hourdata[hourdata_key].append(SO2_iaqi)
-    hourdata[hourdata_key].append(NO2)
-    hourdata[hourdata_key].append(NO2_iaqi)
-    hourdata[hourdata_key].append(CO)
-    hourdata[hourdata_key].append(CO_iaqi)
-    hourdata[hourdata_key].append(O3)
-    hourdata[hourdata_key].append(O3_iaqi)
+    try:
+      PM25 = int(pattern.match(soup.find('td',{'id': 'pmtow'}).contents[0]).group())
+      PM25_iaqi = int(pattern.match(soup.find('td',{'id': 'pmtow_iaqi'}).contents[0]).group())
+      PM10 = int(pattern.match(soup.find('td',{'id': 'pmten'}).contents[0]).group())
+      PM10_iaqi = int(pattern.match(soup.find('td',{'id': 'pmten_iaqi'}).contents[0]).group())
+      SO2 = int(pattern.match(soup.find('td',{'id': 'sotwo'}).contents[0]).group())
+      SO2_iaqi = int(pattern.match(soup.find('td',{'id': 'sotwo_iaqi'}).contents[0]).group())
+      NO2 = int(pattern.match(soup.find('td',{'id': 'notwo'}).contents[0]).group())
+      NO2_iaqi = int(pattern.match(soup.find('td',{'id': 'notwo_iaqi'}).contents[0]).group())
+      # Special notice the CO would be float value
+      CO = float(floatpattern.match(soup.find('td',{'id': 'co'}).contents[0]).group())
+      CO_iaqi = int(pattern.match(soup.find('td',{'id': 'co_iaqi'}).contents[0]).group())
+      O3 = int(pattern.match(soup.find('td',{'id': 'othree'}).contents[0]).group())
+      O3_iaqi = int(pattern.match(soup.find('td',{'id': 'othree_iaqi'}).contents[0]).group())
+      hourdata_key = pinyin.get(position)
+      hourdata[hourdata_key] = []
+      hourdata[hourdata_key].append(PM25)
+      hourdata[hourdata_key].append(PM25_iaqi)
+      hourdata[hourdata_key].append(PM10)
+      hourdata[hourdata_key].append(PM10_iaqi)
+      hourdata[hourdata_key].append(SO2)
+      hourdata[hourdata_key].append(SO2_iaqi)
+      hourdata[hourdata_key].append(NO2)
+      hourdata[hourdata_key].append(NO2_iaqi)
+      hourdata[hourdata_key].append(CO)
+      hourdata[hourdata_key].append(CO_iaqi)
+      hourdata[hourdata_key].append(O3)
+      hourdata[hourdata_key].append(O3_iaqi)
+    except ValueError, Argument:
+      # won't add the data, simply ignore this position
+      print &quot;The argument does not contain numbers\n&quot;, Argument
   # After clicking all of the button, quit the firefox and return the dictionary
   browser.close()
   return hourdata
</code></pre>

<p>到现在为止，数据可以顺利的写入到Graphite中。</p>

<h3 id="graphite-dashboard">Graphite Dashboard</h3>

<p>组建Graphite Dashboard可以通过图形界面来进行，举例如下:</p>

<p><img src="/images/2015_12_16_15_22_04_579x386.jpg" alt="/images/2015_12_16_15_22_04_579x386.jpg" /></p>

<p>具体的添加过程就不说了，值得注意的是，设置几个属性，时间范围为过去24小时，
双击某图片后，<code>Render Options</code>里的<code>Line Mode</code>选择<code>Connected Line</code>，
这样可以构建出连接线，比较适合我们所需要展示的数据类型。Y-Axis，即Y轴的起点(Minimal)设置为0.</p>

<p>点击DashBoard-&gt; Edit Dashboard, 可以看到以下定义:</p>

<p><img src="/images/2015_12_16_15_25_54_789x499.jpg" alt="/images/2015_12_16_15_25_54_789x499.jpg" /></p>

<p>这个定义文件可以修改，我们将使用这个定义文件来批量制作其他十多个监测点的Dashboard.</p>

<h3 id="创建更多的dashboard">创建更多的Dashboard</h3>

<p>参考:<br />
<a href="http://graphite.readthedocs.org/en/latest/dashboard.html#editing-importing-and-exporting-via-json">http://graphite.readthedocs.org/en/latest/dashboard.html#editing-importing-and-exporting-via-json</a></p>

<p>将上述的dashboard定义文件存储在某个文本文件中，
用下列命令批量生成新的dashboard定义文件:</p>

<pre><code>$ cat dashboard.txt | sed 's/haizhuhu/aotizhongxin/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/aotizhongxin/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/baiyunshan/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/dafushan/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/gongyuanqian/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/haizhubaogang/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/haizhuchisha/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/haizhuhu/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/haizhushayuan/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/huangpudashadi/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/huangpuwenchong/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/huangshalubianzhan/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/liwanfangcun/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/liwanxicun/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/luhu/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/luogangxiqu/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/tianhelongdong/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/tiyuxi/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/yayuncheng/g'|myclip
$ cat dashboard.txt | sed 's/haizhuhu/yangjilubianzhan/g'|myclip
</code></pre>

<p><code>myclip</code>是一个自定义的命令，可以将管道输出直接到系统剪贴板，
而后将内容新添加到dashboard定义文件中，点击update后，另存为新的dashboard即可.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-2/">用Graphite呈现广州空气质量(2)</a>
      </h1>
      <span class="post-date">Dec 16, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/12/16/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang-2/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/visualization">Visualization</a>
        
      </span>
      
      

<h3 id="更改后的脚本">更改后的脚本</h3>

<p>以下脚本可以用于取回网页上的数据，并将其写入到Graphite远程服务器。</p>

<pre><code>#!/usr/bin/env python
#-*-coding:utf-8 -*-

##################################################################################
# For fetching back the Air Quality Data and write it into Graphite on local server
# Graphite Data Definition, this is the general definition among every city
# air.city.citypoint.so2
# air.city.citypoint.no2
# air.city.citypoint.pm10
# air.city.citypoint.co
# air.city.citypoint.o38h
# air.city.citypoint.pm25
# air.city.citypoint.aqi
# air.city.citypoint.firstp
# air.city.citypoint.overp
# When running this script in crontab, be sure to give it a display
# Example, execute this script every hour at xx:05
# 5 */1 * * * export DISPLAY=:0;/home/adminubuntu/GuangzhouPM25.py
##################################################################################

# BeautifulSoup
from bs4 import BeautifulSoup

# Selenium
from contextlib import closing
from selenium.webdriver import Firefox
from selenium.webdriver.support.ui import WebDriverWait

# For writing into Graphite
import platform
import socket
import time

# Regex
import re

# pinyin
import pinyin

# Parameters comes here 
CARBON_SERVER = '0.0.0.0'
CARBON_PORT = 2003
DELAY = 5  # secs
URL = 'http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html'
CITY = 'guangzhou'

# All Points In Guangzhou City
positionsets = [&quot;天河龙洞&quot;, &quot;白云山&quot;, &quot;麓湖&quot;, &quot;公园前&quot;, &quot;荔湾西村&quot;, &quot;黄沙路边站&quot;, &quot;杨箕
路边站&quot;, &quot;荔湾芳村&quot;, &quot;海珠宝岗&quot;, &quot;海珠沙园&quot;, &quot;海珠湖&quot;, &quot;大夫山&quot;, &quot;奥体中心&quot;, &quot;萝岗西区
&quot;, &quot;黄埔文冲&quot;, &quot;黄埔大沙地&quot;, &quot;亚运城&quot;, &quot;体育西&quot;, &quot;海珠赤沙&quot;]

# regex for matching the digits.
pattern = re.compile(r'\d*')
floatpattern=re.compile(r'[\d|\.]*')

# Sending message to graphite server. 
def send_msg(message):
  print 'sending message:\n%s' % message
  sock = socket.socket()
  sock.connect((CARBON_SERVER, CARBON_PORT))
  sock.sendall(message)
  sock.close()

# Fetching data, runs each hour. In one-time access should fetch all of the data. 
def get_air_data(positionsets):
  # Dictionary hourdata is for holding data, DataStructure like: 
  # {'baiyunshan': [44, 5], 'haizhubaogang': [55, 6]}
  hourdata = {}
  # Calling selenium, need linux X
  browser = Firefox()
  browser.get(URL)
  # Click button one-by-one
  for position in positionsets:
    # After clicking, should re-get the page_source.
    browser.find_element_by_id(position).click()
    page_source = browser.page_source
    # Cooking Soup
    soup = BeautifulSoup(page_source, 'html.parser')
    # pm2.5 value would be something like xx 微克/立方米, so we need an regex for
    # matching, example: print int(pattern.match(input).group())
    PM25 = int(pattern.match(soup.find('td',{'id': 'pmtow'}).contents[0]).group())
    PM25_iaqi = int(pattern.match(soup.find('td',{'id':
'pmtow_iaqi'}).contents[0]).group())
    PM10 = int(pattern.match(soup.find('td',{'id': 'pmten'}).contents[0]).group())
    PM10_iaqi = int(pattern.match(soup.find('td',{'id':
'pmten_iaqi'}).contents[0]).group())
    SO2 = int(pattern.match(soup.find('td',{'id': 'sotwo'}).contents[0]).group())
    SO2_iaqi = int(pattern.match(soup.find('td',{'id':
'sotwo_iaqi'}).contents[0]).group())
    NO2 = int(pattern.match(soup.find('td',{'id': 'notwo'}).contents[0]).group())
    NO2_iaqi = int(pattern.match(soup.find('td',{'id':
'notwo_iaqi'}).contents[0]).group())
    # Special notice the CO would be float value
    CO = float(floatpattern.match(soup.find('td',{'id': 'co'}).contents[0]).group())
    CO_iaqi = int(pattern.match(soup.find('td',{'id': 'co_iaqi'}).contents[0]).group())
    O3 = int(pattern.match(soup.find('td',{'id': 'othree'}).contents[0]).group())
    O3_iaqi = int(pattern.match(soup.find('td',{'id':
'othree_iaqi'}).contents[0]).group())
    hourdata_key = pinyin.get(position)
    hourdata[hourdata_key] = []
    hourdata[hourdata_key].append(PM25)
    hourdata[hourdata_key].append(PM25_iaqi)
    hourdata[hourdata_key].append(PM10)
    hourdata[hourdata_key].append(PM10_iaqi)
    hourdata[hourdata_key].append(SO2)
    hourdata[hourdata_key].append(SO2_iaqi)
    hourdata[hourdata_key].append(NO2)
    hourdata[hourdata_key].append(NO2_iaqi)
    hourdata[hourdata_key].append(CO)
    hourdata[hourdata_key].append(CO_iaqi)
    hourdata[hourdata_key].append(O3)
    hourdata[hourdata_key].append(O3_iaqi)
  # After clicking all of the button, quit the firefox and return the dictionary
  browser.close()
  return hourdata

if __name__ == '__main__':
  airdata = get_air_data(positionsets)
  timestamp = int(time.time())
  for i in airdata.keys():
    # each key should contains the corresponding hourdata
    lines = [
      'air.guangzhou.%s.pm25 %s %d' % (i, airdata[i][0], timestamp),
      'air.guangzhou.%s.pm25_iaqi %s %d' % (i, airdata[i][1], timestamp),
      'air.guangzhou.%s.pm10 %s %d' % (i, airdata[i][2], timestamp),
      'air.guangzhou.%s.pm10_iaqi %s %d' % (i, airdata[i][3], timestamp),
      'air.guangzhou.%s.so2 %s %d' % (i, airdata[i][4], timestamp),
      'air.guangzhou.%s.so2_iaqi %s %d' % (i, airdata[i][5], timestamp),
      'air.guangzhou.%s.no2 %s %d' % (i, airdata[i][6], timestamp),
      'air.guangzhou.%s.no2_iaqi %s %d' % (i, airdata[i][7], timestamp),
      'air.guangzhou.%s.co %s %d' % (i, airdata[i][8], timestamp),
      'air.guangzhou.%s.co_iaqi %s %d' % (i, airdata[i][9], timestamp),
      'air.guangzhou.%s.o3 %s %d' % (i, airdata[i][10], timestamp),
      'air.guangzhou.%s.o3_iaqi %s %d' % (i, airdata[i][11], timestamp)
    ]
    message = '\n'.join(lines) + '\n'
    send_msg(message)
    # delay for graphite server will use a DELAY time for inserting data
    time.sleep(DELAY)
</code></pre>

<h3 id="使用方法">使用方法</h3>

<p>将上面的文件保存为可执行文件，然后使用crontab添加一个定时任务，譬如以下的crontab条目会
在每个小时的xx:05分时自动运行该脚本文件，将取回的数据写入到Graphite远端。</p>

<pre><code>$ crontab -l
# hourly execute pm25 updating task, xx:05 will be the execute time
5 */1 * * * export DISPLAY=:0;/home/adminubuntu/GuangzhouPM25.py
</code></pre>

<p>写入graphite后的效果如下:<br />
<img src="/images/2015_12_16_12_20_04_284x453.jpg" alt="/images/2015_12_16_12_20_04_284x453.jpg" /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/12/15/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang/">用Graphite呈现广州空气质量</a>
      </h1>
      <span class="post-date">Dec 15, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/12/15/yong-graphitecheng-xian-yan-zhou-kong-qi-zhi-liang/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/visualization">visualization</a>
        
      </span>
      
      

<h3 id="数据源准备">数据源准备</h3>

<p>数据源地址在:<br />
<a href="http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html">http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html</a></p>

<p>但是这个地址取回数据比较困难。而在<a href="http://www.gzepb.gov.cn/">http://www.gzepb.gov.cn/</a>
右侧的栏里可以通过点击，打开某个监测点当前的空气质量指数,例如海珠湖的数据位于:</p>

<p><a href="http://210.72.1.216:8080/gzaqi_new/DataList2.html?EPNAME=%E6%B5%B7%E7%8F%A0%E6%B9%96">http://210.72.1.216:8080/gzaqi_new/DataList2.html?EPNAME=%E6%B5%B7%E7%8F%A0%E6%B9%96</a></p>

<h3 id="beautiful-soup">Beautiful Soup</h3>

<p>Beautiful Soup可以被理解为网页爬虫，用于爬取某个页面并取回所需信息。在Ubuntu/Debian系统
中，安装命令如下。同时为了使用对XML解析速度更快的lxml解析器，我们安装python-lxml:</p>

<pre><code>$ sudo apt-get install -y python-bs4
$ sudo apt-get install -y python-lxml 
</code></pre>

<p>现在我们打开某个终端，开始用命令行交互的方式，取回海珠湖监测点的数据:</p>

<p>首先，引入所需的库：</p>

<pre><code># python
Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; from bs4 import BeautifulSoup
&gt;&gt;&gt; import urllib2
&gt;&gt;&gt; response = urllib2.urlopen('http://210.72.1.216:8080/gzaqi_new/DataList2.html?EPNAME=%E6%B5%B7%E7%8F%A0%E6%B9%96')
&gt;&gt;&gt; print response.info()
Content-Length: 10216
Content-Type: text/html
Last-Modified: Wed, 13 May 2015 08:12:28 GMT
Accept-Ranges: bytes
ETag: &quot;b680828d548dd01:da2&quot;
Server: Microsoft-IIS/6.0
X-Powered-By: ASP.NET
Date: Tue, 15 Dec 2015 02:25:17 GMT
Connection: close

&gt;&gt;&gt; html = response.read()
&gt;&gt;&gt; print &quot;Get the length :&quot;, len(html)
Get the length : 10216
&gt;&gt;&gt; response.close()  # best practice to close the file
</code></pre>

<p>上述的操作里调用urllib2取回了页面， html变量里包含了该网页的内容。接下来我们使用
BeautifulSoup来美化并从中取回我们想要的元素。</p>

<pre><code>&gt;&gt;&gt; soup = BeautifulSoup(html, 'html.parser')    
&gt;&gt;&gt; print soup.prettify()
</code></pre>

<p>仔细检查后发现，用urllib2取回的网页中，html变量里未包含当前的数据值。通过阅读代码得知，
当前页面的值是浏览器在载入网页时执行javascript函数得到的。因而我们使用一个真实的浏览器
来实现页面的抓取。</p>

<p>Selenium是一套用于进行浏览器自动化测试的开源工具集，可进行Web应用的端到端测试
。Selenium主要包括两个工具：一是Selenium IDE，二是Selenium WebDriver（简称
WebDriver）. 安装命令如下:</p>

<pre><code>$ pip install selenium
</code></pre>

<p>使用selenium抓取该网页的代码如下:</p>

<pre><code>&gt;&gt;&gt; from contextlib import closing
&gt;&gt;&gt; from selenium.webdriver import Firefox
&gt;&gt;&gt; from selenium.webdriver.support.ui import WebDriverWait
&gt;&gt;&gt; url='http://210.72.1.216:8080/gzaqi_new/DataList2.html?EPNAME=%E6%B5%B7%E7%8F%A0%E6%B9%96'
&gt;&gt;&gt; with closing(Firefox()) as browser:
...   browser.get(url)
...   page_source = browser.page_source
... 
&gt;&gt;&gt; print page_source
&gt;&gt;&gt; soup = BeautifulSoup(page_source, 'html.parser')
&gt;&gt;&gt; print soup
</code></pre>

<p>现在我们可以看到，取回的<code>page_source</code>变量中已经包含有该时段的数据。接下来就是如何把数据
从其中提取出来的过程。</p>

<p>定位到含有数据的表格, 根据其层叠结构，获得tr的值:</p>

<pre><code>&gt;&gt;&gt; table = soup.find('table', {'class': 'headTable'})
&gt;&gt;&gt; for td in table.tbody.tr:
...     print td
... 
&lt;td class=&quot;SO2_24H&quot;&gt;7&lt;/td&gt;
&lt;td class=&quot;NO2_24H&quot;&gt;50&lt;/td&gt;
&lt;td class=&quot;PM10_24H&quot;&gt;29&lt;/td&gt;
&lt;td class=&quot;CO_24H&quot;&gt;31&lt;/td&gt;
&lt;td class=&quot;O3_8H_24H&quot;&gt;18&lt;/td&gt;
&lt;td class=&quot;PM25_24H&quot;&gt;25&lt;/td&gt;
&lt;td class=&quot;AQI&quot;&gt;50&lt;/td&gt;
&lt;td class=&quot;Pollutants&quot;&gt;—&lt;/td&gt;
&lt;td class=&quot;jibie2&quot;&gt;--&lt;/td&gt;
&lt;td class=&quot;jibie2&quot;&gt;一级&lt;/td&gt;
&lt;td class=&quot;leibie&quot;&gt;优                  &lt;/td&gt;
&lt;td class=&quot;yanse&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;Images/you.jpg&quot;/&gt;&lt;/td&gt;
</code></pre>

<p>更进一步得到值:</p>

<pre><code>&gt;&gt;&gt; for td in table.tbody.tr:
...     print td.contents[0]
... 
7
50
29
31
18
25
50
—
--
一级
优                  
&lt;img alt=&quot;&quot; src=&quot;Images/you.jpg&quot;/&gt;
</code></pre>

<p>对应的图片如下:</p>

<p><img src="/images/2015_12_15_12_06_23_943x201.jpg" alt="/images/2015_12_15_12_06_23_943x201.jpg" /></p>

<p>提取出来了数据，就可以做后续处理了。</p>

<h3 id="graphite">Graphite</h3>

<p>Graphite的搭建过程不提及。基于我们前面提取出的数据，只需要将其写入Graphite，就可以看
到数据的显示了。</p>

<p>具体的写入代码参考(需翻墙):</p>

<p><a href="http://coreygoldberg.blogspot.com/2012/04/python-getting-data-into-graphite-code.html">http://coreygoldberg.blogspot.com/2012/04/python-getting-data-into-graphite-code.html</a></p>

<p>按照博客中提供的例子，写入到Graphite后的数据在Graphite看起来是这样的:</p>

<p><img src="/images/2015_12_15_14_48_48_318x115.jpg" alt="/images/2015_12_15_14_48_48_318x115.jpg" /></p>

<p>而对应的数据格式则如下:</p>

<pre><code> sending message:
     system.monitorserver.loadavg_1min 0.18 1450161396
     system.monitorserver.loadavg_5min 0.25 1450161396
     system.monitorserver.loadavg_15min 0.23 1450161396
</code></pre>

<p>我们可以仿照这样的数据来组织自己的空气质量数据。</p>

<h3 id="数据来源再加工">数据来源再加工</h3>

<p>前面取回地址失败， 因为它只是返回空气日报的地址，我们需要的是实时情况，所以还是回到<br />
<a href="http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html">http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html</a></p>

<p>这里需要在selenium里模拟出鼠标快速点击所有链接的效果。</p>

<p>下面是一次完整的点击白云山按钮并获得PM2.5页面的过程:</p>

<pre><code>root@monitorserver:~/Code# python
Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; from contextlib import closing
&gt;&gt;&gt; from selenium.webdriver import Firefox
&gt;&gt;&gt; from selenium.webdriver.support.ui import WebDriverWait
&gt;&gt;&gt; driver = Firefox()                                                 
&gt;&gt;&gt; driver.get('http://210.72.1.216:8080/gzaqi_new/RealTimeDate.html')
&gt;&gt;&gt; driver.refresh()
&gt;&gt;&gt; baiyunmountain=driver.find_element_by_id(&quot;白云山&quot;)
&gt;&gt;&gt; baiyunmountain.click()
&gt;&gt;&gt; PM25=driver.find_element_by_id(&quot;PM25&quot;)
&gt;&gt;&gt; type(PM25)
&lt;class 'selenium.webdriver.remote.webelement.WebElement'&gt;
&gt;&gt;&gt; PM25.click()
</code></pre>

      
    </div>
    
    
    
    <ul class="pagination">
        
        <li>
            <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
        </li>
        
        <li
        >
        <a href="/page/16/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
        </li>
        
        <li
        ><a href="/">1</a></li>
        
        <li
        ><a href="/page/2/">2</a></li>
        
        <li
        ><a href="/page/3/">3</a></li>
        
        <li
        ><a href="/page/4/">4</a></li>
        
        <li
        ><a href="/page/5/">5</a></li>
        
        <li
        ><a href="/page/6/">6</a></li>
        
        <li
        ><a href="/page/7/">7</a></li>
        
        <li
        ><a href="/page/8/">8</a></li>
        
        <li
        ><a href="/page/9/">9</a></li>
        
        <li
        ><a href="/page/10/">10</a></li>
        
        <li
        ><a href="/page/11/">11</a></li>
        
        <li
        ><a href="/page/12/">12</a></li>
        
        <li
        ><a href="/page/13/">13</a></li>
        
        <li
        ><a href="/page/14/">14</a></li>
        
        <li
        ><a href="/page/15/">15</a></li>
        
        <li
        ><a href="/page/16/">16</a></li>
        
        <li
        class="active"><a href="/page/17/">17</a></li>
        
        <li
        ><a href="/page/18/">18</a></li>
        
        <li
        ><a href="/page/19/">19</a></li>
        
        <li
        ><a href="/page/20/">20</a></li>
        
        <li
        ><a href="/page/21/">21</a></li>
        
        <li
        ><a href="/page/22/">22</a></li>
        
        <li
        ><a href="/page/23/">23</a></li>
        
        <li
        ><a href="/page/24/">24</a></li>
        
        <li
        ><a href="/page/25/">25</a></li>
        
        <li
        ><a href="/page/26/">26</a></li>
        
        <li
        ><a href="/page/27/">27</a></li>
        
        <li
        ><a href="/page/28/">28</a></li>
        
        <li
        ><a href="/page/29/">29</a></li>
        
        <li
        ><a href="/page/30/">30</a></li>
        
        <li
        ><a href="/page/31/">31</a></li>
        
        <li
        ><a href="/page/32/">32</a></li>
        
        <li
        ><a href="/page/33/">33</a></li>
        
        <li
        ><a href="/page/34/">34</a></li>
        
        <li
        ><a href="/page/35/">35</a></li>
        
        <li
        ><a href="/page/36/">36</a></li>
        
        <li
        ><a href="/page/37/">37</a></li>
        
        <li
        ><a href="/page/38/">38</a></li>
        
        <li
        ><a href="/page/39/">39</a></li>
        
        <li
        ><a href="/page/40/">40</a></li>
        
        <li
        ><a href="/page/41/">41</a></li>
        
        <li
        ><a href="/page/42/">42</a></li>
        
        <li
        ><a href="/page/43/">43</a></li>
        
        <li
        ><a href="/page/44/">44</a></li>
        
        <li
        ><a href="/page/45/">45</a></li>
        
        <li
        ><a href="/page/46/">46</a></li>
        
        <li
        ><a href="/page/47/">47</a></li>
        
        <li
        ><a href="/page/48/">48</a></li>
        
        <li
        ><a href="/page/49/">49</a></li>
        
        <li
        ><a href="/page/50/">50</a></li>
        
        <li
        ><a href="/page/51/">51</a></li>
        
        <li
        ><a href="/page/52/">52</a></li>
        
        <li
        ><a href="/page/53/">53</a></li>
        
        <li
        ><a href="/page/54/">54</a></li>
        
        <li
        ><a href="/page/55/">55</a></li>
        
        <li
        ><a href="/page/56/">56</a></li>
        
        <li
        ><a href="/page/57/">57</a></li>
        
        <li
        ><a href="/page/58/">58</a></li>
        
        <li
        ><a href="/page/59/">59</a></li>
        
        <li
        ><a href="/page/60/">60</a></li>
        
        <li
        ><a href="/page/61/">61</a></li>
        
        <li
        ><a href="/page/62/">62</a></li>
        
        <li
        ><a href="/page/63/">63</a></li>
        
        <li
        ><a href="/page/64/">64</a></li>
        
        <li
        ><a href="/page/65/">65</a></li>
        
        <li
        ><a href="/page/66/">66</a></li>
        
        <li
        ><a href="/page/67/">67</a></li>
        
        <li
        ><a href="/page/68/">68</a></li>
        
        <li
        ><a href="/page/69/">69</a></li>
        
        <li
        ><a href="/page/70/">70</a></li>
        
        <li
        ><a href="/page/71/">71</a></li>
        
        <li
        ><a href="/page/72/">72</a></li>
        
        <li
        ><a href="/page/73/">73</a></li>
        
        <li
        ><a href="/page/74/">74</a></li>
        
        <li
        ><a href="/page/75/">75</a></li>
        
        <li
        ><a href="/page/76/">76</a></li>
        
        <li
        ><a href="/page/77/">77</a></li>
        
        <li
        ><a href="/page/78/">78</a></li>
        
        <li
        ><a href="/page/79/">79</a></li>
        
        <li
        ><a href="/page/80/">80</a></li>
        
        <li
        ><a href="/page/81/">81</a></li>
        
        <li
        ><a href="/page/82/">82</a></li>
        
        <li
        ><a href="/page/83/">83</a></li>
        
        <li
        ><a href="/page/84/">84</a></li>
        
        <li
        ><a href="/page/85/">85</a></li>
        
        <li
        ><a href="/page/86/">86</a></li>
        
        <li
        ><a href="/page/87/">87</a></li>
        
        <li
        ><a href="/page/88/">88</a></li>
        
        <li
        ><a href="/page/89/">89</a></li>
        
        <li
        ><a href="/page/90/">90</a></li>
        
        <li
        ><a href="/page/91/">91</a></li>
        
        <li
        ><a href="/page/92/">92</a></li>
        
        <li
        ><a href="/page/93/">93</a></li>
        
        <li
        ><a href="/page/94/">94</a></li>
        
        <li
        ><a href="/page/95/">95</a></li>
        
        <li
        ><a href="/page/96/">96</a></li>
        
        <li
        ><a href="/page/97/">97</a></li>
        
        <li
        ><a href="/page/98/">98</a></li>
        
        <li
        ><a href="/page/99/">99</a></li>
        
        <li
        ><a href="/page/100/">100</a></li>
        
        <li
        ><a href="/page/101/">101</a></li>
        
        <li
        ><a href="/page/102/">102</a></li>
        
        <li
        ><a href="/page/103/">103</a></li>
        
        <li
        ><a href="/page/104/">104</a></li>
        
        <li
        ><a href="/page/105/">105</a></li>
        
        <li
        ><a href="/page/106/">106</a></li>
        
        <li
        ><a href="/page/107/">107</a></li>
        
        <li
        ><a href="/page/108/">108</a></li>
        
        <li
        ><a href="/page/109/">109</a></li>
        
        <li
        ><a href="/page/110/">110</a></li>
        
        <li
        ><a href="/page/111/">111</a></li>
        
        <li
        ><a href="/page/112/">112</a></li>
        
        <li
        ><a href="/page/113/">113</a></li>
        
        <li
        ><a href="/page/114/">114</a></li>
        
        <li
        ><a href="/page/115/">115</a></li>
        
        <li
        ><a href="/page/116/">116</a></li>
        
        <li
        ><a href="/page/117/">117</a></li>
        
        <li
        ><a href="/page/118/">118</a></li>
        
        <li
        ><a href="/page/119/">119</a></li>
        
        <li
        ><a href="/page/120/">120</a></li>
        
        <li
        ><a href="/page/121/">121</a></li>
        
        <li
        ><a href="/page/122/">122</a></li>
        
        <li
        ><a href="/page/123/">123</a></li>
        
        <li
        ><a href="/page/124/">124</a></li>
        
        <li
        ><a href="/page/125/">125</a></li>
        
        <li
        ><a href="/page/126/">126</a></li>
        
        <li
        ><a href="/page/127/">127</a></li>
        
        <li
        ><a href="/page/128/">128</a></li>
        
        <li
        ><a href="/page/129/">129</a></li>
        
        <li
        ><a href="/page/130/">130</a></li>
        
        <li
        ><a href="/page/131/">131</a></li>
        
        <li
        ><a href="/page/132/">132</a></li>
        
        <li
        ><a href="/page/133/">133</a></li>
        
        <li
        >
        <a href="/page/18/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
        </li>
        
        <li>
            <a href="/page/133/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
        </li>
        
    </ul>
    
  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "dashsagittariussglory";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<script src="http://purplepalmdash.github.io/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>

