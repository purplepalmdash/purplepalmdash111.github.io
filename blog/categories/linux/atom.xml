<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | Dash]]></title>
  <link href="http://purplepalmdash.github.io/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://purplepalmdash.github.io/"/>
  <updated>2015-08-21T15:11:45+08:00</updated>
  <id>http://purplepalmdash.github.io/</id>
  <author>
    <name><![CDATA[Dash]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mrepo Tips for Syncing CentOS Repositories]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/08/21/mrepo-tips-for-syncing-centos-repositories/"/>
    <updated>2015-08-21T14:48:30+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/08/21/mrepo-tips-for-syncing-centos-repositories</id>
    <content type="html"><![CDATA[<p><img src="/images/2015_08_21_14_50_38_722x742.jpg" alt="/images/2015_08_21_14_50_38_722x742.jpg" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup Squid]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/08/21/setup-squid/"/>
    <updated>2015-08-21T11:33:13+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/08/21/setup-squid</id>
    <content type="html"><![CDATA[<h3>Installation And Configuration</h3>

<pre><code># yum install -y squid
# vim /etc/squid/squid.conf
http_port 3072
#acl localnet src 192.168.0.0/16        # RFC1918 possible internal network
# Squid normally listens to port 3128
http_port 3072
cache_mem 64 MB
maximum_object_size 4 MB
# Cache 3GB
cache_dir ufs /home/juju/SquidCache     3072    16      256
access_log /var/log/squid/access.log
auth_param basic program /usr/lib64/squid/basic_ncsa_auth /etc/squid/passwd
auth_param basic children 5
auth_param basic kspc-01 proxy
auth_param basic credentialsttl 2 hours
acl myacl proxy_auth REQUIRED
http_access allow myacl
http_access deny all
visible_hostname squid.kspc-01
</code></pre>

<p>First you should setup the cache file:</p>

<pre><code># squid -z
# systemctl start suiqd
# systemctl enable squid
</code></pre>

<p>Change username password via:</p>

<pre><code>$ htpasswd -c /etc/squid/passwd user1
$ htpasswd  /etc/squid/passwd user2
$ htpasswd  /etc/squid/passwd user3
</code></pre>

<h3>Usage</h3>

<p>In firefox: Edit->Preference->Network->Settings->, change proxy setting.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build Nbd Kernel Module on CentOS7]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/08/13/build-nbd-kernel-module-on-centos7/"/>
    <updated>2015-08-13T17:02:53+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/08/13/build-nbd-kernel-module-on-centos7</id>
    <content type="html"><![CDATA[<h3>Get Source Code</h3>

<p>First check your kernel version via:</p>

<pre><code>$ uname -r
3.10.0-229.7.2.el7.x86_64
</code></pre>

<p>Then find the corresponding kernel source rpm under vault.centos.org, download its rpm
and install it.</p>

<pre><code>$ wget http://vault.centos.org/7.1.1503/updates/Source/SPackages/kernel-3.10.0-229.7.2.el7.src.rpm
# useradd builder
# groupadd builder
$ rpm -ivh kernel-3.10.0-229.7.2.el7.src.rpm
</code></pre>

<h3>Build Preparation</h3>

<p>As a normal user, do following:</p>

<pre><code>$ mkdir -p ~/rpmbuild/{BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS}
$ echo '%_topdir %(echo $HOME)/rpmbuild' &gt; ~/.rpmmacros
$ cd ~/rpmbuild/SPECS
$ rpmbuild -bp --target=$(uname -m) kernel.spec
$ cd ~/rpmbuild/BUILD/kernel-3.10.0-229.7.2.el7/linux-3.10.0-229.7.2.el7.centos.x86_64/
$ ls
arch     COPYING  Documentation  fs       ipc      kernel       Makefile  README          scripts   tools
block    CREDITS  drivers        include  Kbuild   lib          mm        REPORTING-BUGS  security  usr
configs  crypto   firmware       init     Kconfig  MAINTAINERS  net       samples         sound     virt
</code></pre>

<p>Now the source code tree is available.</p>

<h3>Build</h3>

<p>In the kernel source directory, type <code>make menuconfig</code> for configurating the kernel
configuration, select :</p>

<p>Device Driver -> Block devices -> Set &ldquo;M&rdquo; On &ldquo;Network block device support&rdquo;</p>

<p>Save the configuration and exit, now begin to make via:</p>

<pre><code>$ make prepare &amp;&amp; make modules_prepare &amp;&amp; make
</code></pre>

<p>Now makeout the kernel module and copy it to modules directory:</p>

<pre><code>$ make M=drivers/block -j8
$ modinfo drivers/block/nbd.ko
$ sudo cp drivers/block/nbd.ko /lib/modules/3.10.0-229.7.2.el7.x86_64/extra/
$ sudo depmod -a &amp;&amp; sudo modprobe nbd
</code></pre>

<p>Finally met some problems of nbd, don&rsquo;t know why, later will debug on.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Chromebook Kernel Issue]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/07/25/chromebook-kernel-issue/"/>
    <updated>2015-07-25T11:34:48+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/07/25/chromebook-kernel-issue</id>
    <content type="html"><![CDATA[<h3>Issues</h3>

<p>Chromebook could not support: <br/>
* bluetooth LAN
* NFS  <br/>
* ETC</p>

<p>So I re-compile the Chromebook kernel for soving these issue.</p>

<h3>Kernel Version</h3>

<pre><code># uname -r
3.10.18
</code></pre>

<h3>Get The SourceCode</h3>

<pre><code># git clone --branch v3.10.18 https://chromium.googlesource.com/chromiumos/third_party/kernel
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Try Raid0 Installation on Ubuntu]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/07/03/try-raid0-installation-on-ubuntu/"/>
    <updated>2015-07-03T10:58:55+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/07/03/try-raid0-installation-on-ubuntu</id>
    <content type="html"><![CDATA[<h3>Preparation</h3>

<p>Prepare the disks:</p>

<pre><code>[root:/home/juju/img]# mkdir Raid0
[root:/home/juju/img]# cd Raid0/
[root:/home/juju/img/Raid0]# ls
[root:/home/juju/img/Raid0]# qemu-img create -f qcow2 disk0.qcow2 10G
Formatting 'disk0.qcow2', fmt=qcow2 size=10737418240 encryption=off cluster_size=65536 
[root:/home/juju/img/Raid0]# qemu-img create -f qcow2 disk1.qcow2 10G
Formatting 'disk1.qcow2', fmt=qcow2 size=10737418240 encryption=off cluster_size=65536 
[root:/home/juju/img/Raid0]# qemu-img create -f qcow2 disk2.qcow2 10G
Formatting 'disk2.qcow2', fmt=qcow2 size=10737418240 encryption=off cluster_size=65536 
</code></pre>

<p>Prepare the Virtual Machine:  <br/>
<img src="/images/2015_07_03_11_06_03_658x441.jpg" alt="/images/2015_07_03_11_06_03_658x441.jpg" /></p>

<p><img src="/images/2015_07_03_11_06_57_556x325.jpg" alt="/images/2015_07_03_11_06_57_556x325.jpg" /></p>

<h3>Partition</h3>

<p><img src="/images/2015_07_03_11_12_18_615x311.jpg" alt="/images/2015_07_03_11_12_18_615x311.jpg" /></p>

<p><img src="/images/2015_07_03_11_15_30_476x216.jpg" alt="/images/2015_07_03_11_15_30_476x216.jpg" /></p>

<p><img src="/images/2015_07_03_11_15_36_384x205.jpg" alt="/images/2015_07_03_11_15_36_384x205.jpg" /></p>

<p><img src="/images/2015_07_03_11_18_30_499x265.jpg" alt="/images/2015_07_03_11_18_30_499x265.jpg" /></p>

<h3>Raid</h3>

<p>Configure the Software Raid0:</p>

<p><img src="/images/2015_07_03_11_19_31_441x260.jpg" alt="/images/2015_07_03_11_19_31_441x260.jpg" /></p>

<p><img src="/images/2015_07_03_11_20_41_655x244.jpg" alt="/images/2015_07_03_11_20_41_655x244.jpg" /></p>

<p><img src="/images/2015_07_03_11_22_43_728x243.jpg" alt="/images/2015_07_03_11_22_43_728x243.jpg" /></p>

<p>After Configuration of SoftRaid1, the screen displayed like:</p>

<p><img src="/images/2015_07_03_11_28_28_687x457.jpg" alt="/images/2015_07_03_11_28_28_687x457.jpg" /></p>

<p>Continue to install.</p>

<h3>Verify Raid.</h3>

<p>Use df and fdisk to verify the partition information:</p>

<pre><code>clouder@UbuntuRaid1:~$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/md0        9.3G  870M  7.9G  10% /
none            4.0K     0  4.0K   0% /sys/fs/cgroup
udev            235M  4.0K  235M   1% /dev
tmpfs            50M  440K   49M   1% /run
none            5.0M     0  5.0M   0% /run/lock
none            246M     0  246M   0% /run/shm
none            100M     0  100M   0% /run/user
clouder@UbuntuRaid1:~$ sudo fdisk -l
[sudo] password for clouder: 

Disk /dev/vda: 10.7 GB, 10737418240 bytes
255 heads, 63 sectors/track, 1305 cylinders, total 20971520 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00035942

   Device Boot      Start         End      Blocks   Id  System
/dev/vda1   *        2048    19922943     9960448   fd  Linux raid autodetect
/dev/vda2        19924990    20969471      522241    5  Extended
/dev/vda5        19924992    20969471      522240   fd  Linux raid autodetect

Disk /dev/vdb: 10.7 GB, 10737418240 bytes
255 heads, 63 sectors/track, 1305 cylinders, total 20971520 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000715e9

   Device Boot      Start         End      Blocks   Id  System
/dev/vdb1   *        2048    19922943     9960448   fd  Linux raid autodetect
/dev/vdb2        19924990    20969471      522241    5  Extended
/dev/vdb5        19924992    20969471      522240   fd  Linux raid autodetect

Disk /dev/md0: 10.2 GB, 10190979072 bytes
2 heads, 4 sectors/track, 2488032 cylinders, total 19904256 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/md0 doesn't contain a valid partition table

Disk /dev/md1: 534 MB, 534446080 bytes
2 heads, 4 sectors/track, 130480 cylinders, total 1043840 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/md1 doesn't contain a valid partition table
</code></pre>

<p>Verify the raid status:</p>

<pre><code>root@UbuntuRaid1:/etc/initramfs-tools/conf.d# cat /proc/mdstat 
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
md1 : active raid1 vda5[0] vdb5[1]
      521920 blocks super 1.2 [2/2] [UU]

md0 : active raid1 vda1[0] vdb1[1]
      9952128 blocks super 1.2 [2/2] [UU]

unused devices: &lt;none&gt;
</code></pre>

<p>Query the status of SoftRaid1:</p>

<pre><code>root@UbuntuRaid1:/etc/initramfs-tools/conf.d# sudo mdadm --query --detail /dev/md0
/dev/md0:
        Version : 1.2
  Creation Time : Fri Jul  3 11:24:46 2015
     Raid Level : raid1
     Array Size : 9952128 (9.49 GiB 10.19 GB)
  Used Dev Size : 9952128 (9.49 GiB 10.19 GB)
   Raid Devices : 2
  Total Devices : 2
    Persistence : Superblock is persistent

    Update Time : Fri Jul  3 11:46:19 2015
          State : clean 
 Active Devices : 2
Working Devices : 2
 Failed Devices : 0
  Spare Devices : 0

           Name : UbuntuRaid1:0  (local to host UbuntuRaid1)
           UUID : bc091921:c198c219:7162e35c:bfff3c4e
         Events : 19

    Number   Major   Minor   RaidDevice State
       0     253        1        0      active sync   /dev/vda1
       1     253       17        1      active sync   /dev/vdb1
</code></pre>

<h3>Remove One Disk</h3>

<p>Remove one, and see if it could be startup.</p>

<p>Result:  <br/>
Done, it could start into the system.</p>

<pre><code>clouder@UbuntuRaid1:~$ cat /proc/mdstat 
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
md1 : active (auto-read-only) raid1 vda5[1]
      521920 blocks super 1.2 [2/1] [_U]

md0 : active raid1 vda1[1]
      9952128 blocks super 1.2 [2/1] [_U]

unused devices: &lt;none&gt;
</code></pre>

<h3>Add A New Empty Disk</h3>

<p>Add a new disk into the system, and first partition.</p>

<pre><code>$ sudo fdisk -l 

Disk /dev/vdb: 10.7 GB, 10737418240 bytes
16 heads, 63 sectors/track, 20805 cylinders, total 20971520 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/vdb doesn't contain a valid partition table
</code></pre>

<p>Clone the partition table from the vda to the newly added partion:</p>

<pre><code>$ sudo sfdisk -d /dev/vda &gt; vda.desc
$ cat vda.desc 
$ sudo sfdisk /dev/vdb&lt;./vda.desc
</code></pre>

<p>Now Add the new disk for usage:</p>

<pre><code>clouder@UbuntuRaid1:~$ cat /proc/mdstat 
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
md1 : active (auto-read-only) raid1 vda5[1]
      521920 blocks super 1.2 [2/1] [_U]

md0 : active raid1 vda1[1]
      9952128 blocks super 1.2 [2/1] [_U]

unused devices: &lt;none&gt;
clouder@UbuntuRaid1:~$ sudo mdadm --manage /dev/md0 --add /dev/vdb1
mdadm: added /dev/vdb1
clouder@UbuntuRaid1:~$ sudo mdadm --manage /dev/md1 --add /dev/vdb5
mdadm: added /dev/vdb5
clouder@UbuntuRaid1:~$ cat /proc/mdstat 
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
md1 : active raid1 vdb5[2] vda5[1]
      521920 blocks super 1.2 [2/1] [_U]
        resync=DELAYED

md0 : active raid1 vdb1[2] vda1[1]
      9952128 blocks super 1.2 [2/1] [_U]
      [===&gt;.................]  recovery = 16.6% (1662144/9952128) finish=1.8min speed=75552K/sec

unused devices: &lt;none&gt;
</code></pre>

<h3>Known Bugs</h3>

<p>Error and Solution:</p>

<pre><code>error:  Diskfilter writes are not supported

Edit :/etc/grub.d/10_linux

Replace 'quick_boot="1"' with 'quick_boot="0"'

Then :

sudo update-grub
</code></pre>
]]></content>
  </entry>
  
</feed>
