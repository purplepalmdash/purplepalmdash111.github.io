<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Virtualization | Dash]]></title>
  <link href="http://purplepalmdash.github.io/blog/categories/virtualization/atom.xml" rel="self"/>
  <link href="http://purplepalmdash.github.io/"/>
  <updated>2016-03-02T12:57:12+08:00</updated>
  <id>http://purplepalmdash.github.io/</id>
  <author>
    <name><![CDATA[Dash]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Virtio-gpu Working Tips]]></title>
    <link href="http://purplepalmdash.github.io/blog/2016/01/31/virtio-gpu-working-tips/"/>
    <updated>2016-01-31T11:49:13+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2016/01/31/virtio-gpu-working-tips</id>
    <content type="html"><![CDATA[<h3>System</h3>

<p>Install Fedora 23, select fedora server and install the system, then using the
lastest development kernel via:</p>

<pre><code>$ curl -s https://repos.fedorapeople.org/repos/thl/kernel-vanilla.repo | sudo tee /etc/yum.repos.d/kernel-vanilla.repo
$ sudo dnf --enablerepo=kernel-vanilla-mainline update
</code></pre>

<p>Checking the running kernel via:</p>

<pre><code>$ uname -r
4.5.0-0.rc1.git0.1.vanilla.knurd.1.fc23.x86_64
</code></pre>

<p>Running the system which have kernel version newer than 4.4  is the basis for enable the virt-io.</p>

<h3>Install packages</h3>

<pre><code>$ sudo dnf install -y gcc zlib-devel glib2-devel pixman-devel libfdt-devel \ 
lzo-devel snappy-devel bzip2-devel libseccomp-devel gtk2-devel gtk3-devel \ 
gnutls-devel vte-devel SDL-devel librdmacm-devel libuuid-devel \ 
 libcap-ng-devel libcurl-devel ceph-devel libssh2-devel libaio-devel \ 
glusterfs-devel glusterfs-api-devel numactl-devel gperftools-devel \ 
 texinfo libiscsi-devel spice-server-devel libusb-devel usbredir-devel \ 
libnfs-devel libcap-devel libattr-devel  
</code></pre>

<h3>virglrenderer</h3>

<p>coprs have the repository for this:  <br/>
<a href="https://copr.fedorainfracloud.org/coprs/kraxel/">https://copr.fedorainfracloud.org/coprs/kraxel/</a></p>

<pre><code>$ cd /etc/yum.repos.d/
$ sudo wget https://copr.fedorainfracloud.org/coprs/kraxel/virgl/repo/fedora-23/kraxel-virgl-fedora-23.repo
</code></pre>

<p>Install the virglrenderer via:</p>

<pre><code>$ sudo dnf install virglrenderer
</code></pre>

<h3>qemu</h3>

<p>Git clone the source code:</p>

<pre><code>$ git clone https://www.kraxel.org/cgit/qemu
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Read Digest on KVM]]></title>
    <link href="http://purplepalmdash.github.io/blog/2016/01/26/read-digest-on-kvm/"/>
    <updated>2016-01-26T09:12:26+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2016/01/26/read-digest-on-kvm</id>
    <content type="html"><![CDATA[<h3>Some Words</h3>

<p>VMM: (Virtual Machine Monitor)   <br/>
VMX: (Virtual Machine eXtensions):  instructions on processors with x86 virtualization.</p>

<p>Virtualization software:  is most often used to emulate a complete computer system in
order to allow a guest operating system to be run, for example allowing Linux to run as
a guest on top of a PC that is natively running a Microsoft Windows operating system
(or the inverse, running Windows as a guest on Linux).</p>

<p>CPU Ring:   <br/>
<a href="https://en.wikipedia.org/wiki/Protection_ring">https://en.wikipedia.org/wiki/Protection_ring</a></p>

<p><img src="/images/300px-Priv_rings.svg.png" alt="/images/300px-Priv_rings.svg.png" /></p>

<p>VT-d, I/O Hardware Virtualization.   <br/>
VT-c, Networking Hardware Virtualization.</p>

<h3>Host kickstart file</h3>

<p>Add following installation packages:</p>

<pre><code>%packages
@virtualization
@Base
@Core
@additional-devel
@base
@large-systems
@storage-client-iscsi
@systgem-management-snmp
@virtualization
@virtualization-client
@virtualization-platform
@virtualization-tools
%end
</code></pre>

<h3>Mouse On Windows Virtual Machine</h3>

<p>Add twice the usb mouse:</p>

<pre><code>&lt;input type='tablet' bus='usb'
</code></pre>

<h3>NUMA</h3>

<p>Install the numa configuration tools via:</p>

<pre><code># apt-cache search numactl
numactl - NUMA scheduling and memory placement tool
# apt-get -y install numactl
</code></pre>

<p>Command: <code>numactl --hardware</code>, <code>numastat</code>, <code>numastat -c qemu-kvm</code>.</p>

<p>Check the numa banlancing policy via:</p>

<pre><code># cat /proc/sys/kernel/numa_balancing
0
</code></pre>

<p><code>echo 1</code> for open the auto balancing.</p>

<p>KSM, could merge the same memory page, even in different NUMA node.</p>

<pre><code># cat /sys/kernel/mm/ksm/merge_across_nodes 
1
</code></pre>

<h3>CPU Binding</h3>

<p>Use <code>virsh vcpuinfo xx</code> for displaying the VCPU/CPU corresponding relationship.</p>

<pre><code>virsh # emulatorpin 79
emulator: CPU Affinity
----------------------------------
       *: 0-7
</code></pre>

<p>Change it dynamically:</p>

<pre><code>virsh # emulatorpin 79 0-3 --live

virsh # emulatorpin 79
emulator: CPU Affinity
----------------------------------
       *: 0-3
</code></pre>

<p>Now you could check the result via <code>virsh dumpxml xxx</code>:</p>

<pre><code>  &lt;vcpu placement='static'&gt;4&lt;/vcpu&gt;
  &lt;cputune&gt;
    &lt;emulatorpin cpuset='0-3'/&gt;
  &lt;/cputune&gt;
</code></pre>

<p>1-1 binding using virsh:</p>

<pre><code># virsh vcpupin 79 0 0    
# virsh vcpupin 79 1 1
# virsh vcpupin 79 2 2
# virsh vcpupin 79 3 3
# virsh dumpxml 79 | more
  &lt;cputune&gt;
    &lt;vcpupin vcpu='0' cpuset='0'/&gt;
    &lt;vcpupin vcpu='1' cpuset='1'/&gt;
    &lt;vcpupin vcpu='2' cpuset='2'/&gt;
    &lt;vcpupin vcpu='3' cpuset='3'/&gt;
</code></pre>

<p>Now view the vcpuinfo via:</p>

<pre><code># virsh vcpuinfo 79
VCPU:           0
CPU:            0
State:          running
CPU time:       9.2s
CPU Affinity:   y-------
</code></pre>

<h3>CPU Hot-Plug-in</h3>

<p>The cpu configuration info is listed as:</p>

<p><img src="/images/2016_01_26_10_54_29_285x127.jpg" alt="/images/2016_01_26_10_54_29_285x127.jpg" /></p>

<p>View the CPU infos via:</p>

<pre><code># cat /proc/interrupts 
           CPU0       CPU1       
</code></pre>

<p>Change the CPUs to 3:</p>

<pre><code>virsh # setvcpus 80 3 --live
</code></pre>

<p>Now in the vm the result should be(or detect it via <code>cat /proc/cpuinfo</code>) :</p>

<pre><code># cat /proc/interrupts 
           CPU0       CPU1       CPU2  
</code></pre>

<h3>CPU Working Mode</h3>

<p>If we select the pass-through, then the cpuinfo should be:</p>

<pre><code># virsh dumpxml xxxxx
  &lt;cpu mode='host-passthrough'&gt;
  &lt;/cpu&gt;
# cat /proc/cpuinfo
processor       : 1
vendor_id       : GenuineIntel
cpu family      : 6
model           : 58
model name      : Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz
</code></pre>

<p>If we select the host-model, will choose the most similar:  <br/>
Or If we choose <code>Copy host cpu mode</code>, like following:  <br/>
<img src="/images/2016_01_26_11_07_32_299x274.jpg" alt="/images/2016_01_26_11_07_32_299x274.jpg" /></p>

<pre><code># cat /proc/cpuinfo
....
processor       : 1
vendor_id       : GenuineIntel
cpu family      : 6
model           : 42
model name      : Intel Xeon E312xx (Sandy Bridge)
</code></pre>

<h3>Memory Balloon</h3>

<p>Change the memory balloon to 1024 or 4096 via:</p>

<pre><code># virsh qemu-monitor-command PerfTune --hmp --cmd balloon 1024
# virsh qemu-monitor-command PerfTune --hmp --cmd info balloon
balloon: actual=1024
# virsh qemu-monitor-command PerfTune --hmp --cmd balloon 4096
</code></pre>

<h3>Memory Limitation</h3>

<p>Make configuration of the memory via:</p>

<pre><code>virsh memtune PerfTune --hard-limit xxxxx --config
virsh memtune PerfTune --soft-limit xxxxx --config
virsh memtune PerfTune --swap-hard-limit xxxxx --config
virsh memtune PerfTune --min_guarantee xxxxx --config
</code></pre>

<p>&ndash;config, write to configuration xml
&ndash;live, lively write
&ndash;current ?</p>

<h3>HugePage</h3>

<p>Enable hugepage via:</p>

<pre><code># grep -i huge /proc/meminfo 
AnonHugePages:  12820480 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CloudStack使用LXC要点]]></title>
    <link href="http://purplepalmdash.github.io/blog/2016/01/14/cloudstackshi-yong-lxcyao-dian/"/>
    <updated>2016-01-14T19:41:03+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2016/01/14/cloudstackshi-yong-lxcyao-dian</id>
    <content type="html"><![CDATA[<h3>先决条件</h3>

<p>Cloudstack 4.6.0, Management Server搭建完毕, Agent包安装完毕.   <br/>
具体的步骤可以参考KVM的安装.</p>

<h3>Agent机器</h3>

<p>设置hypervisor的类型为LXC模式:</p>

<pre><code>$ vim /etc/cloudstack/agent/agent.properties
 hypervisor.type=lxc
$ service cloudstack-agent restart
</code></pre>

<h3>LXC系统虚拟机模板安装</h3>

<p>在CloudStack Management节点上,运行以下命令安装系统虚拟机模板:</p>

<pre><code>$ /usr/share/cloudstack-common/scripts/storage/secondary/cloud-install-sys-tmplt -m /mnt1 -u http://192.168.177.13/systemvm64template-4.6.0-kvm.qcow2.bz2 -h lxc -F
</code></pre>

<p>注意替换以上命令里的镜像下载地址及安装目录.</p>

<h3>添加Zone</h3>

<p>先添加一个基本的Zone,注意选择hypervisor为LXC.  <br/>
添加一级/二级存储.  <br/>
添加完毕后, enable zone后, 下载模板, 注意不要选择HVM的选项.</p>

<p>到这里就可以开始创建实例了.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Install CloudStack Mgmt Server on CentOS7]]></title>
    <link href="http://purplepalmdash.github.io/blog/2016/01/11/install-cloudstack-mgmt-server-on-centos7/"/>
    <updated>2016-01-11T15:03:38+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2016/01/11/install-cloudstack-mgmt-server-on-centos7</id>
    <content type="html"><![CDATA[<h3>Steps</h3>

<p>Disable selinux:</p>

<pre><code># setenforce permissive
# vim /etc/selinux/config 
SELINUX=permissive
</code></pre>

<p>Edit the hostname and hosts file:</p>

<pre><code>[root@csman ~]# cat /etc/hostname 
csman
[root@csman ~]# cat /etc/hosts
127.0.0.1 localhost localhost.cstack.local
192.168.56.12 csman.cstack.local csman
192.168.56.101 xenserver.cstack.local xenserver
</code></pre>

<p>Enable the ntp server:</p>

<pre><code># yum install -y ntp
# chkconfig ntpd on
# service ntpd start
</code></pre>

<p>Configure the nfs sharing:</p>

<pre><code># mkdir /exports
# mkdir -p /exports/primary
# mkdir -p /exports/secondary
# chmod 777 -R /exports
# echo "/exports/primary 10.10.100.0/24(rw,async,no_root_squash)" &gt; /etc/exports
# echo "/exports/secondary 10.10.101.0/24(rw,async,no_root_squash)" &gt;&gt; /etc/exports
# exportfs -a
</code></pre>

<p>Configure the nfs ruls:</p>

<pre><code># sed -i -e '/#MOUNTD_NFS_V3="no"/ c\MOUNTD_NFS_V3="yes"' -e '/#RQUOTAD_PORT=875/ c\RQUOTAD_PORT=875' -e '/#LOCKD_TCPPORT=32803/ c\LOCKD_TCPPORT=32803' -e '/#LOCKD_UDPPORT=32769/ c\LOCKD_UDPPORT=32769' -e '/#MOUNTD_PORT=892/ c\MOUNTD_PORT=892' -e '/#STATD_PORT=662/ c\STATD_PORT=662' -e '/#STATD_OUTGOING_PORT=2020/ c\STATD_OUTGOING_PORT=2020' /etc/sysconfig/nfs
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 111 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p udp -m udp --dport 111 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 2049 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p udp -m udp --dport 2049 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 2020 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 32803 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p udp -m udp --dport 32769 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 892 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p udp -m udp --dport 892 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 875 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p udp -m udp --dport 875 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 662 -j ACCEPT" /etc/sysconfig/iptables
# sed -i -e "/:OUTPUT/ a\-A INPUT -p udp -m udp --dport 662 -j ACCEPT" /etc/sysconfig/iptables
# service iptables restart
# chkconfig nfs on
# service nfs restart
</code></pre>

<p>Install the packages:</p>

<pre><code># yum install -y cloudstack-management
# yum -y install mariadb-server mariadb
</code></pre>

<p>Configure the mariadb:</p>

<pre><code># sed -i -e '/datadir/ a\innodb_rollback_on_timeout=1' -e '/datadir/ a\innodb_lock_wait_timeout=600' -e '/datadir/ a\max_connections=350' -e '/datadir/ a\log-bin=mysql-bin' -e "/datadir/ a\binlog-format = 'ROW'" -e "/datadir/ a\bind-address = 0.0.0.0" /etc/my.cnf
# systemctl enable mariadb
# systemctl start mariadb
# systemctl start mariadb.service
# mysql_secure_installation
</code></pre>

<p>Setup the privileges:</p>

<pre><code>[root@csman system]# mysql -u root -pengine123
MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;
MariaDB [(none)]&gt; quit
</code></pre>

<p>Setup the management database and setup the managment server:</p>

<pre><code># cloudstack-setup-databases cloud:&lt;password&gt;@127.0.0.1 --deploy-as=root:&lt;password&gt;
# cloudstack-setup-management --tomcat7
# service cloudstack-management start
# /bin/systemctl enable  cloudstack-management.service
</code></pre>

<p>Nginx:</p>

<pre><code># echo "[nginx]
name=nginx repo
baseurl=http://nginx.org/packages/centos/\$releasever/\$basearch/
gpgcheck=0
enabled=1" &gt; /etc/yum.repos.d/nginx.repo
# yum install nginx -y
# cd /usr/share/nginx/html
# wget -nc http://download.cloud.com/templates/builtin/centos56-x86_64.vhd.bz2
# sed -i -e "/:OUTPUT/ a\-A INPUT -p tcp -m tcp --dport 80 -j ACCEPT" /etc/sysconfig/iptables
# service iptables restart
</code></pre>

<p>vhd-utils:</p>

<pre><code># cd /usr/share/cloudstack-common/scripts/vm/hypervisor/xenserver/
# wget http://download.cloud.com.s3.amazonaws.com/tools/vhd-util
# chmod 755 /usr/share/cloudstack-common/scripts/vm/hypervisor/xenserver/vhd-util
</code></pre>

<p>SystemVM Template:</p>

<pre><code># /usr/share/cloudstack-common/scripts/storage/secondary/cloud-install-sys-tmplt -m /exports/secondary -u http://xxxxxxxxxxxxx -h xenserver -F
</code></pre>

<p>CloudStack usage server:</p>

<pre><code># yum install cloudstack-usage -y
# service cloudstack-usage start
</code></pre>

<p>Mysql related:</p>

<pre><code># mysql -p&lt;password&gt; cloud -e \ "INSERT INTO cloud.configuration (category, instance, component, name, value, description) VALUES ('Advanced', 'DEFAULT', 'management-server', 'xen.check.hvm', 'false', 'Shoud we allow only the XenServers support HVM');"
</code></pre>

<h3>If KVM</h3>

<p>Install bridge-utils:</p>

<pre><code># yum install -y bridge-utils
</code></pre>

<p>Edit the bridge connections:</p>

<pre><code># cat /etc/sysconfig/network-scripts/ifcfg-eth0 
DEVICE="eth0"
ONBOOT="yes"
BOOTPROTO=none
NM_CONTROLLED="no"
BRIDGE="cloudbr0"
TYPE=Ethernet
# cat /etc/sysconfig/network-scripts/ifcfg-cloudbr0
DEVICE="cloudbr0"
ONBOOT="yes"
NM_CONTROLLED=yes
TYPE="Bridge"
BOOTPROTO=static
IPADDR=10.47.58.11
NETMASK=255.255.255.0
GATEWAY=10.47.58.1
DNS1=223.5.5.5
DEFROUTE=yes
</code></pre>

<h3>Building 4.5.2/4.5.1 For CentOS 7</h3>

<p>Key-Step:</p>

<p><a href="http://zooi.widodh.nl/cloudstack/build-dep/cloud-manageontap.jar">http://zooi.widodh.nl/cloudstack/build-dep/cloud-manageontap.jar</a></p>

<h3>CentOS7 Isuse On CloudStack4.5.2</h3>

<p>Could not start the service of cloudstack-management, then you should manually add one
line in definition of the service file:</p>

<pre><code>[root@csmgmt ~]# vim /usr/lib/systemd/system/cloudstack-management.service
[Service]
+ PermissionsStartOnly=true
[root@csmgmt ~]# systemctl daemon-reload
[root@csmgmt ~]# service cloudstack-management start
Redirecting to /bin/systemctl start  cloudstack-management.service
[root@csmgmt ~]# netstat -anp | grep 8080
tcp6       0      0 :::8080                 :::*                    LISTEN
5665/java  
</code></pre>

<p>Another issue:</p>

<pre><code>Could not load org.apache.commons.pool.impl.CursorableLinkedList$Cursor
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Purge CloudStack Env]]></title>
    <link href="http://purplepalmdash.github.io/blog/2016/01/04/purge-cloudstack-env/"/>
    <updated>2016-01-04T16:26:30+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2016/01/04/purge-cloudstack-env</id>
    <content type="html"><![CDATA[<p>For totally reset the configured cloudstack environment, do following commands:</p>

<pre><code># service cloudstack-management stop
# mysql -pengine123 -e 'drop database cloud'
# mysql -pengine123 -e 'drop database cloud_usage'
# cloudstack-setup-databases cloud:engine123@localhost --deploy-as=root:engine123
# rm -rf /var/log/cloud/management/*
# cloudstack-setup-management 
</code></pre>
]]></content>
  </entry>
  
</feed>
