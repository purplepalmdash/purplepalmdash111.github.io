<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Virtualization | Dash]]></title>
  <link href="http://purplepalmdash.github.io/blog/categories/virtualization/atom.xml" rel="self"/>
  <link href="http://purplepalmdash.github.io/"/>
  <updated>2015-06-07T16:11:53+08:00</updated>
  <id>http://purplepalmdash.github.io/</id>
  <author>
    <name><![CDATA[Dash]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Use Chef for Deploying CloudStack Management Node]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/06/05/use-chef-for-deploying-cloudstack-management-node/"/>
    <updated>2015-06-05T17:07:22+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/06/05/use-chef-for-deploying-cloudstack-management-node</id>
    <content type="html"><![CDATA[<p>Following record all of the necessary steps for deploying cloudstack management node on kvm based environment.</p>

<h3>Get The CookBook</h3>

<p>You need following cookbooks:</p>

<pre><code>[kkkk@~/chef-repo/cookbooks]$ ls
apt         cloudstack_wrapper      cookbook_cloudstack_wrapper  line   nfs    rbac       selinux  sudo  yum-mysql-community
cloudstack  cloudstack_wrapper_kvm  learn_chef_apache2           mysql  nginx  README.md  smf      yum
[kkkk@~/chef-repo/cookbooks]$ pwd
/home/kkkk/chef-repo/cookbooks
</code></pre>

<p>Most of the books could be downloaded from the chef supermarket, while the <code>cookbook_cloudstack_wrapper</code> is downloaded from the github, and <code>cloudstack_wrapper_kvm</code> is modified from it.</p>

<p>Note: You have to replace all of the <code>cloudstack_wrapper::</code> to <code>cloudstack_wrapper_kvm::</code> under the copied folder.</p>

<p>You have to modify the definition of the</p>

<pre><code>[dash@~/chef-repo/cookbooks]$ cat cloudstack_wrapper_kvm/recipes/management_server.rb

......

# download initial systemvm template
cloudstack_system_template 'kvm' do
  nfs_path    node['cloudstack']['secondary']['path']
  nfs_server  node['cloudstack']['secondary']['host']
  url         node['cloudstack']['systemvm']['kvm']
  db_user     node['cloudstack']['db']['username']
  db_password node['cloudstack']['db']['password']
  db_host     node['cloudstack']['db']['host']
  action :create
end
......
</code></pre>

<h3>Add Node</h3>

<p>Add a new node into the system , then you should do following steps for letting the deployment continue:</p>

<pre><code>$ proxychains4  /opt/chef/embedded/bin/gem install cloudstack_ruby_client
$ sudo apt-get update
$  sudo apt-get install nfs-common
</code></pre>

<p>Now continue until you could see the final result.</p>

<h3>Verification</h3>

<p>After deployment, visit:</p>

<p><a href="http://YourIP:8080/client">http://YourIP:8080/client</a>   admin/password</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tips on Using Vagrant and Chefdk]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/06/03/tips-on-using-vagrant-and-chefdk/"/>
    <updated>2015-06-03T21:00:20+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/06/03/tips-on-using-vagrant-and-chefdk</id>
    <content type="html"><![CDATA[<ol>
<li>You should install all of the gem of <code>berkshelf</code> via:</li>
</ol>


<pre><code>$ gem install berkshelf
$ /opt/chef/embedded/bin/gem install berkshelf
$ /opt/vagrant/embedded/bin/gem install berkshelf
</code></pre>

<ol>
<li>Besure to add following into your PATH:</li>
</ol>


<pre><code>$  echo $PATH
/opt/chefdk/bin:/home/kkk/.rvm/gems/ruby-2.2.1/bin:/home/kkk/.rvm/gems/ruby-2.2.1@global/bin:/home/kkk/.rvm/rubies/ruby-2.2.1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/kkk/.rvm/bin:/home/kkk/.rvm/bin:/home/kkk/.rvm/bin
</code></pre>

<p>So now you could continue with <code>vagrant up</code> or other steps.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Chef Trouble-Shooting]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/06/02/chef-trouble-shooting/"/>
    <updated>2015-06-02T16:16:42+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/06/02/chef-trouble-shooting</id>
    <content type="html"><![CDATA[<h3>Error</h3>

<p>Could not Add new nodes.</p>

<h3>Reason</h3>

<p>This is because the chefDK remains the old version of chef-client,</p>

<pre><code>[dash@~/chef-repo]$ chef --version
Chef Development Kit Version: 0.6.0
chef-client version: ERROR
berks version: ERROR
kitchen version: 1.4.0
</code></pre>

<h3>Solution</h3>

<p>In node, manually get verified via following command:</p>

<pre><code>$ knife ssl fetch --config /etc/chef/client.rb
$ chef-client -l debug -S https://ChefServer/organizations/xxxxx -K /xxx/xxx/xxxxx.pem
</code></pre>

<p>Now bootstrap again, and you will see the node could be added into the Chef-Server&rsquo;s system.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tips on Deleteing Neutron Subnet and Router]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/05/25/tips-on-deleteing-neutron-subnet-and-router/"/>
    <updated>2015-05-25T21:44:54+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/05/25/tips-on-deleteing-neutron-subnet-and-router</id>
    <content type="html"><![CDATA[<p>Get the existing subnet:</p>

<pre><code>root@Controller:~# neutron subnet-list 
+--------------------------------------+-------------+----------------+--------------------------------------------------+
| id                                   | name        | cidr           | allocation_pools                                 |
+--------------------------------------+-------------+----------------+--------------------------------------------------+
| 98725e3a-7ee2-4e3f-83e3-eaca0236918f | demo-subnet | 192.168.1.0/24 | {"start": "192.168.1.2", "end": "192.168.1.254"} |
+--------------------------------------+-------------+----------------+--------------------------------------------------+
</code></pre>

<p>Delete it via:</p>

<pre><code>root@Controller:~# neutron subnet-delete --name demo-subnet
Unable to complete operation on subnet 98725e3a-7ee2-4e3f-83e3-eaca0236918f. One or more ports have an IP allocation from this subnet. (HTTP 409) (Request-ID: req-7d729bcc-ec50-4de6-83d9-5d2b98332127)
</code></pre>

<p>Because we have the router, so we list the router via:</p>

<pre><code>root@Controller:~# neutron router-list
+--------------------------------------+-------------+-----------------------+
| id                                   | name        | external_gateway_info |
+--------------------------------------+-------------+-----------------------+
| a745487e-8e7c-4cc2-aff7-a8423d0a6614 | demo-router | null                  |
+--------------------------------------+-------------+-----------------------+
</code></pre>

<p>Get the ports of this router:</p>

<pre><code>root@Controller:~# neutron router-port-list a745487e-8e7c-4cc2-aff7-a8423d0a6614
+--------------------------------------+------+-------------------+------------------------------------------------------------------------------------+
| id                                   | name | mac_address       | fixed_ips                                                                          |
+--------------------------------------+------+-------------------+------------------------------------------------------------------------------------+
| e56fe57e-e939-493b-8984-b5adfa64e2cc |      | fa:16:3e:b3:7b:e6 | {"subnet_id": "98725e3a-7ee2-4e3f-83e3-eaca0236918f", "ip_address": "192.168.1.1"} |
+--------------------------------------+------+-------------------+------------------------------------------------------------------------------------+
</code></pre>

<p>So we remove the interface from this router via:</p>

<pre><code>root@Controller:~# neutron router-interface-delete demo-router 98725e3a-7ee2-4e3f-83e3-eaca0236918f
Removed interface from router demo-router.
root@Controller:~# neutron router-port-list a745487e-8e7c-4cc2-aff7-a8423d0a6614
</code></pre>

<p>Now we could remove the router and the subnet:</p>

<pre><code>root@Controller:~# neutron router-delete demo-router
Deleted router: demo-router
root@Controller:~# neutron subnet-delete demo-subnet
Deleted subnet: demo-subnet
</code></pre>

<p>From now on ,you could create another subnet and router.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[三节点搭建OpenStack Juno(4)]]></title>
    <link href="http://purplepalmdash.github.io/blog/2015/05/25/san-jie-dian-da-jian-openstack-juno-4/"/>
    <updated>2015-05-25T20:11:17+08:00</updated>
    <id>http://purplepalmdash.github.io/blog/2015/05/25/san-jie-dian-da-jian-openstack-juno-4</id>
    <content type="html"><![CDATA[<p>Neutron和nova-network的区别在于，nova-network可以让你在每个instance上部署一种网络类型，适合基本的网络功能。而Neutron则使得你可以在一个instance上部署多种网络类型，并且以插件的方式支持多种虚拟化网络。</p>

<p>详细的介绍，以后慢慢加，理解吃透了再加上来，这里单单提操作步骤。</p>

<h3>准备</h3>

<p>数据库准备如下:</p>

<pre><code>root@Controller:~# mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 39
Server version: 5.5.43-MariaDB-1ubuntu0.14.04.2 (Ubuntu)

Copyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE neutron;
Query OK, 1 row affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY 'xxxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'xxxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; quit;
Bye
</code></pre>

<h3>配置服务</h3>

<pre><code>root@Controller:~# source admin-openrc.sh
root@Controller:~# keystone user-create --name neutron --pass xxxxx
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | a6d790e8e86749bba1d27972de8eaae2 |
|   name   |             neutron              |
| username |             neutron              |
+----------+----------------------------------+
root@Controller:~# keystone user-role-add --user neutron --tenant service --role admin
root@Controller:~# keystone service-create --name neutron --type network --description "OpenStack Networking"
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |       OpenStack Networking       |
|   enabled   |               True               |
|      id     | 2f6de710ec414797a4a639c2310c8249 |
|     name    |             neutron              |
|     type    |             network              |
+-------------+----------------------------------+
root@Controller:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ network / {print $2}') --publicurl http://Controller:9696 --adminurl http://Controller:9696 --internalurl http://Controller:9696 --region regionOne
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
|   adminurl  |      http://Controller:9696      |
|      id     | a23132fd0a824aa09f3b1ea72cbb97d2 |
| internalurl |      http://Controller:9696      |
|  publicurl  |      http://Controller:9696      |
|    region   |            regionOne             |
|  service_id | 2f6de710ec414797a4a639c2310c8249 |
+-------------+----------------------------------+
</code></pre>

<h3>安装和配置网络组件</h3>

<p>安装下列包:</p>

<pre><code># apt-get install neutron-server neutron-plugin-ml2 python-neutronclient
</code></pre>

<p>在Controller节点上开始配置:</p>

<pre><code>$ sudo vim /etc/neutron/neutron.conf
[database]
...
connection = mysql://neutron:NEUTRON_DBPASS@Controller/neutron
</code></pre>

<p>配置rabbitMQ认证方式:</p>

<pre><code>
[DEFAULT]
...
rpc_backend = rabbit
rabbit_host = Controller
rabbit_password = RABBIT_PASS
</code></pre>

<p>配置keystone认证:</p>

<pre><code>[DEFAULT]
...
auth_strategy = keystone

#### 删除已有的keystone authtoken配置方式
[keystone_authtoken]
...
auth_uri = http://Controller:5000/v2.0
identity_uri = http://Controller:35357
admin_tenant_name = service
admin_user = neutron
admin_password = NEUTRON_PASS
</code></pre>

<p>激活ML2插件(Modular Layer 2), router服务, 和overlapping IP地址:</p>

<pre><code>[DEFAULT]
...
core_plugin = ml2
service_plugins = router
allow_overlapping_ips = True
</code></pre>

<p>配置网络，以便在网络拓扑发生变化时告知Compute节点:</p>

<pre><code>[DEFAULT]
...
notify_nova_on_port_status_changes = True
notify_nova_on_port_data_changes = True
nova_url = http://Controller:8774/v2
nova_admin_auth_url = http://Controller:35357/v2.0
nova_region_name = regionOne
nova_admin_username = nova
nova_admin_tenant_id = SERVICE_TENANT_ID
nova_admin_password = NOVA_PASS
</code></pre>

<p><code>SERVICE_TENANT_ID</code> 通过以下命令来获得:</p>

<pre><code>$ source admin-openrc.sh
$ keystone tenant-get service
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |          Service Tenant          |
|   enabled   |               True               |
|      id     | 08a675be93a04cca8a74159a3eefa288 |
|     name    |             service              |
+-------------+----------------------------------+
</code></pre>

<p>可以自定义打开verbose选项:</p>

<pre><code>[DEFAULT]
...
verbose = True
</code></pre>

<p>配置Modular Layer2(ML2)插件:</p>

<p>在[ml2]部分，激活flat and generic routing encapsulation(GRE) network类型驱动, GRE Tenant网络和OVS机制驱动:</p>

<pre><code>$ sudo vim /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
...
type_drivers = flat,gre
tenant_network_types = gre
mechanism_drivers = openvswitch
</code></pre>

<p><code>[ml2_type_gre]</code> 部分，配置tunnel identifier(id)范围:</p>

<pre><code>[ml2_type_gre]
...
tunnel_id_ranges = 1:1000
</code></pre>

<p>配置securitygroup部分,</p>

<pre><code>[securitygroup]
...
enable_security_group = True
enable_ipset = True
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
</code></pre>

<p>配置计算服务使用网络:</p>

<pre><code>$ sudo vim /etc/nova/nova.conf
[DEFAULT]
...
network_api_class = nova.network.neutronv2.api.API
security_group_api = neutron
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver
</code></pre>

<p>在<code>[neutron]</code>部分，配置访问参数:</p>

<pre><code>[neutron]
...
url = http://Controller:9696
auth_strategy = keystone
admin_auth_url = http://Controller:35357/v2.0
admin_tenant_name = service
admin_username = neutron
admin_password = NEUTRON_PASS
</code></pre>

<p>完成安装：</p>

<pre><code># su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade juno" neutron
# service nova-api restart
# service nova-scheduler restart
# service nova-conductor restart
# service neutron-server restart
</code></pre>

<p>验证:</p>

<pre><code>root@Controller:~# source admin-openrc.sh
root@Controller:~# neutron ext-list
+-----------------------+-----------------------------------------------+
| alias                 | name                                          |
+-----------------------+-----------------------------------------------+
| security-group        | security-group                                |
| l3_agent_scheduler    | L3 Agent Scheduler                            |
| ext-gw-mode           | Neutron L3 Configurable external gateway mode |
| binding               | Port Binding                                  |
| provider              | Provider Network                              |
| agent                 | agent                                         |
| quotas                | Quota management support                      |
| dhcp_agent_scheduler  | DHCP Agent Scheduler                          |
| l3-ha                 | HA Router extension                           |
| multi-provider        | Multi Provider Network                        |
| external-net          | Neutron external network                      |
| router                | Neutron L3 Router                             |
| allowed-address-pairs | Allowed Address Pairs                         |
| extraroute            | Neutron Extra Route                           |
| extra_dhcp_opt        | Neutron Extra DHCP opts                       |
| dvr                   | Distributed Virtual Router                    |
+-----------------------+-----------------------------------------------+
</code></pre>

<h3>配置网络节点</h3>

<p>安装以下包:</p>

<pre><code># apt-get install neutron-plugin-ml2 neutron-plugin-openvswitch-agent neutron-l3-agent neutron-dhcp-agent
</code></pre>

<p>配置， 首先，删除<code>/etc/neutron/neutron.conf</code>里所有的database连接，因为网络节点不需要任何数据库连接。</p>

<pre><code>$ sudo vim /etc/neutron/neutron.conf
[DEFAULT]
...
rpc_backend = rabbit
rabbit_host = controller
rabbit_password = RABBIT_PASS
</code></pre>

<p>更改keystone认证方式:</p>

<pre><code>[DEFAULT]
...
auth_strategy = keystone
[keystone_authtoken]
...
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = neutron
admin_password = NEUTRON_PASS
</code></pre>

<p>有关<code>[ml2]</code>的配置:</p>

<pre><code>[DEFAULT]
...
core_plugin = ml2
service_plugins = router
allow_overlapping_ips = True
</code></pre>

<p>接着：</p>

<pre><code>$ sudo vim /etc/neutron/plugins/ml2/ml2_conf
[ml2]
...
type_drivers = flat,gre
tenant_network_types = gre
mechanism_drivers = openvswitch
[ml2_type_flat]
...
flat_networks = external
[ml2_type_gre]
...
tunnel_id_ranges = 1:1000
[securitygroup]
...
enable_security_group = True
enable_ipset = True
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
[ovs]
...
local_ip = INSTANCE_TUNNELS_INTERFACE_IP_ADDRESS
enable_tunneling = True
bridge_mappings = external:br-ex
[agent]
...
tunnel_types = gre
</code></pre>

<p>配置Layer-3客户端:</p>

<pre><code>$ sudo vim /etc/neutron/l3_agent.ini
[DEFAULT]
...
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
use_namespaces = True
external_network_bridge = br-ex
router_delete_namespaces = True
</code></pre>

<p>配置DHCP客户端：</p>

<pre><code>$ sudo vim /etc/neutron/dhcp_agent.init
[DEFAULT]
...
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
use_namespaces = True
dhcp_delete_namespaces = True

[DEFAULT]
...
dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf
</code></pre>

<p>配置dnsmasq配置文件:</p>

<pre><code>$ sudo vim /etc/neutron/dnsmasq_neutron.conf
dhcp-option-force=26,1454
$ sudo pkill dnsmasq
</code></pre>

<p>配置metadata客户端:</p>

<pre><code>$ sudo vim /etc/neutron/metadata_agent.ini
[DEFAULT]
...
auth_url = http://controller:5000/v2.0
auth_region = regionOne
admin_tenant_name = service
admin_user = neutron
admin_password = NEUTRON_PASS

[DEFAULT]
...
nova_metadata_ip = controller

[DEFAULT]
...
metadata_proxy_shared_secret = METADATA_SECRET
</code></pre>

<p>对应的，在控制节点上，配置:</p>

<pre><code>$ sudo vim /etc/nova/nova.conf
[neutron]
...
service_metadata_proxy = True
metadata_proxy_shared_secret = METADATA_SECRET
# service nova-api restart
</code></pre>

<p>配置Open vSwitch(OVS)服务:</p>

<pre><code># service openvswitch-switch restart
# ovs-vsctl add-br br-ex
# ovs-vsctl add-port br-ex INTERFACE_NAME
# service neutron-plugin-openvswitch-agent restart
# service neutron-l3-agent restart
# service neutron-dhcp-agent restart
# service neutron-metadata-agent restart
</code></pre>

<p>验证:</p>

<pre><code>$ source admin-openrc.sh
$ neutron agent-list
</code></pre>

<h3>计算节点配置</h3>

<p>配置如下;</p>

<pre><code>$ sudo vim /etc/sysctl.conf
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
# sysctl -p
</code></pre>

<p>安装网络组件：</p>

<pre><code># apt-get install neutron-plugin-ml2 neutron-plugin-openvswitch-agent
</code></pre>

<p>配置网络组件：</p>

<pre><code>$ sudo vim /etc/neutron/neutron.conf
[DEFAULT]
...
rpc_backend = rabbit
rabbit_host = controller
rabbit_password = RABBIT_PASS
</code></pre>

<p>keystone组件:</p>

<pre><code>[DEFAULT]
...
auth_strategy = keystone
[keystone_authtoken]
...
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = neutron
admin_password = NEUTRON_PASS
</code></pre>

<p><code>[ml2]</code>插件:</p>

<pre><code>$ sudo vim /etc/neutron/neutron.conf
[DEFAULT]
...
core_plugin = ml2
service_plugins = router
allow_overlapping_ips = True
</code></pre>

<p>继续配置ml2插件:  <br/>
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo vim /etc/neutron/plugins/ml2/ml2_conf.ini
</span><span class='line'>[ml2]
</span><span class='line'>&hellip;
</span><span class='line'>type_drivers = flat,gre
</span><span class='line'>tenant_network_types = gre
</span><span class='line'>mechanism_drivers = openvswitch&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;[ml2_type_gre]
</span><span class='line'>&hellip;
</span><span class='line'>tunnel_id_ranges = 1:1000&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;[securitygroup]
</span><span class='line'>&hellip;
</span><span class='line'>enable_security_group = True
</span><span class='line'>enable_ipset = True
</span><span class='line'>firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;[ovs]
</span><span class='line'>&hellip;
</span><span class='line'>local_ip = INSTANCE_TUNNELS_INTERFACE_IP_ADDRESS
</span><span class='line'>enable_tunneling = True&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;[agent]
</span><span class='line'>&hellip;
</span><span class='line'>tunnel_types = gre</span></code></pre></td></tr></table></div></figure></p>

<p>配置OVS服务：</p>

<pre><code># service openvswitch-switch restart
</code></pre>

<p>配置计算节点使用网络:</p>

<pre><code>$ sudo vim /etc/nova/nova.conf
[DEFAULT]
...
network_api_class = nova.network.neutronv2.api.API
security_group_api = neutron
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver

[neutron]
...
url = http://controller:9696
auth_strategy = keystone
admin_auth_url = http://controller:35357/v2.0
admin_tenant_name = service
admin_username = neutron
admin_password = NEUTRON_PASS
</code></pre>

<p>完成安装:</p>

<pre><code># service nova-compute restart
# service neutron-plugin-openvswitch-agent restart
</code></pre>

<p>验证， 在Controller节点上:</p>

<pre><code>$ source admin-openrc.sh
$ neutron agent-list
</code></pre>

<h3>创建初始化网络</h3>

<p>步骤如下:  <br/>
创建外网:</p>

<pre><code># source admin-openrc.sh
# neutron net-create ext-net --router:external True \
--provider:physical_network external --provider:network_type flat
# neutron subnet-create ext-net --name ext-subnet \
--allocation-pool start=10.77.77.200,end=10.77.77.220 \
--disable-dhcp --gateway 10.77.77.1 10.77.77.0/24
</code></pre>

<p>租户网络:</p>

<pre><code>$ source demo-openrc.sh
$ neutron net-create demo-net
$ neutron subnet-create demo-net --name demo-subnet \
--gateway 10.10.10.1 10.10.10.0/24
$ neutron router-create demo-router
$ neutron router-interface-add demo-router demo-subnet
$ neutron router-gateway-set demo-router ext-net
</code></pre>

<p>验证, 因为我们用了10.77.77.200~220作为外网的floating IP, 所以路由器外网的IP应该落在10.77.77.200上，在计算节点上直接ping, 看结果:</p>

<pre><code>dash@PowerfulDash:~$ ping 10.77.77.200
PING 10.77.77.200 (10.77.77.200) 56(84) bytes of data.
64 bytes from 10.77.77.200: icmp_seq=1 ttl=64 time=0.323 ms
64 bytes from 10.77.77.200: icmp_seq=2 ttl=64 time=0.177 ms
64 bytes from 10.77.77.200: icmp_seq=3 ttl=64 time=0.141 ms
</code></pre>

<p>其实上面的结果是在Host机器上Ping的，因host机器已经有了10.77.77.1地址，理论上，如果能Ping通10.77.77.200，证明Router工作正常。</p>

<h3>Horizon</h3>

<p>在控制节点上安装以下包 ：</p>

<pre><code># apt-get install openstack-dashboard apache2 libapache2-mod-wsgi memcached python-memcache
</code></pre>

<p>配置:</p>

<pre><code># vim /etc/openstack-dashboard/local_settings.py
OPENSTACK_HOST = "controller"
ALLOWED_HOSTS = ['*']
CACHES = {
'default': {
'BACKEND': 'django.core.cache.backends.memcached.
MemcachedCache',
'LOCATION': '127.0.0.1:11211',
}
}
TIME_ZONE = "TIME_ZONE"
</code></pre>

<p>重启服务:</p>

<pre><code># service apache2 restart
# service memcached restart
</code></pre>

<p>最后访问:  <br/>
<a href="http://Controller/horizon">http://Controller/horizon</a> 来看到结果.</p>
]]></content>
  </entry>
  
</feed>
