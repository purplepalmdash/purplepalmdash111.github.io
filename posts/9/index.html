
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Dash</title>
  <meta name="author" content="Dash">

  
  <meta name="description" content="在OpenStack HA部署好的基础上集成OpenContrail是一个比较繁琐的过程，所以这一节里我们主要做集成前的准备工作，准备网络拓扑和创建好OpenContrail本地部署仓库。 网络规划 在Miranti提供的集成参考里，有如下的图，定义了整个环境的网络拓扑。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://purplepalmdash.github.io/posts/9">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/purplepalmdash/atom.xml" rel="alternate" title="Dash" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//libs.useso.com/js/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Dash</a></h1>
  
    <h2>Get busy living, or get busy dying.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/purplepalmdash/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:purplepalmdash.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/27/shi-yong-fuelbu-shu-opencontrail-3/">使用Fuel部署OpenContrail(3)</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-27T18:56:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>27</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>6:56 pm</span></time>
        
         | <a href="/blog/2015/04/27/shi-yong-fuelbu-shu-opencontrail-3/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>在OpenStack HA部署好的基础上集成OpenContrail是一个比较繁琐的过程，所以这一节里我们主要做集成前的准备工作，准备网络拓扑和创建好OpenContrail本地部署仓库。</p>

<h3>网络规划</h3>

<p>在Miranti提供的集成参考里，有如下的图，定义了整个环境的网络拓扑。  <br/>
<img src="/images/2015_04_27_19_06_11_1147x804.jpg" alt="images/2015_04_27_19_06_11_1147x804.jpg" /> <br/>
从图中可以看到各个节点所接入到的物理网络。我们根据这些节点接入网络的不同，来定义对应系统上的网络配置。  <br/>
在安装完毕后的虚拟机里，可以看到该节点的DNS名称，例如node-19, node-20之类，在Fuel Controller上可以通过<code>ssh root@node-19</code>来登入相应角色的机器上。  <br/>
以下是三个OpenStack节点的网络部署, N/A代表不需要配置，可以直接把对应的接口文件删除:  <br/>
对应的接口分别是从eth0 ~ eth4.</p>

<p>OS1: node-19, PXE:10.20.0.14, Public: 172.16.0.6, Management: 10.55.55.6, Storage: 10.66.66.5, Private: N/A.   <br/>
OS2: node-20, PXE:10.20.0.15, Public: 172.16.0.7, Management: 10.55.55.7, Storage: 10.66.66.6, Private: N/A.   <br/>
OS3: node-22, PXE:10.20.0.16, Public: 172.16.0.8, Management: 10.55.55.8, Storage: 10.66.66.7, Private: N/A.</p>

<p>Compute: node-18, PXE: 10.20.0.13, Public: 172.16.0.5, Management: 10.55.55.5, Storage: 10.66.66.4, Private: N/A.</p>

<p>Contrail1: node-24, PXE: 10.20.0.10, Public: N/A, Management: N/A, Storage: N/A, Private: 10.77.77.10
Contrail2: node-21, PXE: 10.20.0.11, Public: N/A, Management: N/A, Storage: N/A, Private: 10.77.77.11
Contrail3: node-23, PXE: 10.20.0.12, Public: N/A, Management: N/A, Storage: N/A, Private: 10.77.77.12</p>

<p>OpenStack和Compute各个节点的配置是自动配置好的，Contrail节点上的Private节点则需要手动配置，具体步骤如下:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@node-24:~# vim /etc/network/interfaces.d/ifcfg-eth4 
</span><span class='line'>auto eth4
</span><span class='line'>iface eth4 inet static
</span><span class='line'>
</span><span class='line'>address 10.77.77.10
</span><span class='line'>netmask 255.255.255.0
</span><span class='line'>gateway 10.77.77.1
</span><span class='line'>
</span><span class='line'>post-up  ethtool  -K  eth4  gso off  gro off || true
</span></code></pre></td></tr></table></div></figure>


<p>删除三个Contrail Controller节点上的未用端口, 并重启后得到我们要的配置:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@node-24:~# rm -f /etc/network/interfaces.d/ifcfg-eth3 
</span><span class='line'>root@node-24:~# rm -f /etc/network/interfaces.d/ifcfg-eth2
</span><span class='line'>root@node-24:~# rm -f /etc/network/interfaces.d/ifcfg-eth1 
</span></code></pre></td></tr></table></div></figure>


<p>到这里，我们节点机的网络单机就配置完毕了。</p>

<h3>网间互通</h3>

<p>我们需要让Management网络和Private网络可以通过某种途径互相连通，这里为了部署的方便，直接在主机(Host机器)上用iptables加上以下规则：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># iptables -D FORWARD -i virbr5 -j REJECT --reject-with icmp-port-unreachable
</span><span class='line'># iptables -D FORWARD -o virbr5 -j REJECT --reject-with icmp-port-unreachable
</span><span class='line'># iptables -D FORWARD -o virbr3 -j REJECT --reject-with icmp-port-unreachable
</span><span class='line'># iptables -D FORWARD -i virbr3 -j REJECT --reject-with icmp-port-unreachable
</span><span class='line'># iptables -t nat -A POSTROUTING -s 10.55.55.0/24 -d 10.77.77.0/24 -j MASQUERADE
</span><span class='line'># iptables -t nat -A POSTROUTING -s 10.77.77.0/24 -d 10.55.55.0/24 -j MASQUERADE
</span></code></pre></td></tr></table></div></figure>


<p>值得注意的是，virbr5和virbr3就是10.55.55.0/24和10.77.77.0/24所附属的网口，具体可以在Virt-Manager的配置菜单里看到。   <br/>
添加完毕后，在OpenStack的节点(OS1,OS2,OS3)ping Private网络里的地址，如<code>ping 10.77.77.10</code>, 确保可以ping通；在Contrail Controller的节点(Contrail1, Contrail2, Contrail3)上ping Management网络里的地址，如10.55.55.6，确保可以ping通。 <br/>
集成OpenContrail的一个先决条件是Private网络和Management网络可以互通。</p>

<h3>OpenContrail安装仓库准备</h3>

<p>我们在Fuel Controller上建立OpenContrail的安装仓库，这样有利于快速部署， 具体的操作是从Juniper官方提供的deb包里释出OpenContrail安装所需要的包，形成一个本地仓库。具体步骤如下:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum -y install dpkg-devel
</span><span class='line'># cd ~/Deb
</span><span class='line'># mkdir -p /var/www/nailgun/contrail
</span><span class='line'># mv /root/contrail-install-packages_2.0-22~icehouse_all.deb  ./
</span><span class='line'># ar vx contrail-install-packages_2.0-22~icehouse_all.deb
</span><span class='line'># rm -f contrail-install-packages_2.0-22~icehouse_all.deb 
</span><span class='line'># tar xf data.tar.gz
</span><span class='line'># tar xf opt/contrail/contrail_packages/contrail_debs.tgz -C /var/www/nailgun/contrail
</span><span class='line'># cd /var/www/nailgun/contrail
</span><span class='line'># dpkg-scanpackages . /dev/null | gzip -9c &gt; Packages.gz
</span><span class='line'># rm -rf ~/Deb
</span></code></pre></td></tr></table></div></figure>


<p>
这时候如果在本机上访问  <br/>
<a href="http://10.20.0.2:8080/contrail/">http://10.20.0.2:8080/contrail/</a>  <br/>
就可以看到整个仓库的包列表及详情。这个仓库将在后面部署Contrail时被用到。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/27/shi-yong-fuelbu-shu-opencontrail-2/">使用Fuel部署OpenContrail(2)</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-27T17:04:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>27</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>5:04 pm</span></time>
        
         | <a href="/blog/2015/04/27/shi-yong-fuelbu-shu-opencontrail-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>本节在前面部署完Fuel 控制节点的基础上，接着部署一个OpenStack HA环境，并准备好OpenContrail的三个部署节点。</p>

<h3>节点初始化准备</h3>

<p>所有加入到Fuel控制节点里的机器，在加入前都需要进行初始化配置，而后才可以被Fuel所识别.  <br/>
在所有配置好的机器里，点击Details-> Boot Options, 设置如下：  <br/>
<img src="/images/2015_04_27_17_14_26_532x372.jpg" alt="/images/2015_04_27_17_14_26_532x372.jpg" />  <br/>
因为第一次启动的时候，磁盘里是没有内容的，机器会自动从第二选项启动(PXE). 机器将自动侦测5个网段上的PXE Server， 因为Fuel Controller接管了10.20.0.0/24 网段上的PXE请求，它将会把机器从PXE变成可部署的状态。</p>

<h3>OpenStack HA环境创建</h3>

<p>创建一个OpenStack HA环境，如下步骤，因为是HA，所以需要至少三个OpenStack Controller节点和一个OpenStack Compute节点。  <br/>
点击界面里的New OpenStack Environment, 在弹出的窗口中，命名需要部署的HA环境名，并选择部署所需要的镜像，这里我们选择Ubuntu作为部署OpenStack的基础镜像。  <br/>
<img src="/images/2015_04_27_17_18_22_680x435.jpg" alt="/images/2015_04_27_17_18_22_680x435.jpg" />  <br/>
点击下一步，选择HA模式：  <br/>
<img src="/images/2015_04_27_17_20_13_681x427.jpg" alt="/images/2015_04_27_17_20_13_681x427.jpg" /> <br/>
点击下一步，选择计算节点模式，这里选择qemu或者kvm问题都不大，不要选vcenter就是了:   <br/>
<img src="/images/2015_04_27_17_21_48_683x435.jpg" alt="/images/2015_04_27_17_21_48_683x435.jpg" />   <br/>
点击下一步，进入到网络模式选择，选择Legacy Network(nova-network), 先部署成这种形式，接下来我们会使用neutron和contrail的组合重新规划网络:   <br/>
<img src="/images/2015_04_27_17_23_03_682x428.jpg" alt="/images/2015_04_27_17_23_03_682x428.jpg" /> <br/>
点击下一步，Storage Backend，因为我们不打算引入任何存储节点，这里选择Default，直接进入下一步， Additional Service里我们也不打算启任何额外的服务，一路Next直到最后Create出整个OpenStack环境。</p>

<p>依次创建另一个OpenStack HA环境，用来部署三台Contrail Controller的节点机.</p>

<h3>OpenStack环境网络</h3>

<p>Fuel默认的网络配置会激活三个物理端口，第一个端口接入PXE网络，第二个接入Public网络，第三个上启三个VLAN，分别接入到Management/Storage/Private网络。我认为VLAN的配置增加了配置和部署的复杂度，更改为五个物理网络，分别使用我们在Virt-Manager中创建出的五个物理网卡接入。更改方法如下:   <br/>
点击Network, 更改Management下的CIDR，手动填入10.55.55.0/24，然后去掉前面的Use VLAN Tag:      <br/>
<img src="/images/2015_04_27_17_32_09_465x466.jpg" alt="/images/2015_04_27_17_32_09_465x466.jpg" /></p>

<p>依次修改Storage网络和Private网络，更改完毕后，你的配置应该看起来是这样的:    <br/>
<img src="/images/2015_04_27_17_34_33_387x388.jpg" alt="/images/2015_04_27_17_34_33_387x388.jpg" /></p>

<p>对于Public网络我们不需要有任何修改，保持172.16网段的配置即可。</p>

<p>确认Network的配置为FlatDHCP Manager:   <br/>
<img src="/images/2015_04_27_17_35_37_391x149.jpg" alt="/images/2015_04_27_17_35_37_391x149.jpg" /></p>

<h3>建立OpenStack HA环境</h3>

<p>经PXE启动的虚拟机会把自己加入到"Unallocated Nodes"的队列里，在创建好的环境里，点击Node后，可以看到Fuel对角色的分配，添加一个OpenStack Controller的步骤如下：  <br/>
在Assign Roles里选择"Controller", 下面的备选节点里选择一台机器后，Apply Changes按钮会变绿，点击进入下一步.   <br/>
<img src="/images/2015_04_27_17_42_34_800x530.jpg" alt="/images/2015_04_27_17_42_34_800x530.jpg" />  <br/>
在切换到的页面中，点击节点最右边的齿轮，配置该节点机器的网络、存储等，这里只配置网络：  <br/>
<img src="/images/2015_04_27_17_44_05_797x203.jpg" alt="/images/2015_04_27_17_44_05_797x203.jpg" />  <br/>
点击Configure Network配置网络:   <br/>
<img src="/images/2015_04_27_17_45_19_448x349.jpg" alt="/images/2015_04_27_17_45_19_448x349.jpg" />  <br/>
可以看到前4个节点已经配置好了，我们只需要把VM(Fix)这个框从eth0拖动到eth4即可:    <br/>
<img src="/images/2015_04_27_17_46_34_524x342.jpg" alt="/images/2015_04_27_17_46_34_524x342.jpg" />  <br/>
添加完毕后，网络配置应该如下图:  <br/>
<img src="/images/2015_04_27_17_48_22_489x436.jpg" alt="/images/2015_04_27_17_48_22_489x436.jpg" /> <br/>
点击Apply后，保存当前配置，然后点击Back to node list可以顺次添加其他节点。</p>

<p>下面是一个添加好的OpenStack HA环境示例(3 Controller + 2 Compute):   <br/>
<img src="/images/2015_04_27_17_57_01_948x432.jpg" alt="/images/2015_04_27_17_57_01_948x432.jpg" /></p>

<p>这里要注意，因为我们要启用嵌套虚拟化，所以确保Compute节点是把Host CPU Configuration下发了的那台。 <br/>
添加完三个OpenStack Controller节点和一个OpenStack Compute节点后，就可以点击Deploy Changes开始部署了。整个部署的过程至少需要1个小时，取决于机器配置和磁盘读写快慢。</p>

<p>部署完毕后，Fuel会弹出提示信息，并给出可访问OpenStack HA Horizon界面的URL。</p>

<h3>准备Contrail部署节点</h3>

<p>在OpenStack HA节点部署的同时，我们可以准备好Contrail部署节点。  <br/>
同样创建出一个新的OpenStack HA部署环境，记住我们不能在已有的OpenStack HA环境里添加节点机，因为那样部署出来的节点机都会带上OpenStack的一些包，我们需要一个纯净的Ubuntu环境进行Contrail组件的配置。 <br/>
同样添加3个Compute节点，进行同样的网络配置，添加完节点后，Deploy Changes按钮是不能被点下的，因为我们的环境里没有OpenStack Controller. 一个环境示例如下:  <br/>
<img src="/images/2015_04_27_17_59_13_837x489.jpg" alt="/images/2015_04_27_17_59_13_837x489.jpg" /></p>

<p>我们需要登录到Fuel Controller的终端，就是10.20.0.2那台机器(用户名root,密码r00tme)，手动对添加的三个Contrail节点进行provision:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># fuel --env &lt;ENVIRONMENT_ID&gt; node --list
</span><span class='line'># fuel node --node-id &lt;NODE1_ID&gt;,&lt;NODE2_ID&gt;,&lt;NODE3_ID&gt; --env-id &lt;ENVIRONMENT_ID&gt; --provision
</span></code></pre></td></tr></table></div></figure>


<p>如何得到当前的ENVIRONMENT_ID, 下面提供了一个例子:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@fuel ~]# fuel --env environment
</span><span class='line'>id | status      | name                              | mode       | release_id | changes                                                                                                                                                               | pending_release_id
</span><span class='line'>---|-------------|-----------------------------------|------------|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------
</span><span class='line'>36 | operational | JunoOpenStack                     | multinode  | 2          | []                                       
</span><span class='line'>[root@fuel ~]# fuel --env 36 node --list
</span><span class='line'>id | status | name             | cluster | ip        | mac               | roles      | pending_roles | online | group_id
</span><span class='line'>---|--------|------------------|---------|-----------|-------------------|------------|---------------|--------|---------
</span><span class='line'>3  | ready  | Untitled (e5:f2) | 36      | 10.20.0.3 | da:98:96:c5:c3:4b | compute    |               | False  | 36      
</span><span class='line'>4  | ready  | Untitled (71:15) | 36      | 10.20.0.4 | 1a:ff:37:1f:26:44 | controller |               | False  | 36  
</span><span class='line'>[root@fuel ~]# fuel node --node-id 3 --env-id 36 --provision2
</span></code></pre></td></tr></table></div></figure>


<p>同样需要大约30分钟时间用来在三台Contrail Controller的节点机上部署完可用的Ubuntu系统，部署完毕后，node界面上可以看到绿色的小字"ubuntu installed".</p>

<p>这一节我们通过Fuel部署完毕OpenStack HA, 并准备了用于后续部署OpenContrail的三台Contrail Controller节点。接下来我们可以进入到OpenStack和OpenContrail的集成了。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/22/shi-yong-fuelbu-shu-opencontrail-1/">使用Fuel部署OpenContrail(1)</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-22T20:01:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>22</span><span class='date-suffix'>nd</span>, <span class='date-year'>2015</span></span> <span class='time'>8:01 pm</span></time>
        
         | <a href="/blog/2015/04/22/shi-yong-fuelbu-shu-opencontrail-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最近在做OpenContrail的解耦合操作，因为官方提供的OpenContrail一键安装包里诸多组件都是用的默认的推荐，通过解耦合可以做到更灵活的安装和配置，有利于更方便的部署和后续的维护。所以这一系列文章是关于如何用Fuel在部署完OpenStack的基础上完成OpenContrail的部署。</p>

<h3>先决条件</h3>

<p>先决条件主要是用于准备用于部署的硬件环境和软件包。 <br/>
硬件环境:   <br/>
i5-4460(3.2GHz/4核/6M三级缓存), 32G 内存。  <br/>
系统:  <br/>
Ubuntu 14.04 LTS  <br/>
软件:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get install libvirtd virt-manager
</span></code></pre></td></tr></table></div></figure>


<p>
从Miranti网站下载： MirantisOpenStack-6.0.iso  <br/>
从Contrail网站下载: contrail-install-packages_2.0-22~icehouse_all.deb  <br/>
contrail-neutron-plugin仓库:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/Juniper/contrail-neutron-plugin.git
</span></code></pre></td></tr></table></div></figure>


<h3>CPU/内存/磁盘规划</h3>

<p>需要构建一共8台虚拟机用于在部署好的Mirantis OpenStack上集成OpenContrail. CPU/内存/磁盘规划如下:  <br/>
1台Mirantis Fuel控制节点机,2核,划分3G内存, 100G磁盘。
3个OpenStack Controller节点, 2核,各划分3G内存, 100G磁盘。   <br/>
1个OpenStack Compute节点，2核(嵌套虚拟化),划分3G内存, 100G磁盘。   <br/>
3个OpenContrail节点，2核,各划分4G内存, 100G磁盘。  <br/>
一共需要27G内存。磁盘格式为qcow2，实际占用远小于这个数，各个节点最大也就是在5G左右大小。 <br/>
其中，关于嵌套虚拟化的CPU设置，如下图, 记得选择Copy host CPU Configuration:   <br/>
<img src="/images/2015_04_27_12_20_40_598x372.jpg" alt="/images/2015_04_27_12_20_40_598x372.jpg" />   <br/>
启用嵌套虚拟化需要在BIOS设置，并添加相应的内核模块。</p>

<h3>网络规划</h3>

<p>Fuel OpenStack规划了5个网络，分别是:   <br/>
Admin(PXE)  <br/>
Public   <br/>
Management   <br/>
Storage   <br/>
Private</p>

<p>我们在Virt-Manager里也同样创建出这样的五个子网:  <br/>
Admin(PXE) &ndash; FuelNAT  &ndash; 10.20.0.0/24   <br/>
Public &ndash; FuelPublic  &ndash; 172.16.0.0/24  <br/>
Management &ndash; FuelMgmt &ndash; 10.55.55.0/24  <br/>
Storage  &ndash; FuelStorage &ndash; 10.66.66.0/24  <br/>
Private  &ndash; FuelPrivate &ndash; 10.77.77.0/24</p>

<p>创建网络的步骤如下，双击Virtual Machine Manager里的localhost(QEMU), 弹出下面的窗口:  <br/>
<img src="/images/2015_04_27_14_57_37_499x379.jpg" alt="/images/2015_04_27_14_57_37_499x379.jpg" />  <br/>
点击网络列表最下面的+号,弹出创建网络的窗口:  <br/>
<img src="/images/2015_04_27_14_58_52_543x374.jpg" alt="/images/2015_04_27_14_58_52_543x374.jpg" />  <br/>
命名该网络，点击下一步:  <br/>
<img src="/images/2015_04_27_15_00_34_549x371.jpg" alt="/images/2015_04_27_15_00_34_549x371.jpg" />  <br/>
禁用DHCP:  <br/>
<img src="/images/2015_04_27_16_37_32_544x374.jpg" alt="/images/2015_04_27_16_37_32_544x374.jpg" />  <br/>
选择isolated网络模式:  <br/>
<img src="/images/2015_04_27_16_38_34_551x375.jpg" alt="/images/2015_04_27_16_38_34_551x375.jpg" />  <br/>
接着点击下一步直到完成，这样我们的网络就创建好了。  <br/>
用上面的方法创建出以上5个子网。</p>

<h3>各个节点网络配置</h3>

<p>Miranti Fuel Node: 仅FuelNAT, 安装完毕后，自动指定地址为10.20.0.2.    <br/>
其他所有节点机，在创建时，把五个网络都添加上，添加方法如下:  <br/>
Details -> Add Hardware -> Network, 而后选择:      <br/>
<img src="/images/2015_04_27_16_45_34_765x444.jpg" alt="/images/2015_04_27_16_45_34_765x444.jpg" /></p>

<h3>Miranti Fuel Node安装</h3>

<p>安装很简单，直接用下载的MirantisOpenStack-6.0.iso作为安装光盘，在创建出来的虚拟机里安装系统。安装完毕后，在Host机器的浏览器里访问   <br/>
<a href="http://10.20.0.2:8000">http://10.20.0.2:8000</a>    <br/>
输入用户名密码都为admin后，登录，可以看到以下界面:    <br/>
<img src="/images/2015_04_27_16_55_29_717x477.jpg" alt="/images/2015_04_27_16_55_29_717x477.jpg" />  <br/>
在这个界面里我们可以进行OpenStack环境的准备、部署、配置、销毁等操作。</p>

<p>到这一步，我们已经完成了Miranti Fuel Node的安装，基本的部署准备工作已经完成，接下来我们将使用Fuel来部署一个可用的OpenStack环境, 以及三台用于部署Contrail的节点机.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/17/glusterfs-howto/">Glusterfs Howto</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-17T14:18:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>2:18 pm</span></time>
        
         | <a href="/blog/2015/04/17/glusterfs-howto/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I want to expand my storage size on DigitalOcean, the droplet I have on DO one have 11G, and the other have 15G size, so if I could combine them together, I could do much more development on it. Following is how-to.</p>

<h3>Glusterfs Setup</h3>

<p>Install it under Ubuntu via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># apt-get install glusterfs-server
</span></code></pre></td></tr></table></div></figure>


<p>In both node, install the same software, and then add following lines into your /etc/hosts:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>10.17.17.195    Gluster2
</span><span class='line'>10.17.17.194    Gluster1
</span></code></pre></td></tr></table></div></figure>


<p>In Gluster1, probe Gluster2:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:~# gluster peer probe Gluster2
</span><span class='line'>peer probe: success
</span></code></pre></td></tr></table></div></figure>


<p>Then view the gluster peer status:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:~# gluster peer status
</span><span class='line'>Number of Peers: 1
</span><span class='line'>
</span><span class='line'>Hostname: Gluster2
</span><span class='line'>Port: 24007
</span><span class='line'>Uuid: 881dedb8-6cd4-4127-8c96-223daef081f5
</span><span class='line'>State: Peer in Cluster (Connected)
</span></code></pre></td></tr></table></div></figure>


<p>Create the volumn via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:~# gluster volume create vol_replica transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
</span><span class='line'>volume create: vol_replica: success: please start the volume to access data
</span></code></pre></td></tr></table></div></figure>


<p>Start the created vol:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:~# gluster volume start vol_replica
</span><span class='line'>volume start: vol_replica: success
</span></code></pre></td></tr></table></div></figure>


<p>View volumn info:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:~# gluster volume info 
</span><span class='line'> 
</span><span class='line'>Volume Name: vol_replica
</span><span class='line'>Type: Distribute
</span><span class='line'>Volume ID: 953456f3-0c46-4d07-ac41-591d1e398be6
</span><span class='line'>Status: Started
</span><span class='line'>Number of Bricks: 2
</span><span class='line'>Transport-type: tcp
</span><span class='line'>Bricks:
</span><span class='line'>Brick1: Gluster2:/home/glustervms
</span><span class='line'>Brick2: Gluster1:/home/glustervms
</span></code></pre></td></tr></table></div></figure>


<p>Now create the folder and mount the glusterfs via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home# mkdir glustervmsmnt
</span><span class='line'>root@Gluster1:/home# mount -t glusterfs Gluster1:/vol_replica /home/glustervmsmnt/
</span></code></pre></td></tr></table></div></figure>


<p>View the disk filesystem info:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Gluster1:/vol_replica   39G  4.7G   32G  13% /home/glustervmsmnt
</span></code></pre></td></tr></table></div></figure>


<h3>Glusterfs Volumn deletion</h3>

<p>The replica is not the one we want, for combine two partitions, I need the Distributed stripped mode, which is the one described in:   <br/>
<a href="http://www.gluster.org/community/documentation/index.php/Gluster_3.2:_Creating_Distributed_Striped_Volumes">http://www.gluster.org/community/documentation/index.php/Gluster_3.2:_Creating_Distributed_Striped_Volumes</a>    <br/>
So first I have to delete the one I&rsquo;ve created in the above part. <br/>
First umount the one I&rsquo;ve created:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# umount /home/glustervmsmnt 
</span></code></pre></td></tr></table></div></figure>


<p>checked via <code>mount</code> or <code>df -h</code> we could see the one we have mounted has been umounted.</p>

<p>Second, stop the volumes we&rsquo;ve created:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# gluster volume stop vol_replica
</span><span class='line'>Stopping volume will make its data inaccessible. Do you want to continue? (y/n) y
</span><span class='line'>volume stop: vol_replica: success
</span></code></pre></td></tr></table></div></figure>


<p>Third, delete volumn:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# gluster volume delete vol_replica
</span><span class='line'>Deleting volume will erase all information about the volume. Do you want to continue? (y/n) y
</span><span class='line'>volume delete: vol_replica: success
</span></code></pre></td></tr></table></div></figure>


<p>Check the volume status:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# gluster volume info
</span><span class='line'>No volumes present
</span></code></pre></td></tr></table></div></figure>


<h3>Create the distributed stripped volume</h3>

<p>Create the bigvolume:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# gluster volume create bigvolume transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
</span></code></pre></td></tr></table></div></figure>


<p>Start the volume:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# gluster volume start bigvolume
</span><span class='line'>volume start: bigvolume: success
</span></code></pre></td></tr></table></div></figure>


<p>View the status of the volume:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervmsmnt# gluster volume info 
</span><span class='line'> 
</span><span class='line'>Volume Name: bigvolume
</span><span class='line'>Type: Distribute
</span><span class='line'>Volume ID: 3e09f074-4675-46d3-873f-f00ef13fb509
</span><span class='line'>Status: Started
</span><span class='line'>Number of Bricks: 2
</span><span class='line'>Transport-type: tcp
</span><span class='line'>Bricks:
</span><span class='line'>Brick1: Gluster2:/home/glustervms
</span><span class='line'>Brick2: Gluster1:/home/glustervms
</span></code></pre></td></tr></table></div></figure>


<p>Mount it via following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># mount -t glusterfs Gluster1:/bigvolume /home/glustervmsmnt/
</span></code></pre></td></tr></table></div></figure>


<h3>Trouble-Shooting</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@Gluster1:/home/glustervms# gluster volume create bigvolume transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
</span><span class='line'>volume create: bigvolume: failed: /home/glustervms or a prefix of it is already part of a volume
</span></code></pre></td></tr></table></div></figure>


<p>Resolve it via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#  apt-get install attr
</span><span class='line'>#  setfattr -x trusted.glusterfs.volume-id /home/glustervms
</span><span class='line'>#  setfattr -x trusted.gfid /home/glustervms
</span><span class='line'>#  rm -rf /home/glustervms/.glusterfs/
</span></code></pre></td></tr></table></div></figure>


<p>Re-run the gluster volome create command it will create the volume which combines two folders.</p>

<h3>Digital Ocean Scenario</h3>

<p>My DO droplet runs Ubuntu and CentOS, their version is Trusty(14.04) and CentOS7, so do following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CentOS # wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repo
</span><span class='line'>CentOS # yum -y install glusterfs glusterfs-fuse glusterfs-server
</span><span class='line'>CentOS # systemctl start glusterd
</span><span class='line'>CentOS # systemctl enable glusterd
</span><span class='line'>Trusty # apt-get install glusterfs-server
</span></code></pre></td></tr></table></div></figure>


<p>Add each other&rsquo;s name and ip address into /etc/hosts, make sure they could ping each other and get responsible:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>1xx.xx.xxx.xxx   CentOS
</span><span class='line'>1xx.xx.xxx.xx Trusty
</span></code></pre></td></tr></table></div></figure>


<p>Use Trusty as the server, so on the Trusty machine, detect the CentOS&rsquo;s glusterd configuration as:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Trusty # gluster peer probe CentOS
</span><span class='line'>peer probe: success
</span></code></pre></td></tr></table></div></figure>


<p>Check the status:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Trusty # gluster peer status
</span><span class='line'>Number of Peers: 1
</span><span class='line'>
</span><span class='line'>Hostname: CentOS
</span><span class='line'>Port: 24007
</span><span class='line'>Uuid: xxxxxxxx
</span><span class='line'>State: Peer in Cluster (Connected)
</span></code></pre></td></tr></table></div></figure>


<p>Create the bigvolume, and mount it into your own directory via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Trusty # gluster volume create bigvolume transport tcp CentOS:/home/glustervms Trusty:/home/glustervms force
</span><span class='line'>volume create: bigvolume: success: please start the volume to access data
</span><span class='line'>Trusty # gluster volume start bigvolume
</span><span class='line'>volume start: bigvolume: success
</span><span class='line'>Trusty # gluster volume info
</span><span class='line'> 
</span><span class='line'>Volume Name: bigvolume
</span><span class='line'>Type: Distribute
</span><span class='line'>Volume ID: xxxxxxxxxxxxxxxxxxxxx
</span><span class='line'>Status: Started
</span><span class='line'>Number of Bricks: 2
</span><span class='line'>Transport-type: tcp
</span><span class='line'>Bricks:
</span><span class='line'>Brick1: CentOS:/home/glustervms
</span><span class='line'>Brick2: Trusty:/home/glustervms
</span><span class='line'>Trusty # mkdir /home/glustervmsmnt/
</span><span class='line'>Trusty # mount -t glusterfs Trusty:/bigvolume /home/glustervmsmnt/
</span><span class='line'>Trusty # df -h
</span><span class='line'>Filesystem              Size  Used Avail Use% Mounted on
</span><span class='line'>/dev/vda1                20G  9.4G  9.2G  51% /
</span><span class='line'>none                    4.0K     0  4.0K   0% /sys/fs/cgroup
</span><span class='line'>udev                    235M  8.0K  235M   1% /dev
</span><span class='line'>tmpfs                    50M  396K   49M   1% /run
</span><span class='line'>none                    5.0M     0  5.0M   0% /run/lock
</span><span class='line'>none                    246M  1.1M  244M   1% /run/shm
</span><span class='line'>none                    100M     0  100M   0% /run/user
</span><span class='line'>Trusty:/bigvolume       40G   14G   24G  37% /home/glustervmsmnt
</span></code></pre></td></tr></table></div></figure>


<p>Now you could operate under the /home/glustervmsmnt and you have 24G size partion of the disk. Enjoy them!!!</p>

<h3>Trouble-Shooting 1</h3>

<p>If you met <code>File change as we read it</code> in tar something, do following things:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Trusty # gluster volume set bigvolume performance.stat-prefetch off
</span><span class='line'>volume set: success
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/16/quickly-play-puppet/">Quickly Play Puppet</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-16T16:09:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>4:09 pm</span></time>
        
         | <a href="/blog/2015/04/16/quickly-play-puppet/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Server and Client</h3>

<p>In server, install following packages:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get install puppet puppetmaster
</span></code></pre></td></tr></table></div></figure>


<p>In client, only install puppet is enough.   <br/>
After installation, added the each other&rsquo;s name into <code>/etc/hosts</code>, let them ping each other via name rather than via ip address.</p>

<h3>Sign</h3>

<p>In client, do following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ clouder@pc121:/etc/puppet$ puppet agent --test --server=pc119
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span></code></pre></td></tr></table></div></figure>


<p>Then in server, listed all of the certification request:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@pc119:~/Code/herokublog# sudo puppet cert list
</span><span class='line'>  "pc121" (SHA256) 28:23:36:3C:E4:8B:3A:15:D2:B0:8C:A2:BC:E9:A1:E5:6A:6F:76:0E:40:73:29:1F:8F:8C:D4:83:1F:92:4F:C7
</span></code></pre></td></tr></table></div></figure>


<p>sign the cert:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@pc119:~/Code/herokublog# sudo puppet cert sign pc121
</span><span class='line'>Notice: Signed certificate request for pc121
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest pc121 at '/var/lib/puppet/ssl/ca/requests/pc121.pem'
</span></code></pre></td></tr></table></div></figure>


<p>Verify it in the client:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>clouder@pc121:/etc/puppet$ puppet agent --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/home/clouder/.puppet/var/lib]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span></code></pre></td></tr></table></div></figure>


<h3>Configuration</h3>

<p>TBD</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/16/build-fuel-icehouse-iso/">Build Fuel Icehouse Iso</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-16T15:26:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>3:26 pm</span></time>
        
         | <a href="/blog/2015/04/16/build-fuel-icehouse-iso/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Fuel6.0 didn&rsquo;t support icdhouse by default, so we have to build it manually, the steps are listed as following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>apt-get install git
</span><span class='line'>mkdir ~/fuel
</span><span class='line'>cd ~/fuel
</span><span class='line'>git clone https://github.com/stackforge/fuel-main.git
</span><span class='line'>cd fuel-main
</span><span class='line'> ./prepare-build-env.sh
</span><span class='line'>export MIRROR_BASE=http://mirror.fuel-infra.org/fwm/6.0-icehouse
</span><span class='line'>make iso
</span></code></pre></td></tr></table></div></figure>


<p>After making the iso which have icehouse will be available.</p>

<h3>TroubleShooting</h3>

<p>Some modifications should be made before we make them:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Trusty@ubuntu1204:~/code/fuel6.0/fuel-main$ git checkout stable/6.0
</span><span class='line'>Branch stable/6.0 set up to track remote branch stable/6.0 from origin.
</span><span class='line'>Switched to a new branch 'stable/6.0'
</span><span class='line'>Trusty@ubuntu1204:~/code/fuel6.0/fuel-main$ git branch
</span><span class='line'>  master
</span><span class='line'>* stable/6.0
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/15/using-fuel-for-deploying-openstack/">Using Fuel for Deploying OpenStack</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-15T18:47:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>6:47 pm</span></time>
        
         | <a href="/blog/2015/04/15/using-fuel-for-deploying-openstack/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Network Configuration</h3>

<p>Fuel network configuration is listed as following pictures:   <br/>
PXE network, for using fuel controller to control all of the nodes, 10.20.0.0/24:  <br/>
<img src="/images/2015_04_15_18_48_35_529x382.jpg" alt="/images/2015_04_15_18_48_35_529x382.jpg" />   <br/>
Public network, or floating ip network 172.16.0.0/24
<img src="/images/2015_04_15_18_50_48_527x361.jpg" alt="/images/2015_04_15_18_50_48_527x361.jpg" />  <br/>
Admin network, 192.168.0.0/24:  <br/>
<img src="/images/2015_04_15_18_51_47_533x329.jpg" alt="/images/2015_04_15_18_51_47_533x329.jpg" /></p>

<h3>Fuel Controller Installation</h3>

<p>Create a virtual machine, which have 2-Core, 3072MB Memory, and 100G Hard-disk, 3 ethernet port available for using, startup using the iso file, and then beging installing.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/15/fuel-build-issues/">Fuel Build Issues</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-15T14:07:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>2:07 pm</span></time>
        
         | <a href="/blog/2015/04/15/fuel-build-issues/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I started to deploy OpenContrail use fuel, so following are some tips for building the plugins.</p>

<h3>Fule-Plugin-Builder</h3>

<p>I encounter following errors when building the plugins of the contrail:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># fuel-plugin-builder --build ./
</span><span class='line'>Unexpected error
</span><span class='line'>Wrong package version "2.0.0"
</span></code></pre></td></tr></table></div></figure>


<p>This is because the FPB on PyPI is too old for building the 2.0.0 version of the fuel-plugins.  <br/>
Work-around is we manually create the fpb via following steps:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># git clone https://github.com/stackforge/fuel-plugins
</span><span class='line'># cd fuel-plugins/fuel_plugin_builder
</span><span class='line'># python setup.py sdist
</span><span class='line'># pip install dist/fuel-plugin-builder-2.0.0.dev.tar.gz
</span></code></pre></td></tr></table></div></figure>


<p>Now your fpb could build 2.0.0 version of the packages.</p>

<h3>Build Fuel Contrail plugin</h3>

<p>First we install following packages on Ubuntu.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># sudo apt-get install createrepo rpm dpkg-dev
</span><span class='line'># easy_install pip
</span><span class='line'># pip install fuel-plugin-builder
</span></code></pre></td></tr></table></div></figure>


<p>But notice the fuel-plugin-builder is too old in pip repository, so use the git version instead.   <br/>
Or in CentOS, you could install fuel-plugin-build via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum install createrepo rpm dpkg-devel
</span><span class='line'># pip install fuel-plugin-builder
</span></code></pre></td></tr></table></div></figure>


<p>Retrive the source code and build it via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># git clone https://github.com/stackforge/fuel-plugin-contrail
</span><span class='line'># cd fuel-plugin-contrail/
</span><span class='line'># fpb --build . --debug
</span><span class='line'>[root:/home/juju/Code/fuel-plugin-contrail]# ls
</span><span class='line'>contrail-1.0-1.0.0-0.noarch.rpm  LICENSE         repositories
</span><span class='line'>deployment_scripts               metadata.yaml   specs
</span><span class='line'>environment_config.yaml          pre_build_hook  tasks.yaml
</span><span class='line'>install.sh                       README.md
</span></code></pre></td></tr></table></div></figure>


<p>Once the contrail-1.0xxxx.rpm is available it indicates the plugin is available for fuel to use.   <br/>
Notice this plugin should be compatible for Mirantis Fuel 6.1 and Juniper Contrail 2.01.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/14/an-zhuang-icehouse-at-ubuntu14-dot-04-7/">安装Icehouse@Ubuntu14.04(7)</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-14T12:11:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>12:11 pm</span></time>
        
         | <a href="/blog/2015/04/14/an-zhuang-icehouse-at-ubuntu14-dot-04-7/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>接下来在OpenStack Icehouse的基础上，部署OpenContrail, OpenContrail能提供更为强大的网络功能。  <br/>
首先从Juniper的官网上下载安装文件:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb
</span></code></pre></td></tr></table></div></figure>


<p>Contrail可以被安装到已经部署好的OpenStack环境中，只要在安装Contrail的时候，根据已有的OpenStack组件的部署情况作相应的调整就可以。</p>

<h3>Hook</h3>

<p>Contrail用到的钩子(Hook)有：  <br/>
<code>core_plugin</code> &ndash; 它被用在neutron的配置中，用于指向ContrailPlugin组件。  <br/>
<code>libvirt_vif_driver</code> &ndash; 它被用在nova计算节点配置中，用来指向Contrail的VRouterVIFDriver.  <br/>
<code>MQ broker IP and Port</code> &ndash; 如果现有的OpenStack提供RabbitMQ那么将相应的IP和端口在neutron和nova的配置中指过去。</p>

<h3>Contrial部署涉及组建</h3>

<p>列举如下，对应的文件需要做修改，或者创建。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>api_service.conf - This file needs to be edited to provide details of existing OpenStack keystone.
</span><span class='line'>plugin.ini - This file needs proper keystone URL, token and credentials.
</span><span class='line'>neutron.conf - This file needs auth_host credentials to connect OpenStack keystone.
</span><span class='line'>config.global.js - This file contains IP and PORT for image (glance), compute (nova), identity (keystone), storage (cinder)
</span><span class='line'>OpenStack controller nova config to point to Contrail neutron
</span><span class='line'>OpenStack controller neuron service endpoint to point to contrail neutron.
</span></code></pre></td></tr></table></div></figure>


<p>为了让来之不易的OpenStack不至于被毁掉，建议先做好备份。因为接下来就要对已经部署好的节点做各种操作了。</p>

<h3>干掉OVS</h3>

<p>Make sure to remove existing OpenStack OVS installed modules and config.
首先，在DashBoard里干掉所有的网络配置(网络/路由等）。</p>

<h4>Network节点移除OpenVSwitch</h4>

<p>更改Network节点的网络配置，取消br-ex的配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# vim /etc/network/interfaces
</span><span class='line'>auto eth2
</span><span class='line'>iface eth2 inet static
</span><span class='line'>address 10.22.22.212
</span><span class='line'>netmask 255.255.255.0
</span><span class='line'>
</span><span class='line'>#iface eth2 inet manual
</span><span class='line'>#iface br-ex inet static
</span><span class='line'>#address 10.22.22.212
</span><span class='line'>#netmask 255.255.255.0
</span><span class='line'>## gateway 10.22.22.1
</span><span class='line'>#bridge_ports eth2
</span><span class='line'>#bridge_stp off
</span><span class='line'>#auto br-ex
</span></code></pre></td></tr></table></div></figure>


<p>移除br-ex设备，并重启Network节点:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# ovs-vsctl del-port br-ex eth2
</span><span class='line'>root@JunoNetwork:~# ovs-vsctl del-br br-ex
</span><span class='line'>root@JunoNetwork:~# reboot
</span></code></pre></td></tr></table></div></figure>


<p>注释掉关于ML2服务配置并重新启动服务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# cat /etc/neutron/plugins/ml2/ml2_conf.ini| grep -i "^###"
</span><span class='line'>### type_drivers = flat,gre
</span><span class='line'>### tenant_network_types = gre
</span><span class='line'>### mechanism_drivers = openvswitch
</span><span class='line'>### tunnel_id_ranges = 1:1000
</span><span class='line'>### enable_security_group = True
</span><span class='line'>### firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
</span><span class='line'>### enable_security_group = True
</span><span class='line'>### [ovs]
</span><span class='line'>### local_ip = 10.19.19.212
</span><span class='line'>### tunnel_type = gre
</span><span class='line'>### enable_tunneling = True
</span><span class='line'>root@JunoNetwork:~# service openvswitch-switch restart
</span></code></pre></td></tr></table></div></figure>


<p>注释掉关于metadata的相关配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# cat /etc/neutron/metadata_agent.ini | grep -i "^###"
</span><span class='line'>### auth_url = http://10.17.17.211:5000/v2.0
</span><span class='line'>### auth_region = regionOne
</span><span class='line'>### admin_tenant_name = service
</span><span class='line'>### admin_user = neutron
</span><span class='line'>### admin_password = engine
</span><span class='line'>### nova_metadata_ip = 10.17.17.211
</span><span class='line'>### metadata_proxy_shared_secret = engine
</span></code></pre></td></tr></table></div></figure>


<p>回到Controller节点，同样注释掉metadata的配置:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# cat /etc/nova/nova.conf | grep -i "^###"
</span><span class='line'>### service_neutron_metadata_proxy = true
</span><span class='line'>### metadata_proxy_shared_secret = engine
</span><span class='line'>### neutron_metadata_proxy_shared_secret = engine
</span></code></pre></td></tr></table></div></figure>


<p>移除DHCP相关配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# cat /etc/neutron/dhcp_agent.ini | grep -i "^###"
</span><span class='line'>### interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
</span><span class='line'>### dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
</span><span class='line'>### use_namespaces = True
</span><span class='line'>### dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf
</span><span class='line'>root@JunoNetwork:~# cat /etc/neutron/dnsmasp-neutron.conf | grep -i "^###"
</span><span class='line'>### dhcp-option-force=26,1454
</span></code></pre></td></tr></table></div></figure>


<p>移除L3 agent:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# cat /etc/neutron/l3_agent.ini | grep -i "^###"
</span><span class='line'>### interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
</span><span class='line'>### use_namespaces = True
</span><span class='line'>### verbose = True
</span></code></pre></td></tr></table></div></figure>


<p>移除neutron通用组件的支持:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# cat /etc/neutron/neutron.conf | grep -i "^###"
</span><span class='line'>### rpc_backend = neutron.openstack.common.rpc.impl_kombu
</span><span class='line'>### rabbit_host = 10.17.17.211
</span><span class='line'>### rabbit_password = engine
</span><span class='line'>### core_plugin = ml2
</span><span class='line'>### service_plugins = router
</span><span class='line'>### allow_overlapping_ips = True
</span><span class='line'>### verbose = True
</span><span class='line'>### auth_strategy = keystone
</span><span class='line'>### auth_uri = http://10.17.17.211:5000
</span><span class='line'>### auth_host = 10.17.17.211
</span><span class='line'>### auth_port = 35357
</span><span class='line'>### auth_protocol = http
</span><span class='line'>### admin_tenant_name = service
</span><span class='line'>### admin_user = neutron
</span><span class='line'>### admin_password = engine
</span></code></pre></td></tr></table></div></figure>


<p>移除已经安装的vswitch相关的包:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoNetwork:~# apt-get purge neutron-plugin-ml2 neutron-plugin-openvswitch-agent neutron-l3-agent neutron-dhcp-agent
</span><span class='line'>root@JunoCompute:~# apt-get purge openvswitch-common openvswitch-switch
</span><span class='line'>root@JunoCompute:~# reboot
</span></code></pre></td></tr></table></div></figure>


<h4>Compute节点移除OpenVSwitch</h4>

<p>Compute节点的服务移除：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoCompute:~# cat /etc/neutron/neutron.conf | grep -i "^###"
</span><span class='line'>[DEFAULT]
</span><span class='line'>###auth_strategy = keystone
</span><span class='line'>###rpc_backend = neutron.openstack.common.rpc.impl_kombu
</span><span class='line'>###rabbit_host = 10.17.17.211
</span><span class='line'>###rabbit_password = engine
</span><span class='line'>###core_plugin = ml2
</span><span class='line'>###service_plugins = router
</span><span class='line'>###allow_overlapping_ips = True
</span><span class='line'>###verbose = True
</span><span class='line'>[keystone_authtoken]
</span><span class='line'>### auth_uri = http://10.17.17.211:5000
</span><span class='line'>### auth_host = 10.17.17.211
</span><span class='line'>### auth_port = 35357
</span><span class='line'>### auth_protocol = http
</span><span class='line'>### admin_tenant_name = service
</span><span class='line'>### admin_user = neutron
</span><span class='line'>### admin_password = engine
</span><span class='line'>### signing_dir = $state_path/keystone-signing
</span><span class='line'>root@JunoCompute:~# cat /etc/neutron/plugins/ml2/ml2_conf.ini | grep -i "^###"
</span><span class='line'>### type_drivers = gre
</span><span class='line'>### tenant_network_types = gre
</span><span class='line'>### mechanism_drivers = openvswitch
</span><span class='line'>### tunnel_id_ranges = 1:1000
</span><span class='line'>### firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
</span><span class='line'>### enable_security_group = True
</span><span class='line'>### [ovs]
</span><span class='line'>### local_ip = 10.19.19.213
</span><span class='line'>### tunnel_type = gre
</span><span class='line'>### enable_tunneling = True
</span></code></pre></td></tr></table></div></figure>


<p>注释完毕后，重新启动服务:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoCompute:~# service nova-compute restart
</span><span class='line'>root@JunoCompute:~# service neutron-plugin-openvswitch-agent restart
</span><span class='line'>root@JunoCompute:~# service openvswitch-switch restart
</span></code></pre></td></tr></table></div></figure>


<p>Compute节点上的nova不再使用neutron作为网络管理器:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoCompute:~# cat /etc/nova/nova.conf | grep -i "^###"
</span><span class='line'>### network_api_class = nova.network.neutronv2.api.API
</span><span class='line'>### neutron_url = http://10.17.17.211:9696
</span><span class='line'>### neutron_auth_strategy = keystone
</span><span class='line'>### neutron_admin_tenant_name = service
</span><span class='line'>### neutron_admin_username = neutron
</span><span class='line'>### neutron_admin_password = engine
</span><span class='line'>### neutron_admin_auth_url = http://10.17.17.211:35357/v2.0
</span><span class='line'>### linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
</span><span class='line'>### firewall_driver = nova.virt.firewall.NoopFirewallDriver
</span><span class='line'>### security_group_api = neutron
</span><span class='line'>root@JunoCompute:~# service nova-compute restart
</span></code></pre></td></tr></table></div></figure>


<p>在Compute节点上,移除已经安装的openvswitch的包:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoCompute:~# apt-get purge neutron-plugin-ml2 neutron-plugin-openvswitch-agent openvswitch-datapath-dkms
</span><span class='line'>root@JunoCompute:~# apt-get purge openvswitch-common openvswitch-switch
</span><span class='line'>root@JunoCompute:~# reboot
</span></code></pre></td></tr></table></div></figure>


<p>检查状态,确保服务已经被移除:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoCompute:~# service openvswitch-switch status
</span><span class='line'>openvswitch-switch: unrecognized service
</span><span class='line'>root@JunoCompute:~# service neutron-plugin-openvswitch-agent status
</span><span class='line'>neutron-plugin-openvswitch-agent: unrecognized service
</span></code></pre></td></tr></table></div></figure>


<h4>Controller节点上移除OpenVSwitch</h4>

<p>移除nova配置中关于neutron的条目：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# cat /etc/nova/nova.conf | grep -i "^###"
</span><span class='line'>### service_neutron_metadata_proxy = true
</span><span class='line'>### metadata_proxy_shared_secret = engine
</span><span class='line'>### neutron_metadata_proxy_shared_secret = engine
</span><span class='line'>### network_api_class = nova.network.neutronv2.api.API
</span><span class='line'>### neutron_url = http://10.17.17.211:9696
</span><span class='line'>### neutron_auth_strategy = keystone
</span><span class='line'>### neutron_admin_tenant_name = service
</span><span class='line'>### neutron_admin_username = neutron
</span><span class='line'>### neutron_admin_password = engine
</span><span class='line'>### neutron_admin_auth_url = http://10.17.17.211:35357/v2.0
</span><span class='line'>### linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
</span><span class='line'>### firewall_driver = nova.virt.firewall.NoopFirewallDriver
</span><span class='line'>### security_group_api = neutron
</span></code></pre></td></tr></table></div></figure>


<p>移除对于ML2插件的支持:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# cat /etc/neutron/plugins/ml2/ml2_conf.ini | grep -i "^###"
</span><span class='line'>### type_drivers = flat,gre
</span><span class='line'>### tenant_network_types = gre
</span><span class='line'>### mechanism_drivers = openvswitch
</span><span class='line'>### tunnel_id_ranges = 1:1000
</span><span class='line'>### firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
</span><span class='line'>### enable_security_group = True
</span></code></pre></td></tr></table></div></figure>


<p>移除neutron中配置:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# cat /etc/neutron/neutron.conf | grep -i "^###"
</span><span class='line'>### rpc_backend = neutron.openstack.common.rpc.impl_kombu
</span><span class='line'>### rabbit_host = 10.17.17.211
</span><span class='line'>### rabbit_password = engine
</span><span class='line'>### notify_nova_on_port_status_changes = True
</span><span class='line'>### notify_nova_on_port_data_changes = True
</span><span class='line'>### nova_url = http://10.17.17.211:8774/v2
</span><span class='line'>### nova_admin_username = nova
</span><span class='line'>### nova_admin_tenant_id = 4b22bf4e6a68419aa91da6e0ffaca2dc
</span><span class='line'>### nova_admin_password = engine
</span><span class='line'>### nova_admin_auth_url = http://10.17.17.211:35357/v2.0
</span><span class='line'>### nova_region_name = regionOne
</span><span class='line'>### core_plugin = ml2
</span><span class='line'>### service_plugins = router
</span><span class='line'>### allow_overlapping_ips = True
</span><span class='line'>### auth_strategy = keystone
</span><span class='line'>### auth_uri = http://10.17.17.211:5000
</span><span class='line'>### auth_host = 10.17.17.211
</span><span class='line'>### auth_port = 35357
</span><span class='line'>### auth_protocol = http
</span><span class='line'>### admin_tenant_name = service
</span><span class='line'>### admin_user = neutron
</span><span class='line'>### admin_password = engine
</span><span class='line'>### connection = mysql://neutron:engine@10.17.17.211/neutron
</span></code></pre></td></tr></table></div></figure>


<p>删除ml2插件:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# apt-get purge neutron-plugin-ml2
</span></code></pre></td></tr></table></div></figure>


<p>测试，由于连验证都没法通过，所以会返回错误，当然你的DashBoard也会有错误,暂时没办法访问了。:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~#  neutron agent-list
</span><span class='line'>Authentication required
</span></code></pre></td></tr></table></div></figure>


<h3>Contrail</h3>

<h4>创建机器</h4>

<p>4G内存，2核CPU，同时连接到所有网络(10.17.17.0/24, 10.19.19.0/24, 10.22.22.0/24):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root:/home/juju/img/OpenStack]# qemu-img create -f qcow2 -b ./UbuntuBase1404.qcow2  JunoContrail.qcow2
</span></code></pre></td></tr></table></div></figure>


<p>配置网络接口, hosts, hostname等:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoContrail:~# cat /etc/hostname 
</span><span class='line'>JunoContrail
</span><span class='line'>root@JunoContrail:~# cat /etc/hosts
</span><span class='line'>10.17.17.211    JunoController
</span><span class='line'>10.17.17.212    JunoNetwork
</span><span class='line'>10.17.17.213    JunoCompute
</span><span class='line'>10.17.17.214    JunoContrail
</span><span class='line'>root@JunoContrail:~# cat /etc/network/interfaces
</span><span class='line'>auto lo
</span><span class='line'>iface lo inet loopback
</span><span class='line'>
</span><span class='line'># The primary network interface
</span><span class='line'>auto eth0
</span><span class='line'>iface eth0 inet static
</span><span class='line'>address 10.17.17.214
</span><span class='line'>netmask 255.255.255.0
</span><span class='line'>gateway 10.17.17.1
</span><span class='line'>dns-nameservers 114.114.114.114
</span><span class='line'>
</span><span class='line'># Network, have the tunnel, which locates at the 10.19.19.0/24
</span><span class='line'>auto eth1
</span><span class='line'>iface eth1 inet static
</span><span class='line'>address 10.19.19.214
</span><span class='line'>netmask 255.255.255.0
</span><span class='line'>up route add -net 10.19.19.0/24 dev eth1
</span><span class='line'>
</span><span class='line'>auto eth2
</span><span class='line'>iface eth2 inet static
</span><span class='line'>address 10.22.22.214
</span><span class='line'>netmask 255.255.255.0
</span></code></pre></td></tr></table></div></figure>


<p>得到包，并且安装之:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoContrail:~# wget http://xxxxxxxxxxxxxx/contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb 
</span><span class='line'>root@JunoContrail:~# dpkg -i contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb 
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>直接安装会出错，为了避免，直接手动安装build-essential和python-pip:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoContrail:~# apt-get install build-essential python-pip
</span></code></pre></td></tr></table></div></figure>


<p>而后手动开始安装contrail:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoContrail:/opt/contrail/contrail_packages# ./setup.sh 
</span></code></pre></td></tr></table></div></figure>


<p>使用模板生成testbed.py文件:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoContrail:/opt/contrail# cp /opt/contrail/utils/fabfile/testbeds/testbed_multibox_example.py /opt/contrail/utils/fabfile/testbeds/testbed.py
</span></code></pre></td></tr></table></div></figure>


<p>需要配置ntp，加入到本地的NTP网络里:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoContrail:/opt/contrail/utils# apt-get -y install ntp
</span><span class='line'>root@JunoContrail:/opt/contrail/utils# vim /etc/ntp.conf 
</span><span class='line'>server 10.17.17.211 iburst
</span><span class='line'>root@JunoContrail:/opt/contrail/utils# service ntp restart
</span><span class='line'> * Stopping NTP server ntpd
</span><span class='line'>   ...done.
</span><span class='line'>ntpq * Starting NTP server ntpd
</span><span class='line'>   ...done.
</span><span class='line'>root@JunoContrail:/opt/contrail/utils# ntpq -c peers
</span><span class='line'>     remote           refid      st t when poll reach   delay   offset  jitter
</span><span class='line'>==============================================================================
</span><span class='line'> JunoController  202.112.29.82    3 u    1   64    1    0.312   33.463   0.000
</span></code></pre></td></tr></table></div></figure>


<p>配置testbed.py文件，更改后的例子如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>TBD........
</span></code></pre></td></tr></table></div></figure>


<p>安装的时候，出现问题，需要切换到最旧的原始安装的Ubuntu1404. 切换前，记下已有的步骤:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd /opt/contrail/utils/
</span><span class='line'>$ fab install_pkg_all:/root/contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb 
</span><span class='line'>$ fab -c fabrc install_without_openstack:no
</span></code></pre></td></tr></table></div></figure>


<p>切换:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root:/home/juju/img/OpenStack]# mv JunoContrail.qcow2 JunoContrail.qcow2_Deploy_Failed_Too_new
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/14/an-zhuang-icehouse-at-ubuntu14-dot-04-6/">安装Icehouse@Ubuntu14.04(6)</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-14T11:39:00+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>11:39 am</span></time>
        
         | <a href="/blog/2015/04/14/an-zhuang-icehouse-at-ubuntu14-dot-04-6/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>这里我们安装horizon服务，使得我们对OpenStack的管理做到可视化.</p>

<h3>安装horizon</h3>

<p>在Controller节点上，安装需要的包:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# apt-get -y install openstack-Trustyboard apache2 libapache2-mod-wsgi memcached python-memcache
</span></code></pre></td></tr></table></div></figure>


<p>建议删除ubuntu提供的主题，这个主题会使得一些翻译失效:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# apt-get remove --purge openstack-Trustyboard-ubuntu-theme
</span></code></pre></td></tr></table></div></figure>


<p>配置DashBoard的本地配置文件:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# vim /etc/openstack-Trustyboard/local_settings.py 
</span><span class='line'>    OPENSTACK_HOST = "10.17.17.211"
</span><span class='line'>    TIME_ZONE = "Asia/Shanghai"
</span></code></pre></td></tr></table></div></figure>


<p>重新启动服务:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# service apache2 restart
</span><span class='line'>root@JunoController:~# service memcached restart
</span></code></pre></td></tr></table></div></figure>


<p>访问<code>http://10.17.17.211/horizon</code>登入到DashBoard以管理OpenStack.</p>

<h3>查看OpenStack版本</h3>

<p>节点机器起名错误，应该是IcehouseController/IcehouseCompute/IcehouseNetwork之类，但是这里可以通过以下命令来查看OpenStack安装的版本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@JunoController:~# dpkg -l | grep nova-common
</span><span class='line'>ii  nova-common                         1:2014.1.4-0ubuntu2                   all          OpenStack Compute - common files
</span></code></pre></td></tr></table></div></figure>


<p><code>2014.1.4</code>就是我们要关注的版本信息，在:  <br/>
<a href="https://wiki.openstack.org/wiki/Releases">https://wiki.openstack.org/wiki/Releases</a>  <br/>
可以查到，它属于Icehouse.  <br/>
<img src="/images/2015_04_14_11_58_39_490x203.jpg" alt="/images/2015_04_14_11_58_39_490x203.jpg" /></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/10">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/8">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/08/13/preseed-partition-configuration/">Preseed Partition Configuration</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/13/build-nbd-kernel-module-on-centos7/">Build Nbd Kernel Module on CentOS7</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/13/automatically-create-virtual-machine/">Automatically Create Virtual Machine</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/12/create-channel-slash-repository-in-spacewalk/">Create Channel/Repository in SpaceWalk</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/12/trouble-shooting-on-spacewalk-osad-on-ubuntu-clients/">Trouble Shooting on SpaceWalk OSAD on Ubuntu Clients</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Dash -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'dashsagittariussglory';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
