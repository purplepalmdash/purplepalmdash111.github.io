<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.17-DEV" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Dash &middot; Dash</title>

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/poole.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde-a.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/custom-additions.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/highlight/googlecode.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124">
  <link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel="icon">

  
  
  
  <link href="http://purplepalmdash.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Dash &middot; Dash" />

  <meta name="description" content="Get busy living, or get busy dying.">
  <meta name="keywords" content="unix,virtualization,embedded,linux">
  <link rel="author" href="http://plus.google.com/106572959364703833986">
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-42175003-1', 'auto');
      ga('send', 'pageview');
  </script>

</head>
<body class="theme-base-0c">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <img src="https://www.gravatar.com/avatar/49381c0004d32c0a4296b92dff0c0ae5?s=200" alt="gravatar">
      <h1><a href="http://purplepalmdash.github.io/">Get busy living, or get busy dying.</a></h1>
      <a href="http://purplepalmdash.github.io/"><p>Dash</p></a>
    </div>

    <ul class="sidebar-nav">
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/">First Page</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/post/">All Posts</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/linux/">Linux</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/embedded/">Embedded System</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="https://github.com/purplepalmdash"><i class="fa fa-github-square fa-3x"></i></a>
      
      <a href="https://cn.linkedin.com/in/yang-feipeng-1b909319"><i class="fa fa-linkedin-square fa-3x"></i></a>
      <a href="https://plus.google.com/u/0/106572959364703833986"><i class="fa fa-google-plus-square fa-3x"></i></a>
      <a href="https://www.facebook.com/yang.feipeng"><i class="fa fa-facebook-square fa-3x"></i></a>
      <a href="https://twitter.com/dashwillfly"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="http://purplepalmdash.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-3/">安装Icehouse@Ubuntu14.04(3)</a>
      </h1>
      <span class="post-date">Apr 13, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-3/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">virtualization</a>
        
      </span>
      
      

<p>Image Service 用于提供给用户用于快速启动虚拟机的镜像文件，这样的服务称为glance服务。</p>

<h3 id="glance服务数据库设定">Glance服务数据库设定</h3>

<p>在mysql中创建glance数据库:</p>

<pre><code>root@JunoController:~#  mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 33
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE glance;
Query OK, 1 row affected (0.01 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'xxxx'
    -&gt; ;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'xxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; quit;
Bye

</code></pre>

<h3 id="创建glance的user-role-tenant权限">创建Glance的user/role/tenant权限</h3>

<p>用admin的权限，创建以下权限：</p>

<pre><code>root@JunoController:~#  source ~/openstack/admin-openrc.sh

</code></pre>

<p>创建glance用户:</p>

<pre><code>root@JunoController:~# keystone user-create --name glance --pass engine
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | c706febbcc8843fb97383c9fdfba6214 |
|   name   |              glance              |
| username |              glance              |
+----------+----------------------------------+

</code></pre>

<p>用户glance属于admin角色，使用service tanant:</p>

<pre><code>keystone user-role-add --user glance --tenant service --role admin

</code></pre>

<p>在keystone注册glance服务:</p>

<pre><code>root@JunoController:~# keystone service-create --name glance --type image --description &quot;OpenStack Image Service&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |     OpenStack Image Service      |
|   enabled   |               True               |
|      id     | 3d52d2992b9f423eb9868304e4405fab |
|     name    |              glance              |
|     type    |              image               |
+-------------+----------------------------------+

</code></pre>

<p>在keystone创建服务的end-point:</p>

<pre><code>root@JunoController:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ image / {print $2}') --publicurl http://10.17.17.211:9292 --internalurl http://10.17.17.211:9292 --adminurl http://10.17.17.211:9292 --region regionOne
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
|   adminurl  |     http://10.17.17.211:9292     |
|      id     | f44400bebc07408d8e0f4e70a0d18475 |
| internalurl |     http://10.17.17.211:9292     |
|  publicurl  |     http://10.17.17.211:9292     |
|    region   |            regionOne             |
|  service_id | 3d52d2992b9f423eb9868304e4405fab |
+-------------+----------------------------------+

</code></pre>

<h3 id="安装glance服务">安装Glance服务</h3>

<p>安装:</p>

<pre><code>apt-get -y install glance python-glanceclient

</code></pre>

<p>配置:</p>

<pre><code># vim /etc/glance/glance-api.conf
[database]
# sqlite_db = /var/lib/glance/glance.sqlite
backend = sqlalchemy
connection = mysql://glance:engine@10.17.17.211/glance

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = glance
admin_password = engine
#  vim /etc/glance/glance-registry.conf
[database]
# The file name to use with SQLite (string value)
#sqlite_db = /var/lib/glance/glance.sqlite
backend = sqlalchemy
connection = mysql://glance:engine@10.17.17.211/glance

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = glance
admin_password = engine
# rm -f /var/lib/glance/glance.sqlite
# su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance

</code></pre>

<p>这里会碰到一个问题，解决方案如下:</p>

<pre><code>root@JunoController:~# su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance
2015-04-13 17:20:22.637 9455 CRITICAL glance [-] ValueError: Tables &quot;migrate_version&quot; have non utf8 collation, please make sure all tables are CHARSET=utf8

root@JunoController:~# mysql -u root -p glance
Enter password: 
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 29
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [glance]&gt; alter table migrate_version convert to character set utf8 collate utf8_unicode_ci;
Query OK, 1 row affected (0.09 sec)                
Records: 1  Duplicates: 0  Warnings: 0

MariaDB [glance]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [glance]&gt; quit;
Bye

</code></pre>

<p>重启服务，</p>

<pre><code>root@JunoController:~# service glance-registry restart
root@JunoController:~# service glance-api restart

</code></pre>

<h3 id="验证glance服务">验证Glance服务</h3>

<p>首先下载镜像:</p>

<pre><code># wget http://cdn.download.cirros-cloud.net/0.3.3/cirros-0.3.3-x86_64-disk.img

</code></pre>

<p>创建Glance可见镜像:</p>

<pre><code># glance image-create --name &quot;cirros-0.3.3-x86_64&quot; --file cirros-0.3.3-x86_64-disk.img --disk-format qcow2 --container-format bare --is-public True --progress
[=============================&gt;] 100%
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 133eae9fb1c98f45894a4e60d8736619     |
| container_format | bare                                 |
| created_at       | 2015-04-13T09:27:54                  |
| deleted          | False                                |
| deleted_at       | None                                 |
| disk_format      | qcow2                                |
| id               | 68f14900-8b25-4329-ad56-8fbd497c6812 |
| is_public        | True                                 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | cirros-0.3.3-x86_64                  |
| owner            | ea1f0a6b15dc4796958f087c38756ed1     |
| protected        | False                                |
| size             | 13200896                             |
| status           | active                               |
| updated_at       | 2015-04-13T09:27:54                  |
| virtual_size     | None                                 |
+------------------+--------------------------------------+

</code></pre>

<p>检查镜像:</p>

<pre><code>root@JunoController:~# ls /var/lib/glance/images/
68f14900-8b25-4329-ad56-8fbd497c6812

</code></pre>

<p>列出可用镜像:</p>

<pre><code>root@JunoController:~# glance image-list
+--------------------------------------+---------------------+-------------+------------------+----------+--------+
| ID                                   | Name                | Disk Format | Container Format | Size     | Status |
+--------------------------------------+---------------------+-------------+------------------+----------+--------+
| 68f14900-8b25-4329-ad56-8fbd497c6812 | cirros-0.3.3-x86_64 | qcow2       | bare             | 13200896 | active |
+--------------------------------------+---------------------+-------------+------------------+----------+--------+

</code></pre>

<p>好了，现在glance服务可以使用了，接下来将创建compute节点和网络节点。</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-4/">安装Icehouse@Ubuntu14.04(4)</a>
      </h1>
      <span class="post-date">Apr 13, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-4/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">virtualization</a>
        
      </span>
      
      

<p>这里将配置计算节点。计算节点我们使用了一台2G内存的虚拟机，并使用了嵌套虚拟化，可以通过<code>lscpu</code>来看到CPU的VMX/VT-X标志都已经被下发到虚拟机中。</p>

<h3 id="数据库准备">数据库准备</h3>

<p>使用下列命令来创建nova所需数据库:</p>

<pre><code>root@JunoController:~# mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 35
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE nova;
Query OK, 1 row affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'xxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'xxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; quit
Bye

</code></pre>

<h3 id="nova用户">nova用户</h3>

<p>创建nova用户:</p>

<pre><code>root@JunoController:~# source ~/openstack/admin-openrc.sh
root@JunoController:~# keystone user-create --name nova --pass xxxx
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | 845c22d1a781458a8b28ba54534b73dd |
|   name   |               nova               |
| username |               nova               |
+----------+----------------------------------+

</code></pre>

<p>制定nova属于service tenant, 并赋予admin权限:</p>

<pre><code>root@JunoController:~# keystone user-role-add --user nova --tenant service --role admin

</code></pre>

<p>在keystone注册nova:</p>

<pre><code>root@JunoController:~# keystone service-create --name nova --type compute --description &quot;OpenStack Compute&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |        OpenStack Compute         |
|   enabled   |               True               |
|      id     | 8733caba0b9742a39ee9ac53ad4d8e27 |
|     name    |               nova               |
|     type    |             compute              |
+-------------+----------------------------------+

</code></pre>

<p>在keystone注册nova end-point:</p>

<pre><code>root@JunoController:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ compute / {print $2}') --publicurl http://10.17.17.211:8774/v2/%\(tenant_id\)s --internalurl http://10.17.17.211:8774/v2/%\(tenant_id\)s --adminurl http://10.17.17.211:8774/v2/%\(tenant_id\)s --region regionOne
+-------------+-------------------------------------------+
|   Property  |                   Value                   |
+-------------+-------------------------------------------+
|   adminurl  | http://10.17.17.211:8774/v2/%(tenant_id)s |
|      id     |      d16c91bfacf2474ebee36314535a146f     |
| internalurl | http://10.17.17.211:8774/v2/%(tenant_id)s |
|  publicurl  | http://10.17.17.211:8774/v2/%(tenant_id)s |
|    region   |                 regionOne                 |
|  service_id |      8733caba0b9742a39ee9ac53ad4d8e27     |
+-------------+-------------------------------------------+

</code></pre>

<h3 id="compute服务安装">Compute服务安装</h3>

<h4 id="controller节点配置">Controller节点配置</h4>

<p>在Controller节点上，安装以下包:</p>

<pre><code>root@JunoController:~# apt-get -y install nova-api nova-cert nova-conductor nova-consoleauth nova-novncproxy nova-scheduler python-novaclient

</code></pre>

<p>配置nova所需的配置文件:</p>

<pre><code># vim /etc/nova/nova.conf
[database]
connection = mysql://nova:xxxxx@10.17.17.211/nova

[DEFAULT]
....
rpc_backend = rabbit
rabbit_host = 10.17.17.211
rabbit_password = xxxxxx
my_ip=10.17.17.211
vncserver_listen = 0.0.0.0
vncserver_proxyclient_address = 10.17.17.211
auth_strategy = keystone 

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = nova
admin_password = xxxx
[glance]
host=10.17.17.211

</code></pre>

<p>删除sqlite3数据库:</p>

<pre><code>root@JunoController:~# rm /var/lib/nova/nova.sqlite 

</code></pre>

<p>创建数据库：</p>

<pre><code>root@JunoController:~# su -s /bin/sh -c &quot;nova-manage db sync&quot; nova

</code></pre>

<p>重启服务，使用nova检查本机可用镜像情况:</p>

<pre><code>root@JunoController:~# service nova-api restart
root@JunoController:~# service nova-cert restart
root@JunoController:~#  service nova-consoleauth restart
root@JunoController:~# service nova-scheduler restart
root@JunoController:~# service nova-conductor restart
root@JunoController:~# service nova-novncproxy restart
root@JunoController:~# nova image-list
+--------------------------------------+---------------------+--------+--------+
| ID                                   | Name                | Status | Server |
+--------------------------------------+---------------------+--------+--------+
| 68f14900-8b25-4329-ad56-8fbd497c6812 | cirros-0.3.3-x86_64 | ACTIVE |        |
+--------------------------------------+---------------------+--------+--------+

</code></pre>

<h4 id="compute节点安装">Compute节点安装</h4>

<p>安装下列包:</p>

<pre><code>root@JunoCompute:~#  apt-get -y install nova-compute sysfsutils

</code></pre>

<p>配置:</p>

<pre><code>root@JunoCompute:~# vim /etc/nova/nova.conf 
[DEFAULT]
......
auth_strategy = keystone
rpc_backend = rabbit
rabbit_host = 10.17.17.211
rabbit_password = xxxx
my_ip = 10.17.17.213
vnc_enabled = True
vncserver_listen = 0.0.0.0
vncserver_proxyclient_address = 10.17.17.213
novncproxy_base_url = http://10.17.17.211:6080/vnc_auto.html
glance_host = 10.17.17.211

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = nova
admin_password = xxxx

[database]
#The SQLAlchemy connection string used to connect to the database
connection = mysql://nova:xxxx@10.17.17.211/nova
[glance]
host=10.17.17.211

</code></pre>

<p>看cpu硬件是否支持硬件加速:</p>

<pre><code>root@JunoCompute:~# egrep -c '(vmx|svm)' /proc/cpuinfo
2

</code></pre>

<p>如果支持加速，则配置nova-compute.conf为:</p>

<pre><code>root@JunoCompute:~# cat /etc/nova/nova-compute.conf
[libvirt]
virt_type=kvm

</code></pre>

<p>删除不需要的nova.sqlite文件:</p>

<pre><code>root@JunoCompute:~# rm -f /var/lib/nova/nova.sqlite 

</code></pre>

<p>重起nova服务:</p>

<pre><code>root@JunoCompute:~# service nova-compute restart

</code></pre>

<h3 id="验证">验证</h3>

<p>在控制节点上,列出所有的service:</p>

<pre><code>root@JunoController:~# nova service-list
+------------------+----------------+----------+---------+-------+----------------------------+-----------------+
| Binary           | Host           | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+------------------+----------------+----------+---------+-------+----------------------------+-----------------+
| nova-cert        | JunoController | internal | enabled | up    | 2015-04-13T10:16:10.000000 | -               |
| nova-consoleauth | JunoController | internal | enabled | up    | 2015-04-13T10:16:12.000000 | -               |
| nova-scheduler   | JunoController | internal | enabled | up    | 2015-04-13T10:16:05.000000 | -               |
| nova-conductor   | JunoController | internal | enabled | up    | 2015-04-13T10:16:08.000000 | -               |
| nova-compute     | JunoCompute    | nova     | enabled | up    | 2015-04-13T10:16:09.000000 | -               |
+------------------+----------------+----------+---------+-------+----------------------------+-----------------+

</code></pre>

<p>现在compute节点已经配置完了，接下来可以配置网络节点。配置完网络节点后，就可以启动虚拟机了。</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-5/">安装Icehouse@Ubuntu14.04(5)</a>
      </h1>
      <span class="post-date">Apr 13, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-5/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">virtualization</a>
        
      </span>
      
      

<h3 id="neutron-database">Neutron Database</h3>

<p>Follow following steps for create the database:</p>

<pre><code>root@JunoController:~# mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 58
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE neutron;
Query OK, 1 row affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY 'xxxxx'
    -&gt; ;
Query OK, 0 rows affected (0.01 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'xxxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.01 sec)

MariaDB [(none)]&gt; quit
Bye

</code></pre>

<h3 id="keystone-items">Keystone items</h3>

<p>创建用户:</p>

<pre><code>root@JunoController:~# source ~/openstack/admin-openrc.sh
root@JunoController:~# keystone user-create --name neutron --pass xxxxx
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | a4cbae42a2164c6e9a4c05c3f6835782 |
|   name   |             neutron              |
| username |             neutron              |
+----------+----------------------------------+

</code></pre>

<p>更改权限，服务为tenant, 角色是admin:</p>

<pre><code>root@JunoController:~# keystone user-role-add --user neutron --tenant service --role admin

</code></pre>

<p>创建服务：</p>

<pre><code>root@JunoController:~# keystone service-create --name neutron --type network --description &quot;OpenStack Networking&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |       OpenStack Networking       |
|   enabled   |               True               |
|      id     | 1142b316e4e04061bb676b73d0cf6f68 |
|     name    |             neutron              |
|     type    |             network              |
+-------------+----------------------------------+

</code></pre>

<p>创建服务的end-point:</p>

<pre><code>root@JunoController:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ network / {print $2}') --publicurl http://10.17.17.211:9696 --adminurl http://10.17.17.211:9696 --internalurl http://10.17.17.211:9696 --region regionOne
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
|   adminurl  |     http://10.17.17.211:9696     |
|      id     | 77bb946d42dc4d099875ecc377510937 |
| internalurl |     http://10.17.17.211:9696     |
|  publicurl  |     http://10.17.17.211:9696     |
|    region   |            regionOne             |
|  service_id | 1142b316e4e04061bb676b73d0cf6f68 |
+-------------+----------------------------------+

</code></pre>

<h3 id="安装组件">安装组件</h3>

<p>在Controller端安装:</p>

<pre><code>root@JunoController:~#  apt-get -y install neutron-server neutron-plugin-ml2 python-neutronclient

</code></pre>

<p>取得tenant service id:</p>

<pre><code>root@JunoController:~# source ~/openstack/admin-openrc.sh
root@JunoController:~# keystone tenant-get service
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |          Service Tenant          |
|   enabled   |               True               |
|      id     | 4b22bf4e6a68419aa91da6e0ffaca2dc |
|     name    |             service              |
+-------------+----------------------------------+

</code></pre>

<p>编辑nova配置文件，修改如下：</p>

<pre><code>root@JunoController:~# vim /etc/neutron/neutron.conf
[DEFAULT]
rpc_backend = neutron.openstack.common.rpc.impl_kombu
rabbit_host = 10.17.17.211
rabbit_password = xxxxx

notify_nova_on_port_status_changes = True
notify_nova_on_port_data_changes = True
nova_url = http://10.17.17.211:8774/v2
nova_admin_username = nova
nova_admin_tenant_id = 4b22bf4e6a68419aa91da6e0ffaca2dc
nova_admin_password = xxxxx
nova_admin_auth_url = http://10.17.17.211:35357/v2.0

core_plugin = ml2
service_plugins = router
allow_overlapping_ips = True

auth_strategy = keystone

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = neutron
admin_password = xxxxx
signing_dir = $state_path/keystone-signing
[database]
connection = mysql://neutron:xxxxx@10.17.17.211/neutron

</code></pre>

<p>编辑ML2(Modular Layer2)插件， 在控制节点上：</p>

<pre><code>root@JunoController:~# vim /etc/neutron/plugins/ml2/ml2_conf.ini | more
[ml2]
type_drivers = gre
tenant_network_types = gre
mechanism_drivers = openvswitch

[ml2_type_gre]
tunnel_id_ranges = 1:1000


[securitygroup]
# Controls if neutron security group is enabled or not.
# It should be false when you use nova security group.
# enable_security_group = True
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
enable_security_group = True

</code></pre>

<p>调整Compute Service使用Neutron服务:</p>

<pre><code># vim /etc/nova/nova.conf
network_api_class = nova.network.neutronv2.api.API
neutron_url = http://10.17.17.211:9696
neutron_auth_strategy = keystone
neutron_admin_tenant_name = service
neutron_admin_username = neutron
neutron_admin_password = xxxxx
neutron_admin_auth_url = http://10.17.17.211:35357/v2.0
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver
security_group_api = neutron


</code></pre>

<p>重启服务:</p>

<pre><code># service nova-api restart
# service nova-scheduler restart
# service nova-conductor restart

</code></pre>

<p>重启网络服务:</p>

<pre><code># service neutron-server restart

</code></pre>

<p>检查是否完成的命令:</p>

<pre><code>root@JunoController:~# neutron ext-list
+-----------------------+-----------------------------------------------+
| alias                 | name                                          |
+-----------------------+-----------------------------------------------+
| security-group        | security-group                                |
| l3_agent_scheduler    | L3 Agent Scheduler                            |
| ext-gw-mode           | Neutron L3 Configurable external gateway mode |
| binding               | Port Binding                                  |
| provider              | Provider Network                              |
| agent                 | agent                                         |
| quotas                | Quota management support                      |
| dhcp_agent_scheduler  | DHCP Agent Scheduler                          |
| multi-provider        | Multi Provider Network                        |
| external-net          | Neutron external network                      |
| router                | Neutron L3 Router                             |
| allowed-address-pairs | Allowed Address Pairs                         |
| extra_dhcp_opt        | Neutron Extra DHCP opts                       |
| extraroute            | Neutron Extra Route                           |
+-----------------------+-----------------------------------------------+

</code></pre>

<p>###配置网络节点
激活以下选项:</p>

<pre><code>root@JunoNetwork:~# vim /etc/sysctl.conf
net.ipv4.ip_forward=1
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
net.bridge.bridge-nf-call-arptables=1
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1

</code></pre>

<p>提交更改(这里有错误):</p>

<pre><code>root@JunoNetwork:~# sysctl -p
net.ipv4.ip_forward = 1
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-arptables: No such file or directory
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: No such file or directory

</code></pre>

<p>安装网络组件:</p>

<pre><code>root@JunoNetwork:~# apt-get install neutron-plugin-ml2 neutron-plugin-openvswitch-agent neutron-l3-agent neutron-dhcp-agent

</code></pre>

<p>配置通用组件:</p>

<pre><code># vim /etc/neutron/neutron.conf
[DEFAULT]
rpc_backend = neutron.openstack.common.rpc.impl_kombu
rabbit_host = 10.17.17.211
rabbit_password = xxxxx
core_plugin = ml2
service_plugins = router
allow_overlapping_ips = True
verbose = True
auth_strategy = keystone

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = neutron
admin_password = xxxxx

</code></pre>

<p>编辑L3 agent:</p>

<pre><code># vim /etc/neutron/l3_agent.ini
[DEFAULT]
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
use_namespaces = True
verbose = True

</code></pre>

<p>编辑DHCP插件:</p>

<pre><code># vim /etc/neutron/dhcp_agent.ini
 [DEFAULT]
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
use_namespaces = True

</code></pre>

<p>配置DHCP：</p>

<pre><code>root@JunoNetwork:~# vim /etc/neutron/dhcp_agent.ini
[DEFAULT]
...
dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf
root@JunoNetwork:~# vim /etc/neutron/dnsmasp-neutron.conf
dhcp-option-force=26,1454

</code></pre>

<p>配置metadata agent:</p>

<pre><code>root@JunoNetwork:~# vim /etc/neutron/metadata_agent.ini
[DEFAULT]
auth_url = http://10.17.17.211:5000/v2.0
auth_region = regionOne
admin_tenant_name = service
admin_user = neutron
admin_password = xxxxx
nova_metadata_ip = 10.17.17.211
metadata_proxy_shared_secret = xxxxx

</code></pre>

<p>回到controller节点，编辑:</p>

<pre><code># vim /etc/nova/nova.conf
[DEFAULT]
...
service_neutron_metadata_proxy = true
neutron_metadata_proxy_shared_secret = xxxxx

</code></pre>

<p>重启compute api服务:</p>

<pre><code># service nva-api restart

</code></pre>

<p>配置 ml2:</p>

<pre><code>root@JunoNetwork:~# vim /etc/neutron/plugins/ml2/ml2_conf.ini 
[ml2]
type_drivers = gre
tenant_network_types = gre
mechanism_drivers = openvswitch
[ml2_type_gre]
tunnel_id_ranges = 1:1000
[ovs]
local_ip = 10.19.19.212
tunnel_type = gre
enable_tunneling = True
[securitygroup]
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
enable_security_group = True

</code></pre>

<p>重启openvswitch 服务:</p>

<pre><code>root@JunoNetwork:~# service openvswitch-switch restart

</code></pre>

<p>增加bridge配置：</p>

<pre><code>root@JunoNetwork:~# ovs-vsctl add-br br-ex
root@JunoNetwork:~# cat /etc/network/interfaces
auto eth2
iface eth2 inet manual

iface br-ex inet static
address 10.22.22.212
netmask 255.255.255.0
gateway 10.22.22.1
bridge_ports eth2
bridge_stp off
auto br-ex

</code></pre>

<p>增加桥接端口，并且重启机器:</p>

<pre><code>root@JunoNetwork:~# ovs-vsctl add-port br-ex eth2
root@JunoNetwork:~# reboot

</code></pre>

<p>###计算节点配置
更改sysctl配置:</p>

<pre><code>root@JunoCompute:~# vim /etc/sysctl.conf
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
net.bridge.bridge-nf-call-arptables=1
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
root@JunoCompute:~# sysctl -p 
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.bridge.bridge-nf-call-arptables = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1

</code></pre>

<p>安装下列包:</p>

<pre><code># apt-get install neutron-common neutron-plugin-ml2 neutron-plugin-openvswitch-agent openvswitch-datapath-dkms

</code></pre>

<p>配置compute节点上的网络通用组件:</p>

<pre><code>root@JunoCompute:~# vim /etc/neutron/neutron.conf
    [DEFAULT]
    auth_strategy = keystone
    rpc_backend = neutron.openstack.common.rpc.impl_kombu
    rabbit_host = controller
    rabbit_password = xxxx
    core_plugin = ml2
    service_plugins = router
    allow_overlapping_ips = True
    verbose = True
    [keystone_authtoken]
    auth_uri = http://10.17.17.211:5000
    auth_host = 10.17.17.211
    auth_port = 35357
    auth_protocol = http
    admin_tenant_name = service
    admin_user = neutron
    admin_password = xxxx
    signing_dir = $state_path/keystone-signing
    [database]
root@JunoCompute:~# vim /etc/neutron/plugins/ml2/ml2_conf.ini 
    [DEFAULT]
    ...
    core_plugin = ml2
    service_plugins = router
    allow_overlapping_ips = True
    [ml2]
    ...
    type_drivers = gre
    tenant_network_types = gre
    mechanism_drivers = openvswitch
    [ml2_type_gre]
    ...
    tunnel_id_ranges = 1:1000
    [ovs]
    ...
    local_ip = 10.19.19.213
    tunnel_type = gre
    enable_tunneling = True
    [securitygroup]
    ...
    firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
    enable_security_group = True
root@JunoCompute:~# service openvswitch-switch restart
root@JunoCompute:~# service nova-compute restart
root@JunoCompute:~# service neutron-plugin-openvswitch-agent restart

</code></pre>

<p>接下来我们配置Compute节点上的nova,让它使用neutron作为网络管理器.</p>

<pre><code>root@JunoCompute:~# vim /etc/nova/nova.conf 
[DEFAULT]
network_api_class = nova.network.neutronv2.api.API
neutron_url = http://10.17.17.211:9696
neutron_auth_strategy = keystone
neutron_admin_tenant_name = service
neutron_admin_username = neutron
neutron_admin_password = xxxx
neutron_admin_auth_url = http://10.17.17.211:35357/v2.0
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver
security_group_api = neutron

</code></pre>

<p>修改完毕后，重启Compute节点上的服务:</p>

<pre><code>root@JunoCompute:~# service nova-compute restart
nova-compute stop/waiting
nova-compute start/running, process 2266
root@JunoCompute:~# service neutron-plugin-openvswitch-agent restart
stop: Unknown instance: 
neutron-plugin-openvswitch-agent start/running, process 2303

</code></pre>

<p>配置Network节点的网络，因为我们需要br-ex作为对外网络的接口。<br />
配置网络如下：</p>

<pre><code># ovs-vsctl add-br br-ex
# ovs-vsctl add-port br-ex eth2
# cat /etc/network/interfaces
# 
auto eth2
iface eth2 inet manual

iface br-ex inet static
address 10.22.22.212
netmask 255.255.255.0
gateway 10.22.22.1
bridge_ports eth2
bridge_stp off
auto br-ex
# reboot

</code></pre>

<p>增加ext-net:</p>

<pre><code>root@JunoController:~# neutron net-create ext-net --shared --router:external=True
Created a new network:
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | True                                 |
| id                        | d879d5b1-f16e-4e28-beda-eb2b433e1f39 |
| name                      | ext-net                              |
| provider:network_type     | gre                                  |
| provider:physical_network |                                      |
| provider:segmentation_id  | 1                                    |
| router:external           | True                                 |
| shared                    | True                                 |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tenant_id                 | ea1f0a6b15dc4796958f087c38756ed1     |
+---------------------------+--------------------------------------+

</code></pre>

<p>外部子网：</p>

<pre><code>root@JunoController:~# neutron subnet-create ext-net --name ext-subnet --allocation-pool start=10.22.22.10,end=10.22.22.50 --disable-dhcp --gateway 10.22.22.1 --gateway 10.22.22.1 10.22.22.10/24
Created a new subnet:
+------------------+------------------------------------------------+
| Field            | Value                                          |
+------------------+------------------------------------------------+
| allocation_pools | {&quot;start&quot;: &quot;10.22.22.10&quot;, &quot;end&quot;: &quot;10.22.22.50&quot;} |
| cidr             | 10.22.22.0/24                                  |
| dns_nameservers  |                                                |
| enable_dhcp      | False                                          |
| gateway_ip       | 10.22.22.1                                     |
| host_routes      |                                                |
| id               | 3c7e2224-0979-4eb6-b95f-16401ecbfef0           |
| ip_version       | 4                                              |
| name             | ext-subnet                                     |
| network_id       | d879d5b1-f16e-4e28-beda-eb2b433e1f39           |
| tenant_id        | ea1f0a6b15dc4796958f087c38756ed1               |
+------------------+------------------------------------------------+


</code></pre>

<pre><code>root@JunoController:~# source openstack/demo-openrc.sh 
root@JunoController:~# neutron net-create demo-net
Created a new network:
+----------------+--------------------------------------+
| Field          | Value                                |
+----------------+--------------------------------------+
| admin_state_up | True                                 |
| id             | 01c966ce-88cf-43a2-a7b7-2ebf6d6b6d60 |
| name           | demo-net                             |
| shared         | False                                |
| status         | ACTIVE                               |
| subnets        |                                      |
| tenant_id      | 2ac9cae777014d3d94458f521b013e94     |
+----------------+--------------------------------------+
root@JunoController:~# neutron subnet-create demo-net --name demo-subnet --gateway 10.44.44.1 10.44.44.0/24
Created a new subnet:
+------------------+------------------------------------------------+
| Field            | Value                                          |
+------------------+------------------------------------------------+
| allocation_pools | {&quot;start&quot;: &quot;10.44.44.2&quot;, &quot;end&quot;: &quot;10.44.44.254&quot;} |
| cidr             | 10.44.44.0/24                                  |
| dns_nameservers  |                                                |
| enable_dhcp      | True                                           |
| gateway_ip       | 10.44.44.1                                     |
| host_routes      |                                                |
| id               | c6181123-f729-4ad2-bddc-93cfc761d0e1           |
| ip_version       | 4                                              |
| name             | demo-subnet                                    |
| network_id       | 01c966ce-88cf-43a2-a7b7-2ebf6d6b6d60           |
| tenant_id        | 2ac9cae777014d3d94458f521b013e94               |
+------------------+------------------------------------------------+

root@JunoController:~# neutron router-create demo-router
Created a new router:
+-----------------------+--------------------------------------+
| Field                 | Value                                |
+-----------------------+--------------------------------------+
| admin_state_up        | True                                 |
| external_gateway_info |                                      |
| id                    | e5a010ba-371c-43d2-b3fb-a30e0dc5302b |
| name                  | demo-router                          |
| status                | ACTIVE                               |
| tenant_id             | 2ac9cae777014d3d94458f521b013e94     |
+-----------------------+--------------------------------------+

root@JunoController:~# neutron router-interface-add demo-router demo-subnet
Added interface c862f772-a1ef-4401-9a3b-2bdf5444e41b to router demo-router.

root@JunoController:~# neutron router-gateway-set demo-router ext-net
Set gateway for router demo-router

</code></pre>

<p>检查，在外网上ping 10.22.22.10这个地址，因为路由器占用了一个地址，所以如果能ping通这个地址，说明我们创建的网络是好的。</p>

<pre><code>[root:~]# ping 10.22.22.212                                                                                                                    
PING 10.22.22.212 (10.22.22.212) 56(84) bytes of data.                                                                                         
64 bytes from 10.22.22.212: icmp_seq=1 ttl=64 time=0.152 ms                                                                                    
64 bytes from 10.22.22.212: icmp_seq=2 ttl=64 time=0.136 ms    

</code></pre>

<p>检查agent状态:</p>

<pre><code>root@JunoController:~# neutron agent-list
+--------------------------------------+--------------------+-------------+-------+----------------+
| id                                   | agent_type         | host        | alive | admin_state_up |
+--------------------------------------+--------------------+-------------+-------+----------------+
| 0b7191e1-ecd2-4808-b87a-f616d0a3bc7b | Metadata agent     | JunoNetwork | :-)   | True           |
| 34511134-8392-44a9-a889-0ff03d85a995 | Open vSwitch agent | JunoCompute | :-)   | True           |
| 474065d1-a50a-4d11-89d3-37c7a88e449c | DHCP agent         | JunoNetwork | :-)   | True           |
| 5569c590-df83-4ee1-a073-15c908ef8d20 | L3 agent           | JunoNetwork | :-)   | True           |
| a22c6e2a-7af0-4404-9e5b-46996b370672 | Open vSwitch agent | JunoNetwork | :-)   | True           |
+--------------------------------------+--------------------+-------------+-------+----------------+

</code></pre>

<p>在 Compute Node 上的 OVS agent出现后，才能代表我们的网络配置成功。</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/07/deploy-opencontrail-on-centos-with-docker/">Deploy OpenContrail On CentOS With Docker As Hypervisor</a>
      </h1>
      <span class="post-date">Apr 7, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/07/deploy-opencontrail-on-centos-with-docker/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a>
        
      </span>
      
      

<p>Reference:<br />
<a href="https://software.intel.com/en-us/blogs/2014/12/28/experimenting-with-openstack-sahara-on-docker-containers">https://software.intel.com/en-us/blogs/2014/12/28/experimenting-with-openstack-sahara-on-docker-containers</a><br />
I wanna enable the docker as hypervisor then it would greatly save the resources, and benefit with docker&rsquo;s rich resources. Following is the steps:</p>

<h3 id="preparation">Preparation</h3>

<p>First create the image file via:</p>

<pre><code># qemu-img create -f qcow2 CentOSOpenContrail.qcow2 100G
Formatting 'CentOSOpenContrail.qcow2', fmt=qcow2 size=107374182400 encryption=off cluster_size=65536 
[root:/home/juju/img/CentOSOpenContrail]# pwd
/home/juju/img/CentOSOpenContrail

</code></pre>

<p>Then create a virtual machine based on KVM, allocate 8G Memory, 4-core, which copies the host CPU configuration.</p>

<h3 id="installation">Installation</h3>

<p>After installation, update the installed software via:</p>

<pre><code>$ mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup   
$ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 
$ sudo yum makecache
$ sudo yum update -y
$ sudo reboot

</code></pre>

<p>Install following packages:</p>

<pre><code># wget https://repos.fedorapeople.org/repos/openstack/openstack-juno/rdo-release-juno-1.noarch.rpm
# rpm -ivh rdo-release-juno-1.noarch.rpm 
# yum install –y https://rdo.fedorapeople.org/rdo-release.rpm
# yum install openstack-packstack

</code></pre>

<p>Now you could use packstack for installing the packages:</p>

<pre><code># packstack --gen-answer-file=/root/answer.txt
# packstack --answer-file=/root/answer.txt

</code></pre>

<p>Install openstack-sahara via following command, the python-tox enable tox for generating the configuration files for sahara:</p>

<pre><code># yum install openstack-sahara 
# yum install python-tox

</code></pre>

<p>Create the username and password for sahara to use:</p>

<pre><code>[root@10-17-17-183 etc]# mysql
MariaDB [(none)]&gt; create user 'sahara'@'localhost' identified by 'saharapass';
Query OK, 0 rows affected (0.07 sec)
MariaDB [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| cinder             |
| glance             |
| keystone           |
| mysql              |
| neutron            |
| nova               |
| performance_schema |
| test               |
+--------------------+
9 rows in set (0.00 sec)

MariaDB [(none)]&gt; use mysql
MariaDB [mysql]&gt; show tables;
MariaDB [mysql]&gt; select * from user;
+-----------+----------------+-----------------------------------

</code></pre>

<p>How to get all of the password configuration information of packstack?</p>

<pre><code>$ cd /etc/
$ grep -i &quot;sql://&quot; ./ -r

</code></pre>

<p>Create a database named &lsquo;saharaDB&rdquo; and grant it to user sahra:</p>

<pre><code>MariaDB [(none)]&gt; create database saharaDB;
MariaDB [(none)]&gt; grant all on saharaDB.* to 'sahara'@'localhost';
Query OK, 0 rows affected (0.02 sec)

MariaDB [(none)]&gt; quit;
[root@10-17-17-183 etc]# mysql -h 127.0.0.1 -u sahara -p saharaDB
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 1481
Server version: 5.5.40-MariaDB-wsrep MariaDB Server, wsrep_25.11.r4026

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [saharaDB]&gt; 

</code></pre>

<p>So the syntax for sahara to use is like:</p>

<pre><code># cat /etc/sahara/sahara.conf
connection = mysql://sahara:saharapass@127.0.0.1/saharaDB
use_neutron=true

# sahara-db-manage --config-file /etc/sahara/sahara.conf upgrade head
INFO  [alembic.migration] Context impl MySQLImpl.
INFO  [alembic.migration] Will assume non-transactional DDL.
INFO  [alembic.migration] Running upgrade None -&gt; 001, Icehouse release
INFO  [alembic.migration] Running upgrade 001 -&gt; 002, placeholder
INFO  [alembic.migration] Running upgrade 002 -&gt; 003, placeholder
INFO  [alembic.migration] Running upgrade 003 -&gt; 004, placeholder
INFO  [alembic.migration] Running upgrade 004 -&gt; 005, placeholder
INFO  [alembic.migration] Running upgrade 005 -&gt; 006, placeholder
INFO  [alembic.migration] Running upgrade 006 -&gt; 007, convert clusters.status_description to LongText
INFO  [alembic.migration] Running upgrade 007 -&gt; 008, add security_groups field to node groups
INFO  [alembic.migration] Running upgrade 008 -&gt; 009, add rollback info to cluster
INFO  [alembic.migration] Running upgrade 009 -&gt; 010, add auto_security_groups flag to node group
INFO  [alembic.migration] Running upgrade 010 -&gt; 011, add Sahara settings info to cluster

</code></pre>

<p>REgister the service and specify the endpoint:</p>

<pre><code>[root@10-17-17-183 etc]# cat ./nagios/keystonerc_admin                                                                                         
export OS_USERNAME=admin                                                                                                                       
export OS_TENANT_NAME=admin                                                                                                                    
export OS_PASSWORD=5d4e62e79d314477                                                                                                            
export OS_AUTH_URL=http://10.17.17.183:35357/v2.0/ 
[root@10-17-17-183 etc]# pwd                                                                
/etc  
# keystone service-create --name sahara --type data_processing --description &quot;Data processing service&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |     Data processing service      |
|   enabled   |               True               |
|      id     | 5f711f0d42754b349931349bd0c325d1 |
|     name    |              sahara              |
|     type    |         data_processing          |
+-------------+----------------------------------+
[root@10-17-17-183 ~]# keystone endpoint-create --service-id $(keystone service-list | awk '/ sahara / {print $2}') --publicurl http://127.0.0.1:8386/v1.1/%\(tenant_id\)s --internalurl http://127.0.0.1:8386/v1.1/%\(tenant_id\)s --adminurl http://127.0.0.1:8386/v1.1/%\(tenant_id\)s --region regionOne
+-------------+------------------------------------------+
|   Property  |                  Value                   |
+-------------+------------------------------------------+
|   adminurl  | http://127.0.0.1:8386/v1.1/%(tenant_id)s |
|      id     |     b2115bab8bd743f589b1ed68eef69b4c     |
| internalurl | http://127.0.0.1:8386/v1.1/%(tenant_id)s |
|  publicurl  | http://127.0.0.1:8386/v1.1/%(tenant_id)s |
|    region   |                regionOne                 |
|  service_id |     5f711f0d42754b349931349bd0c325d1     |
+-------------+------------------------------------------+
[root@10-17-17-183 ~]# systemctl start openstack-sahara-all
[root@10-17-17-183 ~]# systemctl enable openstack-sahara-all
ln -s '/usr/lib/systemd/system/openstack-sahara-all.service' '/etc/systemd/system/multi-user.target.wants/openstack-sahara-all.service'
[root@10-17-17-183 ~]# systemctl status openstack-sahara-all.service

</code></pre>

<p>More detailed info could be fetched from:<br />
<a href="http://docs.openstack.org/juno/install-guide/install/apt/content/sahara-install.html">http://docs.openstack.org/juno/install-guide/install/apt/content/sahara-install.html</a><br />
Now login to the <a href="http://10.17.17.183">http://10.17.17.183</a> then you could visit the Trustyboard. The password is the one we used in the <code>OS_PASSWORD</code>.<br />
Install docker:</p>

<pre><code>$  yum install docker
Or
$  wget https://get.docker.com/builds/Linux/x86_64/docker-latest -O docker
$  docker --version
[root@10-17-17-183 ~]#  usermod -G dockerroot nova
[root@10-17-17-183 ~]# service openstack-nova-compute restart
Redirecting to /bin/systemctl restart  openstack-nova-compute.service
# systemctl restart docker
# systemctl enable docker

</code></pre>

<p>Install nova-docker support:</p>

<pre><code>$  yum install python-pip
$  pip install -e git+https://github.com/stackforge/nova-docker#egg=novadocker
$  cd src/novadocker/
$  python setup.py install
$ vim /etc/nova/nova.conf
[DEFAULT]
compute_driver = novadocker.virt.docker.DockerDriver

</code></pre>

<p>Edit the nova&rsquo;s rootwrap like following:</p>

<pre><code>[root@10-17-17-183 nova]# mkdir rootwrap.d
[root@10-17-17-183 nova]# cd rootwrap.d/
[root@10-17-17-183 rootwrap.d]# touch docker.filters
[root@10-17-17-183 rootwrap.d]# vim docker.filters 
[Filters]
# nova/virt/docker/driver.py:'ln', '-sf', '/var/run/netns/.*'
ln: CommandFilter, /bin/ln, root
[root@10-17-17-183 rootwrap.d]# vim /etc/nova/rootwrap.conf 
[root@10-17-17-183 rootwrap.d]# pwd
/etc/nova/rootwrap.d

</code></pre>

<p>Edit the glance-api.conf</p>

<pre><code>[root@10-17-17-183 glance]# vim ./glance-api.conf 
[DEFAULT]
container_formats = ami,ari,aki,bare,ovf,docker
[root@10-17-17-183 glance]# pwd
/etc/glance

</code></pre>

<p>Create the ubuntu Container images via following commands:</p>

<pre><code>$ docker pull ubuntu
$ docker save ubuntu | glance image-create --is-public=True --container-format=docker --disk-format=raw --name ubuntu_container

</code></pre>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/01/build-qemu-for-supporting-glustfs/">Build qemu for supporting glustfs</a>
      </h1>
      <span class="post-date">Apr 1, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/01/build-qemu-for-supporting-glustfs/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/null">null</a>
        
      </span>
      
      <p>Following is the build procedure.</p>

<pre><code>$ sudo apt-get build-dep qemu
$ sudo apt-get install libvde-dev libvdeplug2-dev libcap-ng-dev libattr1-dev
$ wget http://wiki.qemu-project.org/download/qemu-2.0.2.tar.bz2
$ tar xjvf qemu-2.0.2.tar.bz2
$ cd qemu-2.0.2/
$ mkdir -p bin/debug/native
$ cd bin/debug/native
$ sudo apt-get install libjpeg-turbo8-dev
$ sudo apt-get install glusterfs-common
 ../../../configure --enable-sdl --audio-drv-list=alsa,oss --enable-curses --enable-vnc-jpeg --enable-curl --enable-fdt --enable-kvm --enable-tcg-interpreter --enable-system --enable-user \\n --enable-linux-user --enable-guest-base --enable-pie --enable-uuid --enable-vde --enable-linux-aio --enable-cap-ng --enable-attr --enable-docs --enable-vhost-net --enable-rbd \\n --enable-guest-agent --enable-glusterfs --target-list=x86_64-softmmu,i386-softmmu
 ./qemu-img -h
 $ make -j2

</code></pre>

<p>Before, Found qemu-img:</p>

<pre><code>$ qemu-img -h
Supported formats: vvfat vpc vmdk vhdx vdi sheepdog sheepdog sheepdog rbd raw host_cdrom host_floppy host_device file qed qcow2 qcow parallels nbd nbd nbd dmg tftp ftps ftp https http cow cloop bochs blkverify blkdebug

</code></pre>

<p>After, qemu-img:</p>

<pre><code>Supported formats: vvfat vpc vmdk vhdx vdi sheepdog sheepdog sheepdog rbd raw host_cdrom host_floppy host_device file qed qcow2 qcow parallels nbd nbd nbd gluster gluster gluster gluster dmg tftp ftps ftp https http cow cloop bochs blkverify blkdebug

</code></pre>

      
    </div>
    
    
    
    <ul class="pagination">
        
        <li>
            <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
        </li>
        
        <li
        >
        <a href="/page/49/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
        </li>
        
        <li
        ><a href="/">1</a></li>
        
        <li
        ><a href="/page/2/">2</a></li>
        
        <li
        ><a href="/page/3/">3</a></li>
        
        <li
        ><a href="/page/4/">4</a></li>
        
        <li
        ><a href="/page/5/">5</a></li>
        
        <li
        ><a href="/page/6/">6</a></li>
        
        <li
        ><a href="/page/7/">7</a></li>
        
        <li
        ><a href="/page/8/">8</a></li>
        
        <li
        ><a href="/page/9/">9</a></li>
        
        <li
        ><a href="/page/10/">10</a></li>
        
        <li
        ><a href="/page/11/">11</a></li>
        
        <li
        ><a href="/page/12/">12</a></li>
        
        <li
        ><a href="/page/13/">13</a></li>
        
        <li
        ><a href="/page/14/">14</a></li>
        
        <li
        ><a href="/page/15/">15</a></li>
        
        <li
        ><a href="/page/16/">16</a></li>
        
        <li
        ><a href="/page/17/">17</a></li>
        
        <li
        ><a href="/page/18/">18</a></li>
        
        <li
        ><a href="/page/19/">19</a></li>
        
        <li
        ><a href="/page/20/">20</a></li>
        
        <li
        ><a href="/page/21/">21</a></li>
        
        <li
        ><a href="/page/22/">22</a></li>
        
        <li
        ><a href="/page/23/">23</a></li>
        
        <li
        ><a href="/page/24/">24</a></li>
        
        <li
        ><a href="/page/25/">25</a></li>
        
        <li
        ><a href="/page/26/">26</a></li>
        
        <li
        ><a href="/page/27/">27</a></li>
        
        <li
        ><a href="/page/28/">28</a></li>
        
        <li
        ><a href="/page/29/">29</a></li>
        
        <li
        ><a href="/page/30/">30</a></li>
        
        <li
        ><a href="/page/31/">31</a></li>
        
        <li
        ><a href="/page/32/">32</a></li>
        
        <li
        ><a href="/page/33/">33</a></li>
        
        <li
        ><a href="/page/34/">34</a></li>
        
        <li
        ><a href="/page/35/">35</a></li>
        
        <li
        ><a href="/page/36/">36</a></li>
        
        <li
        ><a href="/page/37/">37</a></li>
        
        <li
        ><a href="/page/38/">38</a></li>
        
        <li
        ><a href="/page/39/">39</a></li>
        
        <li
        ><a href="/page/40/">40</a></li>
        
        <li
        ><a href="/page/41/">41</a></li>
        
        <li
        ><a href="/page/42/">42</a></li>
        
        <li
        ><a href="/page/43/">43</a></li>
        
        <li
        ><a href="/page/44/">44</a></li>
        
        <li
        ><a href="/page/45/">45</a></li>
        
        <li
        ><a href="/page/46/">46</a></li>
        
        <li
        ><a href="/page/47/">47</a></li>
        
        <li
        ><a href="/page/48/">48</a></li>
        
        <li
        ><a href="/page/49/">49</a></li>
        
        <li
        class="active"><a href="/page/50/">50</a></li>
        
        <li
        ><a href="/page/51/">51</a></li>
        
        <li
        ><a href="/page/52/">52</a></li>
        
        <li
        ><a href="/page/53/">53</a></li>
        
        <li
        ><a href="/page/54/">54</a></li>
        
        <li
        ><a href="/page/55/">55</a></li>
        
        <li
        ><a href="/page/56/">56</a></li>
        
        <li
        ><a href="/page/57/">57</a></li>
        
        <li
        ><a href="/page/58/">58</a></li>
        
        <li
        ><a href="/page/59/">59</a></li>
        
        <li
        ><a href="/page/60/">60</a></li>
        
        <li
        ><a href="/page/61/">61</a></li>
        
        <li
        ><a href="/page/62/">62</a></li>
        
        <li
        ><a href="/page/63/">63</a></li>
        
        <li
        ><a href="/page/64/">64</a></li>
        
        <li
        ><a href="/page/65/">65</a></li>
        
        <li
        ><a href="/page/66/">66</a></li>
        
        <li
        ><a href="/page/67/">67</a></li>
        
        <li
        ><a href="/page/68/">68</a></li>
        
        <li
        ><a href="/page/69/">69</a></li>
        
        <li
        ><a href="/page/70/">70</a></li>
        
        <li
        ><a href="/page/71/">71</a></li>
        
        <li
        ><a href="/page/72/">72</a></li>
        
        <li
        ><a href="/page/73/">73</a></li>
        
        <li
        ><a href="/page/74/">74</a></li>
        
        <li
        ><a href="/page/75/">75</a></li>
        
        <li
        ><a href="/page/76/">76</a></li>
        
        <li
        ><a href="/page/77/">77</a></li>
        
        <li
        ><a href="/page/78/">78</a></li>
        
        <li
        ><a href="/page/79/">79</a></li>
        
        <li
        ><a href="/page/80/">80</a></li>
        
        <li
        ><a href="/page/81/">81</a></li>
        
        <li
        ><a href="/page/82/">82</a></li>
        
        <li
        ><a href="/page/83/">83</a></li>
        
        <li
        ><a href="/page/84/">84</a></li>
        
        <li
        ><a href="/page/85/">85</a></li>
        
        <li
        ><a href="/page/86/">86</a></li>
        
        <li
        ><a href="/page/87/">87</a></li>
        
        <li
        ><a href="/page/88/">88</a></li>
        
        <li
        ><a href="/page/89/">89</a></li>
        
        <li
        ><a href="/page/90/">90</a></li>
        
        <li
        ><a href="/page/91/">91</a></li>
        
        <li
        ><a href="/page/92/">92</a></li>
        
        <li
        ><a href="/page/93/">93</a></li>
        
        <li
        ><a href="/page/94/">94</a></li>
        
        <li
        ><a href="/page/95/">95</a></li>
        
        <li
        ><a href="/page/96/">96</a></li>
        
        <li
        ><a href="/page/97/">97</a></li>
        
        <li
        ><a href="/page/98/">98</a></li>
        
        <li
        ><a href="/page/99/">99</a></li>
        
        <li
        ><a href="/page/100/">100</a></li>
        
        <li
        ><a href="/page/101/">101</a></li>
        
        <li
        ><a href="/page/102/">102</a></li>
        
        <li
        ><a href="/page/103/">103</a></li>
        
        <li
        ><a href="/page/104/">104</a></li>
        
        <li
        ><a href="/page/105/">105</a></li>
        
        <li
        ><a href="/page/106/">106</a></li>
        
        <li
        ><a href="/page/107/">107</a></li>
        
        <li
        ><a href="/page/108/">108</a></li>
        
        <li
        ><a href="/page/109/">109</a></li>
        
        <li
        ><a href="/page/110/">110</a></li>
        
        <li
        ><a href="/page/111/">111</a></li>
        
        <li
        ><a href="/page/112/">112</a></li>
        
        <li
        ><a href="/page/113/">113</a></li>
        
        <li
        ><a href="/page/114/">114</a></li>
        
        <li
        ><a href="/page/115/">115</a></li>
        
        <li
        ><a href="/page/116/">116</a></li>
        
        <li
        ><a href="/page/117/">117</a></li>
        
        <li
        ><a href="/page/118/">118</a></li>
        
        <li
        ><a href="/page/119/">119</a></li>
        
        <li
        ><a href="/page/120/">120</a></li>
        
        <li
        ><a href="/page/121/">121</a></li>
        
        <li
        ><a href="/page/122/">122</a></li>
        
        <li
        ><a href="/page/123/">123</a></li>
        
        <li
        ><a href="/page/124/">124</a></li>
        
        <li
        ><a href="/page/125/">125</a></li>
        
        <li
        ><a href="/page/126/">126</a></li>
        
        <li
        ><a href="/page/127/">127</a></li>
        
        <li
        ><a href="/page/128/">128</a></li>
        
        <li
        ><a href="/page/129/">129</a></li>
        
        <li
        ><a href="/page/130/">130</a></li>
        
        <li
        ><a href="/page/131/">131</a></li>
        
        <li
        ><a href="/page/132/">132</a></li>
        
        <li
        ><a href="/page/133/">133</a></li>
        
        <li
        ><a href="/page/134/">134</a></li>
        
        <li
        ><a href="/page/135/">135</a></li>
        
        <li
        ><a href="/page/136/">136</a></li>
        
        <li
        >
        <a href="/page/51/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
        </li>
        
        <li>
            <a href="/page/136/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
        </li>
        
    </ul>
    
  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "dashsagittariussglory";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<script src="http://purplepalmdash.github.io/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>

