<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.17-DEV" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Dash &middot; Dash</title>

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/poole.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/hyde-a.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/custom-additions.css?ref=abc124">
  <link rel="stylesheet" href="http://purplepalmdash.github.io/css/highlight/googlecode.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124">
  <link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel="icon">

  
  
  
  <link href="http://purplepalmdash.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Dash &middot; Dash" />

  <meta name="description" content="Get busy living, or get busy dying.">
  <meta name="keywords" content="unix,virtualization,embedded,linux">
  <link rel="author" href="http://plus.google.com/106572959364703833986">
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-42175003-1', 'auto');
      ga('send', 'pageview');
  </script>

</head>
<body class="theme-base-0c">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <img src="https://www.gravatar.com/avatar/49381c0004d32c0a4296b92dff0c0ae5?s=200" alt="gravatar">
      <h1><a href="http://purplepalmdash.github.io/">Get busy living, or get busy dying.</a></h1>
      <a href="http://purplepalmdash.github.io/"><p>Dash</p></a>
    </div>

    <ul class="sidebar-nav">
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/">First Page</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/post/">All Posts</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/linux/">Linux</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/embedded/">Embedded System</a></li>
      
      <li class="sidebar-nav-item"><a href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="https://github.com/purplepalmdash"><i class="fa fa-github-square fa-3x"></i></a>
      
      <a href="https://cn.linkedin.com/in/yang-feipeng-1b909319"><i class="fa fa-linkedin-square fa-3x"></i></a>
      <a href="https://plus.google.com/u/0/106572959364703833986"><i class="fa fa-google-plus-square fa-3x"></i></a>
      <a href="https://www.facebook.com/yang.feipeng"><i class="fa fa-facebook-square fa-3x"></i></a>
      <a href="https://twitter.com/dashwillfly"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="http://purplepalmdash.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/27/shi-yong-fuelbu-shu-opencontrail-4/">使用Fuel部署OpenContrail(4)</a>
      </h1>
      <span class="post-date">Apr 27, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/27/shi-yong-fuelbu-shu-opencontrail-4/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a>
        
      </span>
      
      

<p>前面已经准备好了集成OpenContrail的所有事宜，接下来就是真正部署OpenContrail的过程了。部署OpenContrail需要修改所有的Contrail Controller节点，OpenStack Controller节点， OpenStack Compute节点，为了避免混淆，本节主要完成在Contrail Controller上的部署工作。</p>

<h3 id="openstack-controller节点部署后配置">OpenStack Controller节点部署后配置</h3>

<p>在所有的OpenStack Controller节点(OS1,OS2,OS3)上，打开/usr/lib/ocf/resource.d/mirantis/ns_haproxy文件，编辑以下字段:<br />
OCF_Parameters部分:</p>

<pre><code>OCF_RESKEY_private_network_default=&quot;10.55.55.0/24&quot;
OCF_RESKEY_private_network_gateway_default=&quot;10.55.55.1&quot;

</code></pre>

<p>在meta_data()函数中，添加以下内容:</p>

<pre><code>&lt;parameter name=&quot;private_network&quot;&gt;
&lt;longdesc lang=&quot;en&quot;&gt;
Private L3 network that should be configured inside the namespace
&lt;/longdesc&gt;
&lt;shortdesc lang=&quot;en&quot;&gt;Namespace private network&lt;/shortdesc&gt;
&lt;content type=&quot;string&quot; default=&quot;${OCF_RESKEY_private_network_default}&quot; /&gt;
&lt;/parameter&gt;

&lt;parameter name=&quot;private_network_gateway&quot;&gt;
&lt;longdesc lang=&quot;en&quot;&gt;
Private L3 network gateway that should be configured inside the namespace.
&lt;/longdesc&gt;
&lt;shortdesc lang=&quot;en&quot;&gt;Namespace private gateway network&lt;/shortdesc&gt;
&lt;content type=&quot;string&quot; default=&quot;${OCF_RESKEY_private_network_gateway_default}&quot; /&gt;
&lt;/parameter&gt;

</code></pre>

<p>set_ns_routing()函数中，添加一下内容:</p>

<pre><code>nsip route list | grep -q &quot;${OCF_RESKEY_private_network}&quot;
if [ $? -gt 0 ]; then
ocf_log debug &quot;Creating ${OCF_RESKEY_private_network} route inside the namespace&quot;
ocf_run nsip route add &quot;${OCF_RESKEY_private_network}&quot; via &quot;${OCF_RESKEY_private_network_gateway}&quot;
fi

</code></pre>

<p>以上的修改是为了引入haproxy的namespace的。</p>

<h3 id="配置contrail部署节点">配置Contrail部署节点</h3>

<p>我们引入了三个Contrail Controller节点，从中挑选一个，作为部署的管理节点，OpenContrail通过fabric下发安装指令给各节点机，因此我们首先要准备的是部署节点。这里的例子中，我们选择Contrail1(10.20.0.10)作为部署节点。</p>

<pre><code># echo 'deb http://10.20.0.2:8080/contrail/ /' &gt; /etc/apt/sources.list.d/contrail.list
# echo -e &quot;Package: *\nPin: release l=Ubuntu\nPin-Priority: 100&quot; &gt; /etc/apt/preferences
# &gt;/etc/apt/sources.list
# apt-get update
# apt-get install -y python-paramiko contrail-fabric-utils contrail-setup
# pip install --upgrade --no-deps --index-url=”” /opt/contrail/python_packages/Fabric-1.7.0.tar.gz

</code></pre>

<p>apt-get udpate前我们需要清空本机上的sources.list文件，因为经过前两步后，本机的sources.list中会加上10.20.0.2的默认源，这会引发update失败，因此我们清空此文件。<br />
安装完一些准备包后，部署节点进入就绪状态。</p>

<h3 id="编写testbed-py">编写testbed.py</h3>

<p>testbed.py文件定义了整个OpenContrail的组建部署节点信息，在编写此文件前，我们需要得到以下信息:<br />
A. OpenStack的Service_Token, 在任何一台OpenStack Controller机器上，运行以下命令以得到系统当前的service_token值:</p>

<pre><code>root@node-20:~# cat /etc/keystone/keystone.conf  | grep -i &quot;admin_token=&quot; | more
#admin_token=ADMIN
admin_token=rVlaAKUs

</code></pre>

<p>记下rVlaAKUs这个值，在testbed.py文件中我们会用到。</p>

<p>B. OpenStack Controller的Public vip和Management vip, 如下所示，结合我们的网络规划，Public vip是172网段，而Management vip则是10.55.55网段的IP:</p>

<pre><code>root@node-20:~# source /root/openrc 
root@node-20:~# keystone endpoint-list | grep 5000
| 0e3c0684e8ae4c9fa4e080c9e1c66513 | RegionOne |         http://172.16.0.4:5000/v2.0          |         http://10.55.55.4:5000/v2.0          |       http://10.55.55.4:35357/v2.0      | f822df80ee1042d9b10d57118bb410aa |


</code></pre>

<p>C. Contrail Controller的内部vip和外部vip, 因为我们把Contrail Controller的Private IP分配在10.77.77.0/24网段，所以我们暂时选用10.77.77.9作为两个vip的地址。</p>

<p>D. 如果有外部路由器，则需要配置外部路由器的IP地址。这次的部署中我们不采用外部路由器，因而对比于官方的推荐配置文件，我们的testbed.py中删除了这一部分。</p>

<p>综合考虑到上述因素后，我们的testbed.py文件定义如下:</p>

<pre><code>root@node-24:~# vim /opt/contrail/utils/fabfile/testbeds/testbed.py|more
from fabric.api import env
#Management ip addresses of hosts in the cluster
os_ctrl01 = 'root@10.55.55.6'
os_ctrl02 = 'root@10.55.55.7'
os_ctrl03 = 'root@10.55.55.8'
c_ctrl01 = 'root@10.77.77.10'
c_ctrl02 = 'root@10.77.77.11'
c_ctrl03 = 'root@10.77.77.12'
c_db01 = 'root@10.77.77.10'
c_db02 = 'root@10.77.77.11'
c_db03 = 'root@10.77.77.12'
#External routers
# ext_routers = [('gateway01', '&lt;Gateway_node1_LOOPBACK_ip&gt;'), ('gateway02', '&lt;Gateway_node2_LOOPBACK_ip&gt;')]
#Autonomous system number
router_asn = 64512
#Host from which the fab commands are triggered to install and provision
deploy_node = 'root@10.77.77.10'
#Role definition of the hosts.
env.roledefs = {
'all': [c_ctrl01, c_ctrl02, c_ctrl03, c_db01, c_db02, c_db03],
'cfgm': [c_ctrl01, c_ctrl02, c_ctrl03],
'openstack': [os_ctrl01, os_ctrl02, os_ctrl03],
'control': [c_ctrl01, c_ctrl02, c_ctrl03],
'compute': [],
'collector': [c_ctrl01, c_ctrl02, c_ctrl03],
'webui': [c_ctrl01, c_ctrl02, c_ctrl03],
'database': [c_db01, c_db02, c_db03],
'build': [deploy_node],
'storage-master': [],
'storage-compute': [],
}
#Openstack admin password
env.openstack_admin_password = 'admin'
env.password = 'r00tme'
#Passwords of each host
env.passwords = {
os_ctrl01: 'r00tme',
os_ctrl02: 'r00tme',
os_ctrl03: 'r00tme',
c_ctrl01: 'r00tme',
c_ctrl02: 'r00tme',
c_ctrl03: 'r00tme',
c_db01: 'r00tme',
c_db02: 'r00tme',
c_db03: 'r00tme',
deploy_node: 'r00tme',
}
#For reimage purpose
env.ostypes = {
os_ctrl01: 'ubuntu',
os_ctrl02: 'ubuntu',
os_ctrl03: 'ubuntu',
c_ctrl01: 'ubuntu',
c_ctrl02: 'ubuntu',
c_ctrl03: 'ubuntu',
c_db01: 'ubuntu',
c_db02: 'ubuntu',
c_db03: 'ubuntu',
deploy_node: 'ubuntu',
}
env.openstack = {
'service_token' : 'rVlaAKUs'
}
env.ha = {
'internal_vip': '10.55.55.4',
'external_vip': '172.16.0.4',
'contrail_internal_vip': '10.77.77.9',
'contrail_external_vip': '10.77.77.9',
}
env.keystone = {
'service_tenant': 'services',
'admin_token': 'rVlaAKUs',
}
multi_tenancy = True

</code></pre>

<p>编写完testbed.py文件后，就可以根据文件中的定义，部署OpenContrail的组件到多台节点主机了。<br />
Fuel Controller节点上的id_rsa文件可以实现对各个节点的无密码登录，拷贝它到我们的Contrail部署节点上:</p>

<pre><code># scp 10.20.0.2:/root/.ssh/id_rsa /root/.ssh/id_rsa
# chmod 0600 /root/.ssh/id_rsa

</code></pre>

<h3 id="部署多节点">部署多节点</h3>

<p>首先切换到/opt/contrail/utils目录下，所有用fab执行的部署都需要在这个目录下执行。执行以下操作, 以初始化各部署子节点:</p>

<pre><code># cd /opt/contrail/utils
# fab -P -R control -w -- &quot;ls /etc/apt/sources.list.d/contrail.list || echo 'deb \
http://10.20.0.2:8080/contrail/ /' &gt; \
/etc/apt/sources.list.d/contrail.list&quot;
# fab -P -R control -w -- 'ls /etc/apt/preferences || echo -e &quot;Package: *\nPin: release \
l=Ubuntu\nPin-Priority: 100&quot; &gt; /etc/apt/preferences'
# fab -P -R control -w -- 'DEBIAN_FRONTEND=noninteractive apt-get -y --force-yes \
--allow-unauthenticated install python-crypto python-netaddr python-paramiko \
contrail-fabric-utils contrail-setup'
# fab -P -R control -w -- 'pip install --upgrade --no-deps --index-url=&quot;&quot; \
/opt/contrail/python_packages/ecdsa-0.10.tar.gz'
# fab -P -R control -w -- 'pip install --upgrade --no-deps --index-url=&quot;&quot; \
/opt/contrail/python_packages/Fabric-1.7.0.tar.gz'

</code></pre>

<p>如果出现apt-get update的问题，可以如上面提到的，手动登录到各个节点上去清空/etc/apt/sources.list文件，当然一般情况下不会出现这个问题。<br />
运行以下命令，接受sun的协议:</p>

<pre><code># fab -P -R control -w -- 'echo &quot;sun-java6-plugin shared/accepted-sun-dlj-v1-1 boolean \
true&quot; | /usr/bin/debconf-set-selections' &amp;&amp; fab -P -R control -w -- 'echo &quot;sun-java6-bin shared/accepted-sun-dlj-v1-1 boolean \
 true&quot; | /usr/bin/debconf-set-selections' &amp;&amp; fab -P -R control -w -- 'echo &quot;debconf shared/accepted-oracle-license-v1-1 select \
true&quot; | sudo debconf-set-selections' &amp;&amp; fab -P -R control -w -- 'echo &quot;debconf shared/accepted-oracle-license-v1-1 seen \
 true&quot; | sudo debconf-set-selections'

</code></pre>

<p>OpenContrail组件依赖于特定版本的tzdata， 用以下命令安装：</p>

<pre><code># fab -P -R control -w -- 'DEBIAN_FRONTEND=noninteractive apt-get -y --force-yes \
 --allow-unauthenticated install tzdata=2014e-0ubuntu0.12.04'

</code></pre>

<p>安装和设置database, 并检查节点的状态:</p>

<pre><code> # fab install_database &amp;&amp; fab setup_database
 # fab -R database -w -- &quot;contrail-status&quot;
 # nodetool status
--  Address      Load       Tokens  Owns   Host ID                               Rack
UN  10.77.77.12  141.84 MB  256     33.3%  4ea3abec-16ee-417a-b78c-69e8dca292be  rack1
UN  10.77.77.11  141.33 MB  256     35.8%  d7677bf2-1447-48af-b1d4-356b4a8d6cff  rack1
UN  10.77.77.10  134.28 MB  256     30.9%  e418e4ef-af22-4874-ad94-777d6b4c511c  rack1

</code></pre>

<p>当看到上面有三个条目时，代表安装成功，可以进行下一步。</p>

<p>安装cfgm, control, collector, webui 组件以及keepalived集群。</p>

<pre><code># fab install_cfgm &amp;&amp; fab install_control &amp;&amp; fab install_collector &amp;&amp; fab install_webui &amp;&amp; fab setup_contrail_keepalived &amp;&amp; fab fixup_restart_haproxy_in_collector 2&gt;&amp;1 | tee all.txt

</code></pre>

<p>删除掉/etc/keepalived/keepalived.conf里的EXTERNAL部分, 值得注意的是，在三个Contrail Controller上，都需要执行此操作:</p>

<pre><code># vim /etc/keepalived/keepalived.conf
......remove something......

</code></pre>

<p>删除以后，重新启动keepalived服务:</p>

<pre><code># fab -P -R control -w -- 'service keepalived restart'

</code></pre>

<p>更新haproxy的配置文件，添加WebUI的虚拟IP地址(vip). 值得注意的是，在三个Contrail Controller上，都需要执行此操作:</p>

<pre><code># vim /etc/haproxy/haproxy.cfg
#contrail-webui-marker-start
frontend contrail-webui-api *:443
    mode tcp
    default_backend contrail-webui-api
backend contrail-webui-api
    mode tcp
    balance roundrobin
    option nolinger
    stick on src
    stick-table type ip size 200k expire 300m
    option tcp-check
    tcp-check connect port 8143
    default-server error-limit 1 on-error mark-down
    server 10.77.77.10 10.77.77.10:8143 check inter 2000 rise 2 fall 3
    server 10.77.77.11 10.77.77.11:8143 check inter 2000 rise 2 fall 3
    server 10.77.77.12 10.77.77.12:8143 check inter 2000 rise 2 fall 3
#contrail-webui-marker-end

</code></pre>

<p>更改完以后，重启haproxy服务:</p>

<pre><code># fab -P -R control -w -- 'service haproxy restart'

</code></pre>

<p>更改每个节点上的tenant服务名称，从&rsquo;service&rsquo;改成&rsquo;services&rsquo;:</p>

<pre><code># fab -P -R control -w -- &quot;sed -i '49s/service/services/g' \
/usr/local/lib/python2.7/dist-packages/contrail_provisioning/config/quantum_in_keystone_setup.py&quot;

</code></pre>

<p>配置cfgm服务:</p>

<pre><code># fab setup_cfgm

</code></pre>

<p>这时我们可以验证neutron endpoint是否被正确安装，在任何一个OpenStack Controller节点上，运行以下命令:</p>

<pre><code># keystone service-list
# keystone endpoint-list

</code></pre>

<p>例如:</p>

<pre><code>root@node-20:~# keystone service-list | grep neutron
| 2f4c887f68a9428aa448cbd688d7061f | neutron  |    network     |             network              |
root@node-20:~# keystone endpoint-list | grep 2f4c887f68a9428aa448cbd688d7061f
| 7dd2c25e69ad4a3296f272aa253001c8 | RegionOne |            http://10.77.77.9:9696            |            http://10.77.77.9:9696            |          http://10.77.77.9:9696         | 2f4c887f68a9428aa448cbd688d7061f |

</code></pre>

<p>成功的话，接着下一步设置，删除所有的Contrail Controller节点上文件/etc/haproxy/haproxy.cfg里的rabbit字段：</p>

<pre><code># vim /etc/haproxy/haproxy.cfg
......remove something......

</code></pre>

<p>重新启动haproxy服务:</p>

<pre><code># fab -P -R control -w -- 'service haproxy restart'

</code></pre>

<p>设置control,collector,webui组件服务:</p>

<pre><code># fab setup_control
# fab setup_collector &amp;&amp; fab setup_webui

</code></pre>

<p>在任一OpenStack Controller节点上，运行以下命令，得到rabbit的密码:</p>

<pre><code>root@node-22:~# cat /etc/rabbitmq/rabbitmq.config | grep default_pass
    {default_pass,        &lt;&lt;&quot;gYFQP10P&quot;&gt;&gt;},

</code></pre>

<p>配置neutron插件，使用运行在OpenStack Controller上的rabbit 集群, 这里的rabbit_password使用上面得到的值:</p>

<pre><code>#  fab -P -R control -w -- 'openstack-config --del /etc/neutron/neutron.conf DEFAULT rabbit_host'
#  fab -P -R control -w -- 'openstack-config --set /etc/neutron/neutron.conf DEFAULT rabbit_hosts \
  10.55.55.6:5673,10.55.55.7:5673,10.55.55.8:5673'
#  fab -P -R control -w -- 'openstack-config --set /etc/neutron/neutron.conf DEFAULT rabbit_userid \
   nova'
#  fab -P -R control -w -- 'openstack-config --set /etc/neutron/neutron.conf DEFAULT \
  rabbit_password gYFQP10P'
# fab -P -R control -w -- 'service neutron-server restart'

</code></pre>

<p>配置contrail-api以使用运行在OpenStack Controller上的rabbit集群:</p>

<pre><code># fab -P -R control -w -- 'perl -pi -e \
 &quot;s/rabbit_server.*$/rabbit_server=10.55.55.4/&quot; /etc/contrail/contrail-api.conf'
# fab -P -R control -w -- 'perl -pi -e &quot;s/rabbit_port.*$/rabbit_port=5672/&quot; \
 /etc/contrail/contrail-api.conf'
# fab -R control -w -- &quot;perl -pi -e 'print \&quot;rabbit_password=gYFQP10P\n\&quot; \
 if \$_ =~ rabbit_port' /etc/contrail/contrail-api.conf&quot;
# fab -P -R control -w -- &quot;perl -pi -e 'print \&quot;rabbit_user=nova\n\&quot; if \$_ =~ rabbit_port' \
 /etc/contrail/contrail-api.conf&quot;
# fab -P -R control -w -- &quot;service contrail-api restart&quot;

</code></pre>

<p>使用前面下载的OpenContrail 插件，作为neutron挂载的插件, 或者你可以直接从github克隆下来:</p>

<pre><code># mkdir -p /tmp/contrail-repo
# apt-get install -y git
# git clone https://github.com/Juniper/contrail-neutron-plugin.git /tmp/contrail-repo
# cd /tmp/contrail-repo
# git checkout 3189155
# cp -r /tmp/contrail-repo/neutron_plugin_contrail/plugins/opencontrail \
/usr/share/pyshared/neutron_plugin_contrail/plugins/

</code></pre>

<p>重新启动neutron-service:</p>

<pre><code># cd /opt/contrail/utils
# fab -P -R cfgm -w -- 'service neutron-server restart'

</code></pre>

<p>设置Contrail Controller之间的BGP节点发现，metadata服务及encapsulation类型:</p>

<pre><code># fab prov_control_bgp &amp;&amp; fab prov_metadata_services &amp;&amp; fab prov_encap_type

</code></pre>

<p>用以下命令验证安装是否成功:</p>

<pre><code># fab verify_cfgm
# fab verify_control
# fab verify_collector
# fab verify_webui
# fab -R control -w -- &quot;contrail-status&quot;

</code></pre>

<p>更新rc.d，这样在启动的时候，不会启动supervisor-support进程：</p>

<pre><code># fab -P -R control -w -- 'update-rc.d supervisor-support-service disable'

</code></pre>

<p>用浏览器访问以下页面，以确认Contrail已经被正确安装:<br />
<a href="https://10.77.77.9">https://10.77.77.9</a><br />
此时你看到的页面应该如下：<br />
<img src="/images/2015_04_27_21_49_07_1006x746.jpg" alt="/images/2015_04_27_21_49_07_1006x746.jpg" /></p>

<p>本章过完以后，我们的OpenContrail部署已经完成了大半，接下来就是在Compute和OpenStack Controller节点上的配置，达到最后的集成过程。</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/27/shi-yong-fuelbu-shu-opencontrail-5/">使用Fuel部署OpenContrail(5)</a>
      </h1>
      <span class="post-date">Apr 27, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/27/shi-yong-fuelbu-shu-opencontrail-5/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a>
        
      </span>
      
      

<p>本节主要用于配置OpenStack使用OpenContrail作为其网络配置器，主要涉及到OpenStack Controller和OpenStack Compute上的配置.</p>

<h3 id="openstack-controller配置">OpenStack Controller配置</h3>

<p>!!! 以下的所有操作，需要在每个OpenStack Controller节点上进行！！！
OpenStack Controller不需要使用Private 网络，所以我们可以删除ifcfg-eth0文件:</p>

<pre><code># rm -f /etc/network/interface.d/ifcfg-eth4
# service networking restart

</code></pre>

<p>为了保险，最好重启更改完网络后的节点。<br />
配置/etc/nova/nova.conf文件中的以下字段:</p>

<pre><code># vim /etc/nova/nova.conf
[DEFAULT]
network_api_class = nova.network.neutronv2.api.API
neutron_url = http://10.77.77.9:9696
neutron_admin_tenant_name = services
neutron_admin_username = neutron
neutron_admin_password = rVlaAKUs
neutron_url_timeout = 300
neutron_admin_auth_url = http://10.55.55.4:35357/v2.0/
firewall_driver = nova.virt.firewall.NoopFirewallDriver
enabled_apis = ec2,osapi_compute,metadata
security_group_api = neutron
service_neutron_metadata_proxy = True

</code></pre>

<p>neutron_admin_password的值还是我们以前取得的admin token.<br />
更改完上述配置后，重启以下服务:</p>

<pre><code># service nova-api restart
# service nova-scheduler restart
# service nova-conductor restart

</code></pre>

<p>在任一OpenStack Controller节点上，使用以下命令，在数据库中删除nova-network服务的定义。</p>

<pre><code># source ~/openrc
# for i in $(nova service-list|grep nova-network|awk '{print $2}'); \
do nova service-delete $i;done

</code></pre>

<h3 id="compute-计算-节点配置">Compute(计算)节点配置</h3>

<p>!!! 以下操作，都应该在每个计算节点上运行 !!!!
在每个计算节点上，配置仓库:</p>

<pre><code>#  echo 'deb http://10.20.0.2:8080/contrail/ /' &gt;/etc/apt/sources.list.d/contrail.list
# echo -e &quot;Package: *\nPin: release l=Ubuntu\nPin-Priority: 100&quot; &gt; /etc/apt/preferences
# &gt;/etc/apt/sources.list
# apt-get update

</code></pre>

<p>Contrail是不需要OpenVSwitch(OVS)的，所以我们要把它删除:</p>

<pre><code># apt-get purge -y openvswitch-common openvswitch-datapath-lts-saucy-dkms \
openvswitch-switch nova-network nova-api

</code></pre>

<p>验证openvswitch是否被彻底删除(应该输出空行才对):</p>

<pre><code># aptitude search -F '%p' '~i' | grep openvswitch

</code></pre>

<p>删除OVS的内核模块:</p>

<pre><code># lsmod | grep openvswitch &amp;&amp; rmmod openvswitch

</code></pre>

<p>移除virbr0端口:</p>

<pre><code># virsh net-destroy default
# virsh net-undefine default

</code></pre>

<p>确保在所有节点的/etc/network/interface.d/下，只包括了ifcfg-eth0, ifcfg-eth4, 其他都需要被删除。<br />
重启所有OpenStack Compute节点，以删除所有openvswitch和nova-network相关的iptables规则、接口等。</p>

<pre><code># reboot 

</code></pre>

<p>重启以后，以下面的命令确保没有NAT规则存在:</p>

<pre><code># iptables -L -t nat

</code></pre>

<p>在所有的Compute节点上，安装Contrail vrouter 组件:</p>

<pre><code># apt-get install -y contrail-openstack-vrouter

</code></pre>

<p>所有节点上，配置vhost0和ifcfg-eth4:</p>

<pre><code>root@node-18:~# vim /etc/network/interfaces.d/ifcfg-vhost0 
auto vhost0
iface vhost0 inet static
    netmask 255.255.255.0
    network_name application
    address 10.77.77.15
    gateway 10.77.77.1
    mtu 1300
root@node-18:~# vim /etc/network/interfaces.d/ifcfg-eth4 
auto eth4
iface eth4 inet manual

up ip l set eth4 up
down ip l set eth4 down

post-up  ethtool  -K  eth4  gso off  gro off || true

</code></pre>

<p>创建agent_param文件:</p>

<pre><code># mv /etc/contrail/agent_param.tmpl /etc/contrail/agent_param
# vim /etc/contrail/agent_param
dev=eth4

</code></pre>

<p>设置vroute-agent配置:</p>

<pre><code># vim /etc/contrail/contrail-vrouter-agent.conf
[DEFAULT]
headless_mode=true
[DISCOVERY]
server=10.77.77.9
max_control_nodes=2
[HYPERVISOR]
type=kvm
[NETWORKS]
control_network_ip=10.77.77.15
[VIRTUAL-HOST-INTERFACE]
name=vhost0
ip=10.77.77.15/24
gateway=10.77.77.1
physical_interface=eth4

</code></pre>

<p>在每个OpenStack Compute节点上，配置:</p>

<pre><code># vim /etc/contrail/vrouter_nodemgr_param
DISCOVERY=10.77.77.9

</code></pre>

<p>配置nova-compute:</p>

<pre><code> # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_url http://10.77.77.9:9696
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_auth_url http://10.55.55.4:35357/v2.0/
 # openstack-config --set /etc/nova/nova.conf DEFAULT network_api_class nova_contrail_vif.contrailvif.ContrailNetworkAPI
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_tenant_name services
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_username neutron
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_password rVlaAKUs
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_url_timeout 300
 # openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver
 # openstack-config --set /etc/nova/nova.conf DEFAULT security_group_api neutron
 # service supervisor-vrouter restart

</code></pre>

<p>验证所有的vrouter服务都是active状态的:</p>

<pre><code>root@node-18:~# contrail-status 
== Contrail vRouter ==
supervisor-vrouter:           active
contrail-vrouter-agent        active              
contrail-vrouter-nodemgr      active              

</code></pre>

<p>更改/etc/libvirt/qemu.confg中的cgroup_device_acl部分:</p>

<pre><code>cgroup_device_acl = [
&quot;/dev/null&quot;, &quot;/dev/full&quot;, &quot;/dev/zero&quot;,
&quot;/dev/random&quot;, &quot;/dev/urandom&quot;,
&quot;/dev/ptmx&quot;, &quot;/dev/kvm&quot;, &quot;/dev/kqemu&quot;,
&quot;/dev/rtc&quot;, &quot;/dev/hpet&quot;,&quot;/dev/net/tun&quot;,
]

</code></pre>

<p>在每个OpenStack Compute节点上，添加iptables规则如下并保存:</p>

<pre><code># iptables -I INPUT 1 -s 169.254.0.0/16 -i vhost0 -j ACCEPT -m comment --comment &quot;metadata service&quot;
# iptables -I INPUT 1 -p tcp -m multiport --destination-ports 2049,8085,9090,8102,33617,39704,44177,55970,60663 -j ACCEPT -m comment --comment &quot;juniper contrail rules&quot;
# iptables-save &gt; /etc/iptables/rules.v4

</code></pre>

<p>重启libvirt-bin和nova-compute服务:</p>

<pre><code># service libvirt-bin restart
# service nova-compute restart

</code></pre>

<p>更改vrouter的配置, ！！！注意，这是在Contrail Deploy的那个节点运行的！！！！ ：</p>

<pre><code># python /opt/contrail/utils/provision_vrouter.py --host_name node-18 --host_ip 10.77.77.15 --api_server_ip 10.77.77.9 --admin_user neutron --admin_password rVlaAKUs --admin_tenant_name services --oper add

</code></pre>

<h3 id="vgw配置">VGW配置</h3>

<p>OpenContrail支持多种配置，例如Juniper vSRX, Juniper MX, Cisco ASR等，但这些都需要专有硬件的支持（路由器），我们仅仅采用软件路由器Vrouter, 这里我们配置VGW:</p>

<pre><code># export PYTHONPATH=/usr/lib/python2.7/dist-packages/contrail_vrouter_api/gen_py/instance_service
# python /opt/contrail/utils/provision_vgw_interface.py --oper create --interface vgw --subnets 10.88.88.0/24 --routes 0.0.0.0/0 --vrf default-domain:admin:ext:ext

</code></pre>

<p>更新/etc/contrail/contrail-vrouter-agent.con中的[GATEWAY-0]部分:</p>

<pre><code>[GATEWAY-0]
routing_instance=default-domain:admin:ext:ext
interface=vgw
ip_blocks=10.88.88.0/24
routes=0.0.0.0/0

</code></pre>

<p>重新启动supervisor-vrouter进程:</p>

<pre><code># service supervisor-vrouter restart

</code></pre>

<p>重启其他所有的encapsulation方法，除了MPLS On UPD:<br />
<img src="/images/2015_04_27_22_45_01_799x306.jpg" alt="/images/2015_04_27_22_45_01_799x306.jpg" /></p>

<p>```</p>

<p>好了，这时候，Contrail已经集成到OpenStack环境里，你可以在Contrail的界面里，添加上网络，而后在OpenStack里使用它。Enjoy it !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/22/shi-yong-fuelbu-shu-opencontrail-1/">使用Fuel部署OpenContrail(1)</a>
      </h1>
      <span class="post-date">Apr 22, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/22/shi-yong-fuelbu-shu-opencontrail-1/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">Virtualization</a>
        
      </span>
      
      

<p>最近在做OpenContrail的解耦合操作，因为官方提供的OpenContrail一键安装包里诸多组件都是用的默认的推荐，通过解耦合可以做到更灵活的安装和配置，有利于更方便的部署和后续的维护。所以这一系列文章是关于如何用Fuel在部署完OpenStack的基础上完成OpenContrail的部署。</p>

<h3 id="先决条件">先决条件</h3>

<p>先决条件主要是用于准备用于部署的硬件环境和软件包。<br />
硬件环境:<br />
i5-4460(3.2GHz/4核/6M三级缓存), 32G 内存。<br />
系统:<br />
Ubuntu 14.04 LTS<br />
软件:</p>

<pre><code>$ sudo apt-get install libvirtd virt-manager

</code></pre>

<p>从Miranti网站下载： MirantisOpenStack-6.0.iso<br />
从Contrail网站下载: contrail-install-packages_2.0-22~icehouse_all.deb<br />
contrail-neutron-plugin仓库:</p>

<pre><code>git clone https://github.com/Juniper/contrail-neutron-plugin.git

</code></pre>

<h3 id="cpu-内存-磁盘规划">CPU/内存/磁盘规划</h3>

<p>需要构建一共8台虚拟机用于在部署好的Mirantis OpenStack上集成OpenContrail. CPU/内存/磁盘规划如下:<br />
1台Mirantis Fuel控制节点机,2核,划分3G内存, 100G磁盘。
3个OpenStack Controller节点, 2核,各划分3G内存, 100G磁盘。<br />
1个OpenStack Compute节点，2核(嵌套虚拟化),划分3G内存, 100G磁盘。<br />
3个OpenContrail节点，2核,各划分4G内存, 100G磁盘。<br />
一共需要27G内存。磁盘格式为qcow2，实际占用远小于这个数，各个节点最大也就是在5G左右大小。<br />
其中，关于嵌套虚拟化的CPU设置，如下图, 记得选择Copy host CPU Configuration:<br />
<img src="/images/2015_04_27_12_20_40_598x372.jpg" alt="/images/2015_04_27_12_20_40_598x372.jpg" /><br />
启用嵌套虚拟化需要在BIOS设置，并添加相应的内核模块。</p>

<h3 id="网络规划">网络规划</h3>

<p>Fuel OpenStack规划了5个网络，分别是:<br />
Admin(PXE)<br />
Public<br />
Management<br />
Storage<br />
Private</p>

<p>我们在Virt-Manager里也同样创建出这样的五个子网:<br />
Admin(PXE) &ndash; FuelNAT  &ndash; 10.20.0.0/24<br />
Public &ndash; FuelPublic  &ndash; 172.16.0.0/24<br />
Management &ndash; FuelMgmt &ndash; 10.55.55.0/24<br />
Storage  &ndash; FuelStorage &ndash; 10.66.66.0/24<br />
Private  &ndash; FuelPrivate &ndash; 10.77.77.0/24</p>

<p>创建网络的步骤如下，双击Virtual Machine Manager里的localhost(QEMU), 弹出下面的窗口:<br />
<img src="/images/2015_04_27_14_57_37_499x379.jpg" alt="/images/2015_04_27_14_57_37_499x379.jpg" /><br />
点击网络列表最下面的+号,弹出创建网络的窗口:<br />
<img src="/images/2015_04_27_14_58_52_543x374.jpg" alt="/images/2015_04_27_14_58_52_543x374.jpg" /><br />
命名该网络，点击下一步:<br />
<img src="/images/2015_04_27_15_00_34_549x371.jpg" alt="/images/2015_04_27_15_00_34_549x371.jpg" /><br />
禁用DHCP:<br />
<img src="/images/2015_04_27_16_37_32_544x374.jpg" alt="/images/2015_04_27_16_37_32_544x374.jpg" /><br />
选择isolated网络模式:<br />
<img src="/images/2015_04_27_16_38_34_551x375.jpg" alt="/images/2015_04_27_16_38_34_551x375.jpg" /><br />
接着点击下一步直到完成，这样我们的网络就创建好了。<br />
用上面的方法创建出以上5个子网。</p>

<h3 id="各个节点网络配置">各个节点网络配置</h3>

<p>Miranti Fuel Node: 仅FuelNAT, 安装完毕后，自动指定地址为10.20.0.2.<br />
其他所有节点机，在创建时，把五个网络都添加上，添加方法如下:<br />
Details -&gt; Add Hardware -&gt; Network, 而后选择:<br />
<img src="/images/2015_04_27_16_45_34_765x444.jpg" alt="/images/2015_04_27_16_45_34_765x444.jpg" /></p>

<h3 id="miranti-fuel-node安装">Miranti Fuel Node安装</h3>

<p>安装很简单，直接用下载的MirantisOpenStack-6.0.iso作为安装光盘，在创建出来的虚拟机里安装系统。安装完毕后，在Host机器的浏览器里访问<br />
<a href="http://10.20.0.2:8000">http://10.20.0.2:8000</a><br />
输入用户名密码都为admin后，登录，可以看到以下界面:<br />
<img src="/images/2015_04_27_16_55_29_717x477.jpg" alt="/images/2015_04_27_16_55_29_717x477.jpg" /><br />
在这个界面里我们可以进行OpenStack环境的准备、部署、配置、销毁等操作。</p>

<p>到这一步，我们已经完成了Miranti Fuel Node的安装，基本的部署准备工作已经完成，接下来我们将使用Fuel来部署一个可用的OpenStack环境, 以及三台用于部署Contrail的节点机.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/17/glusterfs-howto/">Glusterfs Howto</a>
      </h1>
      <span class="post-date">Apr 17, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/17/glusterfs-howto/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/storage">storage</a>
        
      </span>
      
      

<p>I want to expand my storage size on DigitalOcean, the droplet I have on DO one have 11G, and the other have 15G size, so if I could combine them together, I could do much more development on it. Following is how-to.</p>

<h3 id="glusterfs-setup">Glusterfs Setup</h3>

<p>Install it under Ubuntu via:</p>

<pre><code># apt-get install glusterfs-server

</code></pre>

<p>In both node, install the same software, and then add following lines into your /etc/hosts:</p>

<pre><code>10.17.17.195    Gluster2
10.17.17.194    Gluster1

</code></pre>

<p>In Gluster1, probe Gluster2:</p>

<pre><code>root@Gluster1:~# gluster peer probe Gluster2
peer probe: success

</code></pre>

<p>Then view the gluster peer status:</p>

<pre><code>root@Gluster1:~# gluster peer status
Number of Peers: 1

Hostname: Gluster2
Port: 24007
Uuid: 881dedb8-6cd4-4127-8c96-223daef081f5
State: Peer in Cluster (Connected)

</code></pre>

<p>Create the volumn via:</p>

<pre><code>root@Gluster1:~# gluster volume create vol_replica transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
volume create: vol_replica: success: please start the volume to access data

</code></pre>

<p>Start the created vol:</p>

<pre><code>root@Gluster1:~# gluster volume start vol_replica
volume start: vol_replica: success

</code></pre>

<p>View volumn info:</p>

<pre><code>root@Gluster1:~# gluster volume info 
 
Volume Name: vol_replica
Type: Distribute
Volume ID: 953456f3-0c46-4d07-ac41-591d1e398be6
Status: Started
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: Gluster2:/home/glustervms
Brick2: Gluster1:/home/glustervms

</code></pre>

<p>Now create the folder and mount the glusterfs via:</p>

<pre><code>root@Gluster1:/home# mkdir glustervmsmnt
root@Gluster1:/home# mount -t glusterfs Gluster1:/vol_replica /home/glustervmsmnt/

</code></pre>

<p>View the disk filesystem info:</p>

<pre><code>Gluster1:/vol_replica   39G  4.7G   32G  13% /home/glustervmsmnt

</code></pre>

<h3 id="glusterfs-volumn-deletion">Glusterfs Volumn deletion</h3>

<p>The replica is not the one we want, for combine two partitions, I need the Distributed stripped mode, which is the one described in:<br />
<a href="http://www.gluster.org/community/documentation/index.php/Gluster_3.2:_Creating_Distributed_Striped_Volumes">http://www.gluster.org/community/documentation/index.php/Gluster_3.2:_Creating_Distributed_Striped_Volumes</a><br />
So first I have to delete the one I&rsquo;ve created in the above part.<br />
First umount the one I&rsquo;ve created:</p>

<pre><code>root@Gluster1:/home/glustervms# umount /home/glustervmsmnt 

</code></pre>

<p>checked via <code>mount</code> or <code>df -h</code> we could see the one we have mounted has been umounted.</p>

<p>Second, stop the volumes we&rsquo;ve created:</p>

<pre><code>root@Gluster1:/home/glustervms# gluster volume stop vol_replica
Stopping volume will make its data inaccessible. Do you want to continue? (y/n) y
volume stop: vol_replica: success

</code></pre>

<p>Third, delete volumn:</p>

<pre><code>root@Gluster1:/home/glustervms# gluster volume delete vol_replica
Deleting volume will erase all information about the volume. Do you want to continue? (y/n) y
volume delete: vol_replica: success

</code></pre>

<p>Check the volume status:</p>

<pre><code>root@Gluster1:/home/glustervms# gluster volume info
No volumes present

</code></pre>

<h3 id="create-the-distributed-stripped-volume">Create the distributed stripped volume</h3>

<p>Create the bigvolume:</p>

<pre><code>root@Gluster1:/home/glustervms# gluster volume create bigvolume transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force

</code></pre>

<p>Start the volume:</p>

<pre><code>root@Gluster1:/home/glustervms# gluster volume start bigvolume
volume start: bigvolume: success

</code></pre>

<p>View the status of the volume:</p>

<pre><code>root@Gluster1:/home/glustervmsmnt# gluster volume info 
 
Volume Name: bigvolume
Type: Distribute
Volume ID: 3e09f074-4675-46d3-873f-f00ef13fb509
Status: Started
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: Gluster2:/home/glustervms
Brick2: Gluster1:/home/glustervms

</code></pre>

<p>Mount it via following command:</p>

<pre><code># mount -t glusterfs Gluster1:/bigvolume /home/glustervmsmnt/

</code></pre>

<h3 id="trouble-shooting">Trouble-Shooting</h3>

<pre><code>root@Gluster1:/home/glustervms# gluster volume create bigvolume transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
volume create: bigvolume: failed: /home/glustervms or a prefix of it is already part of a volume

</code></pre>

<p>Resolve it via:</p>

<pre><code>#  apt-get install attr
#  setfattr -x trusted.glusterfs.volume-id /home/glustervms
#  setfattr -x trusted.gfid /home/glustervms
#  rm -rf /home/glustervms/.glusterfs/

</code></pre>

<p>Re-run the gluster volome create command it will create the volume which combines two folders.</p>

<h3 id="digital-ocean-scenario">Digital Ocean Scenario</h3>

<p>My DO droplet runs Ubuntu and CentOS, their version is Trusty(14.04) and CentOS7, so do following:</p>

<pre><code>CentOS # wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repo
CentOS # yum -y install glusterfs glusterfs-fuse glusterfs-server
CentOS # systemctl start glusterd
CentOS # systemctl enable glusterd
Trusty # apt-get install glusterfs-server

</code></pre>

<p>Add each other&rsquo;s name and ip address into /etc/hosts, make sure they could ping each other and get responsible:</p>

<pre><code>1xx.xx.xxx.xxx	CentOS
1xx.xx.xxx.xx	Trusty

</code></pre>

<p>Use Trusty as the server, so on the Trusty machine, detect the CentOS&rsquo;s glusterd configuration as:</p>

<pre><code>Trusty # gluster peer probe CentOS
peer probe: success

</code></pre>

<p>Check the status:</p>

<pre><code>Trusty # gluster peer status
Number of Peers: 1

Hostname: CentOS
Port: 24007
Uuid: xxxxxxxx
State: Peer in Cluster (Connected)

</code></pre>

<p>Create the bigvolume, and mount it into your own directory via:</p>

<pre><code>Trusty # gluster volume create bigvolume transport tcp CentOS:/home/glustervms Trusty:/home/glustervms force
volume create: bigvolume: success: please start the volume to access data
Trusty # gluster volume start bigvolume
volume start: bigvolume: success
Trusty # gluster volume info
 
Volume Name: bigvolume
Type: Distribute
Volume ID: xxxxxxxxxxxxxxxxxxxxx
Status: Started
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: CentOS:/home/glustervms
Brick2: Trusty:/home/glustervms
Trusty # mkdir /home/glustervmsmnt/
Trusty # mount -t glusterfs Trusty:/bigvolume /home/glustervmsmnt/
Trusty # df -h
Filesystem              Size  Used Avail Use% Mounted on
/dev/vda1                20G  9.4G  9.2G  51% /
none                    4.0K     0  4.0K   0% /sys/fs/cgroup
udev                    235M  8.0K  235M   1% /dev
tmpfs                    50M  396K   49M   1% /run
none                    5.0M     0  5.0M   0% /run/lock
none                    246M  1.1M  244M   1% /run/shm
none                    100M     0  100M   0% /run/user
Trusty:/bigvolume       40G   14G   24G  37% /home/glustervmsmnt

</code></pre>

<p>Now you could operate under the /home/glustervmsmnt and you have 24G size partion of the disk. Enjoy them!!!</p>

<h3 id="trouble-shooting-1">Trouble-Shooting 1</h3>

<p>If you met <code>File change as we read it</code> in tar something, do following things:</p>

<pre><code>Trusty # gluster volume set bigvolume performance.stat-prefetch off
volume set: success

</code></pre>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://purplepalmdash.github.io/2015/04/16/build-fuel-icehouse-iso/">Build fuel icehouse iso</a>
      </h1>
      <span class="post-date">Apr 16, 2015  &middot; <a href="http://purplepalmdash.github.io/2015/04/16/build-fuel-icehouse-iso/#disqus_thread">Comments</a>
      
      <br/>
      <a class="a_cat" href="http://purplepalmdash.github.io/categories/virtualization">virtualization</a>
        
      </span>
      
      

<p>Fuel6.0 didn&rsquo;t support icdhouse by default, so we have to build it manually, the steps are listed as following:</p>

<pre><code>apt-get install git
mkdir ~/fuel
cd ~/fuel
git clone https://github.com/stackforge/fuel-main.git
cd fuel-main
 ./prepare-build-env.sh
export MIRROR_BASE=http://mirror.fuel-infra.org/fwm/6.0-icehouse
make iso

</code></pre>

<p>After making the iso which have icehouse will be available.</p>

<h3 id="troubleshooting">TroubleShooting</h3>

<p>Some modifications should be made before we make them:</p>

<pre><code>Trusty@ubuntu1204:~/code/fuel6.0/fuel-main$ git checkout stable/6.0
Branch stable/6.0 set up to track remote branch stable/6.0 from origin.
Switched to a new branch 'stable/6.0'
Trusty@ubuntu1204:~/code/fuel6.0/fuel-main$ git branch
  master
* stable/6.0

</code></pre>

      
    </div>
    
    
    
    <ul class="pagination">
        
        <li>
            <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
        </li>
        
        <li
        >
        <a href="/page/43/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
        </li>
        
        <li
        ><a href="/">1</a></li>
        
        <li
        ><a href="/page/2/">2</a></li>
        
        <li
        ><a href="/page/3/">3</a></li>
        
        <li
        ><a href="/page/4/">4</a></li>
        
        <li
        ><a href="/page/5/">5</a></li>
        
        <li
        ><a href="/page/6/">6</a></li>
        
        <li
        ><a href="/page/7/">7</a></li>
        
        <li
        ><a href="/page/8/">8</a></li>
        
        <li
        ><a href="/page/9/">9</a></li>
        
        <li
        ><a href="/page/10/">10</a></li>
        
        <li
        ><a href="/page/11/">11</a></li>
        
        <li
        ><a href="/page/12/">12</a></li>
        
        <li
        ><a href="/page/13/">13</a></li>
        
        <li
        ><a href="/page/14/">14</a></li>
        
        <li
        ><a href="/page/15/">15</a></li>
        
        <li
        ><a href="/page/16/">16</a></li>
        
        <li
        ><a href="/page/17/">17</a></li>
        
        <li
        ><a href="/page/18/">18</a></li>
        
        <li
        ><a href="/page/19/">19</a></li>
        
        <li
        ><a href="/page/20/">20</a></li>
        
        <li
        ><a href="/page/21/">21</a></li>
        
        <li
        ><a href="/page/22/">22</a></li>
        
        <li
        ><a href="/page/23/">23</a></li>
        
        <li
        ><a href="/page/24/">24</a></li>
        
        <li
        ><a href="/page/25/">25</a></li>
        
        <li
        ><a href="/page/26/">26</a></li>
        
        <li
        ><a href="/page/27/">27</a></li>
        
        <li
        ><a href="/page/28/">28</a></li>
        
        <li
        ><a href="/page/29/">29</a></li>
        
        <li
        ><a href="/page/30/">30</a></li>
        
        <li
        ><a href="/page/31/">31</a></li>
        
        <li
        ><a href="/page/32/">32</a></li>
        
        <li
        ><a href="/page/33/">33</a></li>
        
        <li
        ><a href="/page/34/">34</a></li>
        
        <li
        ><a href="/page/35/">35</a></li>
        
        <li
        ><a href="/page/36/">36</a></li>
        
        <li
        ><a href="/page/37/">37</a></li>
        
        <li
        ><a href="/page/38/">38</a></li>
        
        <li
        ><a href="/page/39/">39</a></li>
        
        <li
        ><a href="/page/40/">40</a></li>
        
        <li
        ><a href="/page/41/">41</a></li>
        
        <li
        ><a href="/page/42/">42</a></li>
        
        <li
        ><a href="/page/43/">43</a></li>
        
        <li
        class="active"><a href="/page/44/">44</a></li>
        
        <li
        ><a href="/page/45/">45</a></li>
        
        <li
        ><a href="/page/46/">46</a></li>
        
        <li
        ><a href="/page/47/">47</a></li>
        
        <li
        ><a href="/page/48/">48</a></li>
        
        <li
        ><a href="/page/49/">49</a></li>
        
        <li
        ><a href="/page/50/">50</a></li>
        
        <li
        ><a href="/page/51/">51</a></li>
        
        <li
        ><a href="/page/52/">52</a></li>
        
        <li
        ><a href="/page/53/">53</a></li>
        
        <li
        ><a href="/page/54/">54</a></li>
        
        <li
        ><a href="/page/55/">55</a></li>
        
        <li
        ><a href="/page/56/">56</a></li>
        
        <li
        ><a href="/page/57/">57</a></li>
        
        <li
        ><a href="/page/58/">58</a></li>
        
        <li
        ><a href="/page/59/">59</a></li>
        
        <li
        ><a href="/page/60/">60</a></li>
        
        <li
        ><a href="/page/61/">61</a></li>
        
        <li
        ><a href="/page/62/">62</a></li>
        
        <li
        ><a href="/page/63/">63</a></li>
        
        <li
        ><a href="/page/64/">64</a></li>
        
        <li
        ><a href="/page/65/">65</a></li>
        
        <li
        ><a href="/page/66/">66</a></li>
        
        <li
        ><a href="/page/67/">67</a></li>
        
        <li
        ><a href="/page/68/">68</a></li>
        
        <li
        ><a href="/page/69/">69</a></li>
        
        <li
        ><a href="/page/70/">70</a></li>
        
        <li
        ><a href="/page/71/">71</a></li>
        
        <li
        ><a href="/page/72/">72</a></li>
        
        <li
        ><a href="/page/73/">73</a></li>
        
        <li
        ><a href="/page/74/">74</a></li>
        
        <li
        ><a href="/page/75/">75</a></li>
        
        <li
        ><a href="/page/76/">76</a></li>
        
        <li
        ><a href="/page/77/">77</a></li>
        
        <li
        ><a href="/page/78/">78</a></li>
        
        <li
        ><a href="/page/79/">79</a></li>
        
        <li
        ><a href="/page/80/">80</a></li>
        
        <li
        ><a href="/page/81/">81</a></li>
        
        <li
        ><a href="/page/82/">82</a></li>
        
        <li
        ><a href="/page/83/">83</a></li>
        
        <li
        ><a href="/page/84/">84</a></li>
        
        <li
        ><a href="/page/85/">85</a></li>
        
        <li
        ><a href="/page/86/">86</a></li>
        
        <li
        ><a href="/page/87/">87</a></li>
        
        <li
        ><a href="/page/88/">88</a></li>
        
        <li
        ><a href="/page/89/">89</a></li>
        
        <li
        ><a href="/page/90/">90</a></li>
        
        <li
        ><a href="/page/91/">91</a></li>
        
        <li
        ><a href="/page/92/">92</a></li>
        
        <li
        ><a href="/page/93/">93</a></li>
        
        <li
        ><a href="/page/94/">94</a></li>
        
        <li
        ><a href="/page/95/">95</a></li>
        
        <li
        ><a href="/page/96/">96</a></li>
        
        <li
        ><a href="/page/97/">97</a></li>
        
        <li
        ><a href="/page/98/">98</a></li>
        
        <li
        ><a href="/page/99/">99</a></li>
        
        <li
        ><a href="/page/100/">100</a></li>
        
        <li
        ><a href="/page/101/">101</a></li>
        
        <li
        ><a href="/page/102/">102</a></li>
        
        <li
        ><a href="/page/103/">103</a></li>
        
        <li
        ><a href="/page/104/">104</a></li>
        
        <li
        ><a href="/page/105/">105</a></li>
        
        <li
        ><a href="/page/106/">106</a></li>
        
        <li
        ><a href="/page/107/">107</a></li>
        
        <li
        ><a href="/page/108/">108</a></li>
        
        <li
        ><a href="/page/109/">109</a></li>
        
        <li
        ><a href="/page/110/">110</a></li>
        
        <li
        ><a href="/page/111/">111</a></li>
        
        <li
        ><a href="/page/112/">112</a></li>
        
        <li
        ><a href="/page/113/">113</a></li>
        
        <li
        ><a href="/page/114/">114</a></li>
        
        <li
        ><a href="/page/115/">115</a></li>
        
        <li
        ><a href="/page/116/">116</a></li>
        
        <li
        ><a href="/page/117/">117</a></li>
        
        <li
        ><a href="/page/118/">118</a></li>
        
        <li
        ><a href="/page/119/">119</a></li>
        
        <li
        ><a href="/page/120/">120</a></li>
        
        <li
        ><a href="/page/121/">121</a></li>
        
        <li
        ><a href="/page/122/">122</a></li>
        
        <li
        ><a href="/page/123/">123</a></li>
        
        <li
        ><a href="/page/124/">124</a></li>
        
        <li
        ><a href="/page/125/">125</a></li>
        
        <li
        ><a href="/page/126/">126</a></li>
        
        <li
        ><a href="/page/127/">127</a></li>
        
        <li
        ><a href="/page/128/">128</a></li>
        
        <li
        ><a href="/page/129/">129</a></li>
        
        <li
        ><a href="/page/130/">130</a></li>
        
        <li
        ><a href="/page/131/">131</a></li>
        
        <li
        ><a href="/page/132/">132</a></li>
        
        <li
        ><a href="/page/133/">133</a></li>
        
        <li
        >
        <a href="/page/45/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
        </li>
        
        <li>
            <a href="/page/133/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
        </li>
        
    </ul>
    
  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "dashsagittariussglory";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<script src="http://purplepalmdash.github.io/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>

