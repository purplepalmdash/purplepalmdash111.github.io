<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Virtualization on Dash</title>
    <link>http://purplepalmdash.github.io/categories/virtualization/</link>
    <description>Recent content in Virtualization on Dash</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Aug 2016 17:29:36 +0800</lastBuildDate>
    <atom:link href="http://purplepalmdash.github.io/categories/virtualization/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>WorkTipsOnOpenStackDeployment</title>
      <link>http://purplepalmdash.github.io/blog/2016/08/31/worktipsonopenstackdeployment/</link>
      <pubDate>Wed, 31 Aug 2016 17:29:36 +0800</pubDate>
      
      <guid>http://purplepalmdash.github.io/blog/2016/08/31/worktipsonopenstackdeployment/</guid>
      <description>

&lt;h3 id=&#34;repository-sync&#34;&gt;Repository Sync&lt;/h3&gt;

&lt;p&gt;The current version of OpenStack could be found in:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://releases.openstack.org/&#34;&gt;https://releases.openstack.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Mitaka is the recent version.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mitaka	Current stable release, security-supported	2016-04-07	2017-04-10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ubuntu repository could be found at:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ubuntu-cloud.archive.canonical.com/ubuntu/dists/&#34;&gt;http://ubuntu-cloud.archive.canonical.com/ubuntu/dists/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Use apt-mirror for syncing them. Current the ubuntu1404 is well supported.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OnXenServerBridgeWorkingTips2</title>
      <link>http://purplepalmdash.github.io/blog/2016/08/19/onxenserverbridgeworkingtips2/</link>
      <pubDate>Fri, 19 Aug 2016 14:37:59 +0800</pubDate>
      
      <guid>http://purplepalmdash.github.io/blog/2016/08/19/onxenserverbridgeworkingtips2/</guid>
      <description>

&lt;h3 id=&#34;virtualbox-setup&#34;&gt;VirtualBox Setup&lt;/h3&gt;

&lt;p&gt;Define a virtual machine:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_36_05_517x355.jpg&#34; alt=&#34;/images/2016_08_19_14_36_05_517x355.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Use 7G of 8G memory for this VM:&lt;br /&gt;
&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_36_27_520x358.jpg&#34; alt=&#34;/images/2016_08_19_14_36_27_520x358.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Create a new disk(200G), choose VDI, Dynamically allocated, And specify the location
for storing it.&lt;/p&gt;

&lt;p&gt;Now create the virtual machine, and configure its networking like following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_45_56_691x410.jpg&#34; alt=&#34;/images/2016_08_19_14_45_56_691x410.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;CPUs, we allocated 4:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_48_55_532x197.jpg&#34; alt=&#34;/images/2016_08_19_14_48_55_532x197.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And also the acceleration configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_50_06_380x171.jpg&#34; alt=&#34;/images/2016_08_19_14_50_06_380x171.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Storage Configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_51_57_544x202.jpg&#34; alt=&#34;/images/2016_08_19_14_51_57_544x202.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For saving the resources, disable USB/Audio.&lt;/p&gt;

&lt;p&gt;Now insert the XenServer Installation CDROM, and install it.&lt;/p&gt;

&lt;h3 id=&#34;xenserver-configuration&#34;&gt;XenServer Configuration&lt;/h3&gt;

&lt;p&gt;IP Address, for bridged networking:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_56_46_486x268.jpg&#34; alt=&#34;/images/2016_08_19_14_56_46_486x268.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DNS Configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_19_14_58_02_434x249.jpg&#34; alt=&#34;/images/2016_08_19_14_58_02_434x249.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;NTP Server Configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server 0.cn.pool.ntp.org
server 0.asia.pool.ntp.org
server 2.asia.pool.ntp.org
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now Install the XenServer.&lt;/p&gt;

&lt;p&gt;After installation, apply xs patches.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OnXenServerBridgeWorkingTips</title>
      <link>http://purplepalmdash.github.io/blog/2016/08/18/onxenserverbridgeworkingtips/</link>
      <pubDate>Thu, 18 Aug 2016 19:29:45 +0800</pubDate>
      
      <guid>http://purplepalmdash.github.io/blog/2016/08/18/onxenserverbridgeworkingtips/</guid>
      <description>

&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;

&lt;p&gt;I will use XenServer for testing, while I made a vagrant box of XenServer 6.5, it could
work properly in seperated networking, so following I will try to setup a bridged
&amp;ldquo;XenServer&amp;rdquo; which will acts like a real physical machine.&lt;/p&gt;

&lt;h3 id=&#34;vagrantfile&#34;&gt;Vagrantfile&lt;/h3&gt;

&lt;p&gt;The configuration part is listed as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  # csagentxen65 node.
  # Add one networking, modify hostname, define memory, CPU cores.
  config.vm.define :csagentxen65 do |csagentxen65|
    csagentxen65.vm.box = &amp;quot;Xen65Box&amp;quot;
    csagentxen65.vm.boot_timeout = &#39;36000&#39;
    csagentxen65.vm.hostname = CLOUDSTACK_AGENT_HOSTNAME
    csagentxen65.vm.network :public_network, 
	    :dev =&amp;gt; &amp;quot;br0&amp;quot;,
	    :mode =&amp;gt; &amp;quot;bridge&amp;quot;,
	    :type =&amp;gt; &amp;quot;bridge&amp;quot;,
	    :ip =&amp;gt; &amp;quot;192.168.10.3&amp;quot;
    # Disable mounting of vagrant folder as it&#39;s not supported on xenserver
    csagentxen65.vm.synced_folder &amp;quot;.&amp;quot;, &amp;quot;/vagrant&amp;quot;, disabled: true
    csagentxen65.vm.provider :libvirt do |domain|
      domain.memory = 8192
      domain.cpus = 4
      domain.storage_pool_name = &#39;XenStoragePool&#39;
      domain.nested = true
      domain.cpu_mode = &#39;host-passthrough&#39;
      domain.nic_model_type = &#39;e1000&#39;
      domain.management_network_mac = &amp;quot;08:00:27:1D:90:A8&amp;quot;
    end
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we used our newly created storage pool, I use virt-manager for creating a new
storage pool, which is in a seprated disk, could gain much more IOPS.&lt;/p&gt;

&lt;h3 id=&#34;bug-fix&#34;&gt;Bug-Fix&lt;/h3&gt;

&lt;p&gt;vagrant-libvirt will create 2 ethernet port, while the default one is xenbr0, but we
want the xenbr1 be the management port.&lt;/p&gt;

&lt;p&gt;Gain a administration shell:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_18_19_34_41_498x510.jpg&#34; alt=&#34;/images/2016_08_18_19_34_41_498x510.jpg&#34; /&gt;&lt;br /&gt;
Enter following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ifconfig eth1 netmask 255.255.0.0
# route add default gw 192.168.0.xxx eth1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can run ansible-playbook against the XenServer, but it will stuck.&lt;/p&gt;

&lt;p&gt;Now manually configure eth1&amp;rsquo;s netmask and its gateway. ansible-playbook could be run
properly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CloudStackSiteToSiteVPNHowTo</title>
      <link>http://purplepalmdash.github.io/blog/2016/08/10/cloudstacksitetositevpnhowto/</link>
      <pubDate>Wed, 10 Aug 2016 14:29:27 +0800</pubDate>
      
      <guid>http://purplepalmdash.github.io/blog/2016/08/10/cloudstacksitetositevpnhowto/</guid>
      <description>

&lt;p&gt;Recently I am investigating the VPN solution on company&amp;rsquo;s private cloud. Some guys
insist on setting up the site-to-site VPN on Juniper&amp;rsquo;s firewall(SR240), but I think
this is a piece of shit. Setting up the VPN on physical firewall will lose the &lt;code&gt;ease of
use&lt;/code&gt; and &lt;code&gt;ease of configuration&lt;/code&gt; of CloudStack&amp;rsquo;s built-in VPN functionality, so
following are the steps for me to investigate the CloudStack&amp;rsquo;s site-to-site VPN among
different vpcs. Follow the guide line you will get two or more geographical independent
sites working as in a big ethernet.&lt;/p&gt;

&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;The environment is pretty simple, you need 2 PCs(Or more) for experiment.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_14_45_50_603x334.jpg&#34; alt=&#34;/images/2016_08_10_14_45_50_603x334.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Working Machine 1&amp;rsquo;s configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz
24 G Memory
1000M Ethernet Card
More than 20G Free disk    
ArchLinux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Working Machine 2&amp;rsquo;s configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Intel(R) Core(TM) i3 CPU         540  @ 3.07GHz
8 G Memory
1000M Ethernet Card
More than 20G Free disk    
ArchLinux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Make sure the nested KVM is configurated in both machine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ systool -m kvm_intel -v | grep nested
    nested              = &amp;quot;Y&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also make sure you have a Linux Bridge(Not the physical card or OpenVswitch Bridge!).&lt;/p&gt;

&lt;h3 id=&#34;testing-vm&#34;&gt;Testing VM&lt;/h3&gt;

&lt;p&gt;We create two virtual machines for installing cloudstack all in one environment, like
following picture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_14_53_23_652x427.jpg&#34; alt=&#34;/images/2016_08_10_14_53_23_652x427.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Virtual Machine 1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;4 core(host-passthrough CPU)
8G Memory
200G Disk
Bridged to br0
CentOS 6.8 X86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Virtual Machine 2(Because working Machine 2 only have 8G memory, we allocated 7G to
it):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;4 core(host-passthrough CPU)
7G Memory
200G Disk
Bridged to br0
CentOS 6.8 X86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The network configuration is listed as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_14_56_33_689x188.jpg&#34; alt=&#34;/images/2016_08_10_14_56_33_689x188.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Specified &lt;code&gt;shared&lt;/code&gt; is very important, or you won&amp;rsquo;t get networking works.&lt;/p&gt;

&lt;p&gt;We named VirtualMachine1 to &lt;code&gt;vpn1452&lt;/code&gt;, VirtualMachine2 to &lt;code&gt;vpn2452&lt;/code&gt;, because we do the
investigation based on CloudStack 4.5.2 version.&lt;/p&gt;

&lt;h3 id=&#34;vpn1452&#34;&gt;vpn1452&lt;/h3&gt;

&lt;p&gt;vpn1452&amp;rsquo;s IP Address is &lt;code&gt;172.16.0.2&lt;/code&gt;, we started from the CloudStack management
webpage:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_45_14_487x432.jpg&#34; alt=&#34;/images/2016_08_10_15_45_14_487x432.jpg&#34; /&gt;&lt;br /&gt;
Click &lt;code&gt;I have used cloudstack before&lt;/code&gt;, continue to configurate the environment.&lt;/p&gt;

&lt;p&gt;Change the options of following:&lt;/p&gt;

&lt;p&gt;Secondary storage allow(value: 172.16.0.0/16):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_47_49_1140x252.jpg&#34; alt=&#34;/images/2016_08_10_15_47_49_1140x252.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Local Storage, systemvm.use to true:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_49_05_1022x371.jpg&#34; alt=&#34;/images/2016_08_10_15_49_05_1022x371.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Save the configuration via restart the cloudstack-management service &lt;code&gt;service
cloudstack-management restart&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Create a new zone(Select Advanced zone):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_51_37_642x407.jpg&#34; alt=&#34;/images/2016_08_10_15_51_37_642x407.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Zone Name and DNS:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_52_40_417x464.jpg&#34; alt=&#34;/images/2016_08_10_15_52_40_417x464.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Select hypervisor and enable local storages:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_53_32_472x345.jpg&#34; alt=&#34;/images/2016_08_10_15_53_32_472x345.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Public Networking configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_55_01_614x108.jpg&#34; alt=&#34;/images/2016_08_10_15_55_01_614x108.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hit add and hit next:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_55_38_637x132.jpg&#34; alt=&#34;/images/2016_08_10_15_55_38_637x132.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A New pod named &lt;code&gt;pod1452&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_56_46_472x404.jpg&#34; alt=&#34;/images/2016_08_10_15_56_46_472x404.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Guest Traffic :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_57_24_367x202.jpg&#34; alt=&#34;/images/2016_08_10_15_57_24_367x202.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cluster Name:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_58_05_495x100.jpg&#34; alt=&#34;/images/2016_08_10_15_58_05_495x100.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Add Host(172.16.0.2):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_58_57_428x294.jpg&#34; alt=&#34;/images/2016_08_10_15_58_57_428x294.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Secondary storage:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_15_59_44_433x211.jpg&#34; alt=&#34;/images/2016_08_10_15_59_44_433x211.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hit next and finally enable the zone:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_01_22_508x449.jpg&#34; alt=&#34;/images/2016_08_10_16_01_22_508x449.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wait for a while to see the infrastucture works properly.&lt;/p&gt;

&lt;h4 id=&#34;create-vpc&#34;&gt;Create VPC&lt;/h4&gt;

&lt;p&gt;Hit Network-&amp;gt; VPC, &lt;code&gt;Add VPC&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_06_21_760x141.jpg&#34; alt=&#34;/images/2016_08_10_16_06_21_760x141.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Add a new VPC like following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_07_07_405x442.jpg&#34; alt=&#34;/images/2016_08_10_16_07_07_405x442.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wait for VR start up, when VR becomes ready, add a new tier via clicking &lt;code&gt;Configure&lt;/code&gt;
button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_08_39_662x145.jpg&#34; alt=&#34;/images/2016_08_10_16_08_39_662x145.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_09_35_377x324.jpg&#34; alt=&#34;/images/2016_08_10_16_09_35_377x324.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Your new vpc and tier will be viewed as following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_10_14_712x412.jpg&#34; alt=&#34;/images/2016_08_10_16_10_14_712x412.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Add an instance which in the new tier,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_11_37_638x254.jpg&#34; alt=&#34;/images/2016_08_10_16_11_37_638x254.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Examine the instance&amp;rsquo;s ip configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_13_21_340x313.jpg&#34; alt=&#34;/images/2016_08_10_16_13_21_340x313.jpg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;vpn2452&#34;&gt;vpn2452&lt;/h3&gt;

&lt;p&gt;The steps are mainly the same as in vpn1452, but with the following parameters:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zone name: zone2452
public: 10.168.72.110~10.168.72.129
podname: pod2452
pod ip: 172.16.0.130~172.16.0.149
host: 172.16.0.3
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;vpc2452&#34;&gt;vpc2452&lt;/h4&gt;

&lt;p&gt;Configuration for vpc2452:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_29_05_383x430.jpg&#34; alt=&#34;/images/2016_08_10_16_29_05_383x430.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;tier 2452:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_30_21_398x340.jpg&#34; alt=&#34;/images/2016_08_10_16_30_21_398x340.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now use a instance for testing the tier2452:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_34_15_456x306.jpg&#34; alt=&#34;/images/2016_08_10_16_34_15_456x306.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Without site-to-site vpn, testing ping:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_35_24_380x180.jpg&#34; alt=&#34;/images/2016_08_10_16_35_24_380x180.jpg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;site-to-site-vpn&#34;&gt;Site-to-Site VPN&lt;/h3&gt;

&lt;p&gt;We will configure both side, first we create vpc1452:&lt;/p&gt;

&lt;h4 id=&#34;vpc1452&#34;&gt;vpc1452&lt;/h4&gt;

&lt;p&gt;Fist use following command for generating the key:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# dd if=/dev/random count=16 bs=1 | xxd -ps
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Record the key, for later on vpc2452 we will use the same key for configurating the
site-to-site VPN.&lt;/p&gt;

&lt;p&gt;Click vpc&amp;rsquo;s configure button, to get the configuration window:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_43_48_600x145.jpg&#34; alt=&#34;/images/2016_08_10_16_43_48_600x145.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Click the &lt;code&gt;site-to-site VPNS&lt;/code&gt;, a VPN Gateway will be generated:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_44_51_568x151.jpg&#34; alt=&#34;/images/2016_08_10_16_44_51_568x151.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Create a VPN Customer Gateway, like following configuration:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_46_14_352x511.jpg&#34; alt=&#34;/images/2016_08_10_16_46_14_352x511.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice, the Gateway&lt;code&gt;10.168.72.112&lt;/code&gt; is generated in the same procedure in vpn2452 side.
the CIDR list is the vpn2452 side&amp;rsquo;s tier ip ranges, ipsec preshared-key is gerated via
&lt;code&gt;dd&lt;/code&gt; commands.&lt;/p&gt;

&lt;p&gt;Now a new &lt;code&gt;vpnto2452&lt;/code&gt; vpn customer gateway is generated,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_48_17_661x142.jpg&#34; alt=&#34;/images/2016_08_10_16_48_17_661x142.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Back to vpc window, site-to-site vpn, create a new vpn connection:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_49_18_683x123.jpg&#34; alt=&#34;/images/2016_08_10_16_49_18_683x123.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The configuration for the VPN connection is listed as: notice we must select Passive:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_50_11_341x185.jpg&#34; alt=&#34;/images/2016_08_10_16_50_11_341x185.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now the created VPN Connection is like following, remains state &lt;code&gt;Disconnected&lt;/code&gt; because
it will be triggered via VPN2452&amp;rsquo;s dial-in.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_51_16_692x152.jpg&#34; alt=&#34;/images/2016_08_10_16_51_16_692x152.jpg&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;vpc2452-1&#34;&gt;vpc2452&lt;/h4&gt;

&lt;p&gt;The vpc and &lt;code&gt;site-to-site VPNS&lt;/code&gt; configuration is the same as vpc1452, for VPN Customer
Gateway, the configuration is listed :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_57_50_364x533.jpg&#34; alt=&#34;/images/2016_08_10_16_57_50_364x533.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;a new VPN Customer Gateway is created as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_58_45_702x166.jpg&#34; alt=&#34;/images/2016_08_10_16_58_45_702x166.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then back to &lt;code&gt;site-to-site&lt;/code&gt; VPN connection, create a new VPN connection:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_16_59_41_393x216.jpg&#34; alt=&#34;/images/2016_08_10_16_59_41_393x216.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DO NOT select passive, because this one will be activate the remote(vpc1452)&amp;rsquo;s VPN
connection.&lt;/p&gt;

&lt;p&gt;A new connection will be setup:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_17_00_48_734x210.jpg&#34; alt=&#34;/images/2016_08_10_17_00_48_734x210.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now the created instance in vpc2452 will get reach with the instance which runs in vpc1452:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_17_02_09_356x288.jpg&#34; alt=&#34;/images/2016_08_10_17_02_09_356x288.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_17_03_02_347x138.jpg&#34; alt=&#34;/images/2016_08_10_17_03_02_347x138.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can login to the VR for examing the ipsec processes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_17_04_17_604x317.jpg&#34; alt=&#34;/images/2016_08_10_17_04_17_604x317.jpg&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;back-to-vpc1452&#34;&gt;Back to vpc1452&lt;/h4&gt;

&lt;p&gt;Now the site-to-site vpn status has changed to:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_08_10_17_05_27_766x177.jpg&#34; alt=&#34;/images/2016_08_10_17_05_27_766x177.jpg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;The cloudstack&amp;rsquo;s site-to-site VPN functionality is very easy to use. Use it we could
easily setup the connections between different VPCs across Internet.&lt;/p&gt;

&lt;p&gt;Later I will show how to setup the site-to-site VPN with OpenStack and other platforms.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XenServer Statistics</title>
      <link>http://purplepalmdash.github.io/2016/07/01/xenserver-statistics/</link>
      <pubDate>Fri, 01 Jul 2016 17:45:50 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/07/01/xenserver-statistics/</guid>
      <description>&lt;p&gt;Direct write rrd into graphite, refers to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/jgilmour/XenGraphiteIT.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you get the storage pool information fro xsconsole via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ xe vdi-list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice it will contain the hard disk and iso repositories, use harddisk.&lt;/p&gt;

&lt;p&gt;Now edit the .config file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[XENAPI]
URL = http://192.168.10.187
USERNAME = root
PASSWORD = xxxxxxx
SR-UUID = 51977c4b-8dc2-bcff-b7ad-de7cc5c7e717

[GRAPHITE]
CARBON_HOST = 192.168.1.79
CARBON_PORT = 2003
CARBON_NAME = collectd.com.IT.servers.xen.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run &lt;code&gt;python2 xengraphite.py&lt;/code&gt; you could get your XenServer statistic data into your
graphite database, enjoy it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>site-to-site VPN</title>
      <link>http://purplepalmdash.github.io/2016/06/29/site-to-site-vpn/</link>
      <pubDate>Wed, 29 Jun 2016 18:51:40 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/06/29/site-to-site-vpn/</guid>
      <description>

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;Refers to:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://clauseriksen.net/2011/02/02/ipsec-on-debianubuntu/&#34;&gt;https://clauseriksen.net/2011/02/02/ipsec-on-debianubuntu/&lt;/a&gt;&lt;br /&gt;
And
&lt;a href=&#34;http://xmodulo.com/create-site-to-site-ipsec-vpn-tunnel-openswan-linux.html&#34;&gt;http://xmodulo.com/create-site-to-site-ipsec-vpn-tunnel-openswan-linux.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;network-topology&#34;&gt;Network Topology&lt;/h3&gt;

&lt;p&gt;The topology is listed as following:&lt;/p&gt;

&lt;p&gt;Host1 &amp;ndash; LAN1 &amp;ndash; Router1 &amp;ndash;[BIG, BAD INTERNET]&amp;ndash; Router2 &amp;ndash; LAN2 &amp;ndash; Host2&lt;/p&gt;

&lt;p&gt;Router1 and Router2 are Ubuntu14.04 machine, which runs in virt-manager,thus you have
to create 2 new networks, each in one physical machine.&lt;/p&gt;

&lt;p&gt;Physical Machine 1: 192.168.1.79&lt;br /&gt;
Router1:&lt;br /&gt;
eth0: bridge to physical machine&amp;rsquo;s networking. 192.168.10.100&lt;br /&gt;
eth1: 10.47.70.2.&lt;br /&gt;
DHCP on eth1.&lt;/p&gt;

&lt;p&gt;Physical Machine 2: 192.168.1.69&lt;br /&gt;
Router2:&lt;br /&gt;
eth0: bridge to physical machine&amp;rsquo;s networking. 192.168.10.200&lt;br /&gt;
eth1: 10.47.67.2.&lt;br /&gt;
DHCP on eth1.&lt;/p&gt;

&lt;h3 id=&#34;router-network-configuration&#34;&gt;Router Network Configuration&lt;/h3&gt;

&lt;p&gt;Router1&amp;rsquo;s networking configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/network/interfaces
    # The loopback network interface
    auto lo
    iface lo inet loopback
    
    # The primary network interface
    auto eth0
    iface eth0 inet static
    address 192.168.10.100
    netmask 255.255.0.0
    gateway 192.168.0.176
    dns-nameservers 223.5.5.5
    
    auto eth1
    iface eth1 inet static
    address 10.47.70.2
    netmask 255.255.255.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Router2&amp;rsquo;s networking configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/network/interfaces
    # The loopback network interface
    auto lo
    iface lo inet loopback
    
    # The primary network interface
    auto eth0
    iface eth0 inet static
    address 192.168.10.200
    netmask 255.255.0.0
    gateway 192.168.0.176
    dns-nameservers 223.5.5.5
    auto eth1
    iface eth1 inet static
    address 10.47.67.2
    netmask 255.255.255.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After configuration , restart the Router1 and Router2.&lt;/p&gt;

&lt;h3 id=&#34;ipsec-configuration&#34;&gt;IPSEC Configuration&lt;/h3&gt;

&lt;h4 id=&#34;router1&#34;&gt;Router1&lt;/h4&gt;

&lt;p&gt;Install following package:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo apt-get install -y openswan
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Append following lines at the end of &lt;code&gt;/etc/sysctl.conf&lt;/code&gt;,then run &lt;code&gt;sysctl -p
/etc/sysctl.conf&lt;/code&gt; to take effects.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/sysctl.conf
net.ipv4.ip_forward=1
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
net.ipv4.conf.eth0.send_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.eth0.accept_redirects = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also you have to disable the redirects via following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for vpn in /proc/sys/net/ipv4/conf/*;
do echo 0 &amp;gt; $vpn/accept_redirects;
echo 0 &amp;gt; $vpn/send_redirects;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;iptables rules should be done via following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -A INPUT -p udp --dport 500 -j ACCEPT
iptables -A INPUT -p tcp --dport 4500 -j ACCEPT
iptables -A INPUT -p udp --dport 4500 -j ACCEPT
iptables -t nat -A POSTROUTING -s 10.47.70.0/24 -d 10.47.67.0/24 -j SNAT --to 192.168.10.100
#iptables -t nat -A POSTROUTING -s site-A-private-subnet -d site-B-private-subnet -j SNAT --to site-A-Public-IP
iptables -A POSTROUTING -t nat -d 10.47.70.0/24 -o eth1 -m policy --dir out --pol ipsec -j ACCEPT
iptables -A INPUT -m policy --dir in --pol ipsec -j ACCEPT
iptables -A INPUT -p udp -m multiport --dports 500,4500 -j ACCEPT
iptables -A INPUT -p esp -j ACCEPT
iptables -A FORWARD -m policy --dir in --pol ipsec -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now continue to configure the ipsec:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vim /etc/ipsec.conf
    ## general configuration parameters ##
     
    config setup
            plutodebug=all
            plutostderrlog=/var/log/pluto.log
            protostack=netkey
            nat_traversal=yes
            virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12
            ## disable opportunistic encryption in Red Hat ##
            oe=off
     
    ## disable opportunistic encryption in Debian ##
    ## Note: this is a separate declaration statement ##
    #include /etc/ipsec.d/examples/no_oe.conf 
     
    ## connection definition in Debian ##
    conn demo-connection-debian
            authby=secret
            auto=start
            ## phase 1 ##
            keyexchange=ike
            ## phase 2 ##
            esp=3des-md5
            pfs=yes
            type=tunnel
            left=192.168.10.100
            leftsourceip=192.168.10.100
            leftsubnet=10.47.70.0/24
            ## for direct routing ##
            #leftsubnet=192.168.10.100/32
            #leftnexthop=%defaultroute
            leftnexthop=192.168.10.200
            right=192.168.10.200
            rightsubnet=10.47.67.0/24
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the left/right configuration, should corresponding the our definition
of the networking.&lt;/p&gt;

&lt;p&gt;Now generate the pre-shared keys via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ dd if=/dev/random count=24 bs=1 | xxd -ps
24+0 records in
24+0 records out
24 bytes copied, 4.5529e-05 s, 527 kB/s
cece1b0ffe27f82c27efc94339f08c418abb9e5f5c0d5bf5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the &lt;code&gt;cece1b0ffe27f82c27efc94339f08c418abb9e5f5c0d5bf5&lt;/code&gt; is the keys we want to
fill into the secrets:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo cat /etc/ipsec.secrets 
    # This file holds shared secrets or RSA private keys for inter-Pluto
    # authentication.  See ipsec_pluto(8) manpage, and HTML documentation.
    
    # RSA private key for this host, authenticating it to any other host
    # which knows the public part.  Suitable public keys, for ipsec.conf, DNS,
    # or configuration of other implementations, can be extracted conveniently
    # with &amp;quot;ipsec showhostkey&amp;quot;.
    
    # this file is managed with debconf and will contain the automatically created RSA keys
    include /var/lib/openswan/ipsec.secrets.inc
    192.168.10.100  192.168.10.200:  PSK  &amp;quot;cece1b0ffe27f82c27efc94339f08c418abb9e5f5c0d5bf5&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now Router1 is configured, we continue to configure Router2.&lt;/p&gt;

&lt;h4 id=&#34;router2&#34;&gt;Router2&lt;/h4&gt;

&lt;p&gt;Ipsec and sysctl are the same as in Router1, the iptables scripts is listed as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -A INPUT -p udp --dport 500 -j ACCEPT
iptables -A INPUT -p tcp --dport 4500 -j ACCEPT
iptables -A INPUT -p udp --dport 4500 -j ACCEPT
iptables -t nat -A POSTROUTING -s 10.47.67.0/24 -d 10.47.70.0/24 -j SNAT --to 192.168.10.200

#iptables -A POSTROUTING -t nat -d 192.168.1.0/24 -o eth0 -m policy --dir out --pol ipsec -j ACCEPT
iptables -A POSTROUTING -t nat -d 10.47.67.0/24 -o eth1 -m policy --dir out --pol ipsec -j ACCEPT
iptables -A INPUT -m policy --dir in --pol ipsec -j ACCEPT
iptables -A INPUT -p udp -m multiport --dports 500,4500 -j ACCEPT
iptables -A INPUT -p esp -j ACCEPT
iptables -A FORWARD -m policy --dir in --pol ipsec -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now configure the ipsec.conf like following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vim /etc/ipsec.conf
## general configuration parameters ##
 
config setup
        plutodebug=all
        plutostderrlog=/var/log/pluto.log
        protostack=netkey
        nat_traversal=yes
        virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12
        ## disable opportunistic encryption in Red Hat ##
        oe=off
 
## disable opportunistic encryption in Debian ##
## Note: this is a separate declaration statement ##
#include /etc/ipsec.d/examples/no_oe.conf 
 
## connection definition in Debian ##
conn demo-connection-debian
        authby=secret
        auto=start
        ## phase 1 ##
        keyexchange=ike
        ## phase 2 ##
        esp=3des-md5
        pfs=yes
        type=tunnel
        left=192.168.10.200
        leftsourceip=192.168.10.200
        leftsubnet=10.47.67.0/24
        ## for direct routing ##
        #leftsubnet=192.168.10.200/32
        #leftnexthop=%defaultroute
        leftnexthop=192.168.10.100
        right=192.168.10.100
        rightsubnet=10.47.70.0/24
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the definition&amp;rsquo;s differences comparing to Router1.&lt;/p&gt;

&lt;p&gt;The ipsec.secrets is the same as Router1, but you have to change like following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vim /etc/ipsec.secrets
192.168.10.200  192.168.10.100:  PSK  &amp;quot;3030804556207bde9fc5c9a043c6ac13fce136ce41eb98a6&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examine&#34;&gt;Examine&lt;/h3&gt;

&lt;p&gt;Restart the ipsec services on both Router.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo  /etc/init.d/ipsec restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Examine the route via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;adminubuntu@vpn1:~$ ip route
default via 192.168.0.176 dev eth0 
10.47.67.0/24 dev eth0  scope link  src 192.168.10.100 
10.47.70.0/24 dev eth1  proto kernel  scope link  src 10.47.70.2 
192.168.0.0/16 dev eth0  proto kernel  scope link  src 192.168.10.100 
adminubuntu@vpn2:~$ ip route
default via 192.168.0.176 dev eth0 
10.47.67.0/24 dev eth1  proto kernel  scope link  src 10.47.67.2 
10.47.70.0/24 dev eth0  scope link  src 192.168.10.200 
192.168.0.0/16 dev eth0  proto kernel  scope link  src 192.168.10.200 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So we can see the route shows the connection of the vpn.&lt;/p&gt;

&lt;p&gt;Now examine the ipsec status:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service ipsec status
IPsec running  - pluto pid: 930
pluto pid 930
1 tunnels up
some eroutes exist
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More detailed infos could be examine via: &lt;code&gt;sudo ipsec auto --status&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;dhcp-server&#34;&gt;DHCP Server&lt;/h3&gt;

&lt;p&gt;Install dhcpd and configure it via following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo apt-get install -y isc-dhcp-server
$ sudo vim /etc/default/isc-dhcp-server
INTERFACES=&amp;quot;eth1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Append following lines to &lt;code&gt;/etc/dhcp/dhcpd.conf&lt;/code&gt;:&lt;br /&gt;
Router1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;subnet
10.47.70.0 netmask 255.255.255.0 {
# --- default gateway
option routers
10.47.70.2;
# --- Netmask
option subnet-mask
255.255.255.0;
# --- Broadcast Address
option broadcast-address
10.47.70.255;
# --- Domain name servers, tells the clients which DNS servers to use.
option domain-name-servers
223.5.5.5,180.76.76.76;
option time-offset 0;
range 10.47.70.3 10.47.70.254;
default-lease-time 1209600;
max-lease-time 1814400;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Router2:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;subnet
10.47.67.0 netmask 255.255.255.0 {
# --- default gateway
option routers
10.47.67.2;
# --- Netmask
option subnet-mask
255.255.255.0;
# --- Broadcast Address
option broadcast-address
10.47.67.255;
# --- Domain name servers, tells the clients which DNS servers to use.
option domain-name-servers
223.5.5.5,180.76.76.76;
option time-offset 0;
range 10.47.67.3 10.47.67.254;
default-lease-time 1209600;
max-lease-time 1814400;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now your subnet is ready, restart the Router1 and Router2, next step we will
verify our site-to-site VPN.&lt;/p&gt;

&lt;h3 id=&#34;verification&#34;&gt;Verification&lt;/h3&gt;

&lt;p&gt;Create 2 new vm on 2 physical machine, each of them attached to our Router&amp;rsquo;s
eth1 networking. I use tinycore for experiment.&lt;/p&gt;

&lt;p&gt;Tinycore Attaches to Router1:&lt;br /&gt;
&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_06_29_19_23_50_469x212.jpg&#34; alt=&#34;/images/2016_06_29_19_23_50_469x212.jpg&#34; /&gt;&lt;br /&gt;
Tinycore Attaches to Router2:&lt;br /&gt;
&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_06_29_19_25_18_497x351.jpg&#34; alt=&#34;/images/2016_06_29_19_25_18_497x351.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The picture also shows the ping each other without any problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RackHD Worktips</title>
      <link>http://purplepalmdash.github.io/2016/06/07/rackhd-worktips/</link>
      <pubDate>Tue, 07 Jun 2016 17:05:19 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/06/07/rackhd-worktips/</guid>
      <description>

&lt;h3 id=&#34;vagrant-preparation&#34;&gt;Vagrant Preparation&lt;/h3&gt;

&lt;p&gt;rackhd/rackhd vagrant box could be downloaded from following link:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://atlas.hashicorp.com/rackhd/boxes/rackhd&#34;&gt;https://atlas.hashicorp.com/rackhd/boxes/rackhd&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clone the repository from the github:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pwd
/home/dash/Code/Jun13
$ git clone https://github.com/RackHD/RackHD
$ cd RackHD
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Change into the directory example, create config and run the setup command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd example
$ cp config/monorail_rack.cfg.example config/monorail_rack.cfg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edits can be made to this new file to adjust the number of pxe clients created.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/monorail_rack
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;monorail_rack&lt;/code&gt; script will auto-start all of the services by default, but you can also run them manually if you prefer.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant ssh
vagrant:~$ sudo nf start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unfortunately, the vagrant machine won&amp;rsquo;t work due to bad networking.&lt;/p&gt;

&lt;h3 id=&#34;customization-deployment&#34;&gt;Customization Deployment&lt;/h3&gt;

&lt;p&gt;Use a trusty based vagrant box for creating the rackhd node.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant init trustyvirtualbox
$ vim Vagrantfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vagrantfile&amp;rsquo;s configuration modification is listed as following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Vagrant.configure(2) do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Added more disks
+   file_to_disk = File.realpath( &amp;quot;.&amp;quot; ).to_s + &amp;quot;/disk.vdi&amp;quot;

  # config.vm.network &amp;quot;private_network&amp;quot;, ip: &amp;quot;192.168.33.10&amp;quot;
+   config.vm.network &amp;quot;private_network&amp;quot;, ip: &amp;quot;172.31.128.1&amp;quot;, virtualbox__intnet:  &amp;quot;closednet&amp;quot;

+  config.vm.provider &amp;quot;virtualbox&amp;quot; do |vb|
+    if ARGV[0] == &amp;quot;up&amp;quot; &amp;amp;&amp;amp; ! File.exist?(file_to_disk) 
+      puts &amp;quot;Creating 5GB disk #{file_to_disk}.&amp;quot;
+      vb.customize [
+        &#39;createhd&#39;, 
+        &#39;--filename&#39;, file_to_disk, 
+        &#39;--format&#39;, &#39;VDI&#39;, 
+        &#39;--size&#39;, 5000 * 1024 # 5 GB
+      ] 
+      vb.customize [
+        &#39;storageattach&#39;, :id, 
+        &#39;--storagectl&#39;, &#39;IDE Controller&#39;, 
+        &#39;--port&#39;, 1, &#39;--device&#39;, 0, 
+        &#39;--type&#39;, &#39;hdd&#39;, &#39;--medium&#39;, 
+        file_to_disk
+      ] 
+    end
+    vb.memory = &amp;quot;4096&amp;quot;
+    vb.cpus = 2
+    vb.customize [&amp;quot;modifyvm&amp;quot;, :id, &amp;quot;--nicpromisc2&amp;quot;, &amp;quot;allow-all&amp;quot;, &amp;quot;--ioapic&amp;quot;, &amp;quot;on&amp;quot;]
+  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then &lt;code&gt;vagrant up&lt;/code&gt; for start up the machine.&lt;/p&gt;

&lt;p&gt;Notice: the controller of the disk should be noticed very carefully, you could choose
&amp;ldquo;IDE Controller&amp;rdquo; Or &amp;ldquo;SATA Controller&amp;rdquo;, depending on your virtualbox configuration.&lt;br /&gt;
Then follow the tips on:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://purplepalmdash.github.io/blog/2016/06/01/use-rakehd-for-deploying-systems/&#34;&gt;http://purplepalmdash.github.io/blog/2016/06/01/use-rakehd-for-deploying-systems/&lt;/a&gt;&lt;br /&gt;
Extend the root partition of vagrant disk via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo pvcreate /dev/sdb
$ sudo vgextend vagrant-vg /dev/sdb
$ sudo lvextend -l +100%FREE /dev/vagrant-vg/root
$ sudo resize2fs  /dev/vagrant-vg/root
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;adding-ubuntu-deployment&#34;&gt;Adding Ubuntu Deployment&lt;/h3&gt;

&lt;p&gt;Install &lt;code&gt;apt-mirror&lt;/code&gt; first, then using following mirror configuration file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/apt/mirror.list
############# config ##################
#
# set base_path    /var/spool/apt-mirror
#
# set mirror_path  $base_path/mirror
# set skel_path    $base_path/skel
# set var_path     $base_path/var
# set cleanscript $var_path/clean.sh
# set defaultarch  &amp;lt;running host architecture&amp;gt;
# set postmirror_script $var_path/postmirror.sh
# set run_postmirror 0
set base_path	/var/mirrors/ubuntu/14.04
set nthreads     20
set _tilde 0
#
############# end config ##############

deb-amd64 http://mirrors.aliyun.com/ubuntu	trusty main main/debian-installers
deb http://mirrors.aliyun.com/ubuntu	trusty main/installer-amd64
deb-amd64 http://mirrors.aliyun.com/ubuntu	trusty-updates main
deb-amd64 http://mirrors.aliyun.com/ubuntu	trusty-security main
clean http://mirrors.aliyun.com/ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also you have to create following script for downloading the debian-installer:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /var/mirrors/ubuntu/14.04/var/postmirror.sh 
#!/bin/sh -x 
# the udebs script gets the actual files we need 
#/mnt/repo/apt-mirror/var/udebs.sh  
# A quick apt directory structure primer: 
# an apt server (e.g. archive.ubuntu.com) contains repositories (e.g. trusty-backports), 
# which contain archives (e.g. multiverse), which contain directories 
# a complete example - http://archive.ubuntu.com/ubuntu/dists/trusty-backports/multiverse/debian-installer/  
# With this in mind, we create bash &#39;arrays&#39; of the structure: 
# server we&#39;re syncing against 
#MIRROR=&amp;quot;cn.archive.ubuntu.com&amp;quot; 
MIRROR=&amp;quot;archive.ubuntu.com&amp;quot; 
# repositories we&#39;re mirroring 
#REPOS=&amp;quot;trusty trusty-updates trusty-security trusty-proposed trusty-backports&amp;quot; 
REPOS=&amp;quot;trusty&amp;quot;
# archives in repositories 
#ARCHIVES=&amp;quot;main multiverse restricted universe&amp;quot; 
ARCHIVES=&amp;quot;main&amp;quot;
# installer location inside archive 
#DIRECTORIES=&amp;quot;debian-installer dist-upgrader-all installer-amd64 installer-i386&amp;quot; 
DIRECTORIES=&amp;quot;debian-installer installer-amd64&amp;quot;
#where we&#39;re storing it locally 
LOCALDIR=&amp;quot;/var/mirrors/ubuntu/14.04/mirror/mirrors.aliyun.com&amp;quot;
#LOCALDIR=&amp;quot;/mnt/repo/apt-mirror/mirror/archive.ubuntu.com&amp;quot;  
for REPO in $REPOS; do 
for ARCHIVE in $ARCHIVES; do 
for DIRECTORY in $DIRECTORIES;do 
# create directory structure 
if [ ! -e &amp;quot;$LOCALDIR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY&amp;quot; ]; then
mkdir -p &amp;quot;$LOCALDIR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY&amp;quot;
fi
# do the sync 
rsync --recursive --times --links --hard-links --delete --delete-after \
rsync://$MIRROR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY/ $LOCALDIR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY
done
done
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now run &lt;code&gt;sudo apt-mirror&lt;/code&gt; for syncing the repository to local storage.&lt;/p&gt;

&lt;p&gt;Also create a shortcut to the repository in RackHD System:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo ln -s /var/mirrors/ubuntu/14.04/mirror/mirrors.aliyun.com/ubuntu/ /opt/monorail/static/http/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now restart the rackhd node, the ubuntu deployment is ready for use.&lt;/p&gt;

&lt;h3 id=&#34;ubuntu-deployment&#34;&gt;Ubuntu Deployment&lt;/h3&gt;

&lt;p&gt;Add the json file which holds the ubuntu deployment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pwd
/home/vagrant/RackHD/example
$ vim samples/ubuntu_boot.json 
{
    &amp;quot;name&amp;quot;: &amp;quot;Graph.InstallUbuntu&amp;quot;,
    &amp;quot;options&amp;quot;: {
        &amp;quot;defaults&amp;quot;: {
            &amp;quot;obmServiceName&amp;quot;: &amp;quot;noop-obm-service&amp;quot;
        },
        &amp;quot;install-os&amp;quot;: {
            &amp;quot;repo&amp;quot;: &amp;quot;{{api.server}}/ubuntu&amp;quot;,
            &amp;quot;rootPassword&amp;quot;: &amp;quot;ubuntu&amp;quot;,
            &amp;quot;profile&amp;quot;: &amp;quot;install-trusty.ipxe&amp;quot;,
            &amp;quot;completionUri&amp;quot;: &amp;quot;renasar-ansible.pub&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In fact the &lt;code&gt;rootPassword&lt;/code&gt; is not ready for use, the real password after deployment
 is &lt;code&gt;RackHDRocks!&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Add one node(first you should make it pxed):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data @samples/noop_body.json http://localhost:8080/api/1.1/nodes/575fce38d23ba028051b4711/obm
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data @samples/ubuntu_boot.json http://localhost:8080/api/1.1/nodes/575fce38d23ba028051b4711/workflows
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then restart the machine, you will get it installing ubuntu.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use RackHD For Deploying Systems</title>
      <link>http://purplepalmdash.github.io/2016/06/01/use-rakehd-for-deploying-systems/</link>
      <pubDate>Wed, 01 Jun 2016 09:14:18 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/06/01/use-rakehd-for-deploying-systems/</guid>
      <description>

&lt;p&gt;Following are the steps for using the RackHD for deploying systems. Mainly refers to
&lt;a href=&#34;http://dojoblog.emc.com/rackhd-cpi/setting-up-rackhd/&#34;&gt;http://dojoblog.emc.com/rackhd-cpi/setting-up-rackhd/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But the tutorial from emc includes lots of mistakes, so I listed all of the steps in
following chapters.&lt;/p&gt;

&lt;h3 id=&#34;vagrant-env-preparation&#34;&gt;Vagrant Env Preparation&lt;/h3&gt;

&lt;p&gt;Initialize the vagrant env via(ubuntu1404 is my box name):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant init ubuntu1404
A `Vagrantfile` has been placed in this directory. 
$ vim Vagrantfile
  config.vm.provider &amp;quot;virtualbox&amp;quot; do |vb|
  #   # Display the VirtualBox GUI when booting the machine
  #   vb.gui = true
  #
  #   # Customize the amount of memory on the VM:
    vb.memory = &amp;quot;4096&amp;quot;
    vb.cpus = 4
    vb.customize [&amp;quot;modifyvm&amp;quot;, :id, &amp;quot;--nicpromisc2&amp;quot;, &amp;quot;allow-all&amp;quot;, &amp;quot;--ioapic&amp;quot;, &amp;quot;on&amp;quot;]
  end
$ vagrant up
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;Use following scripts for installing the prerequisites for RackHD(&lt;code&gt;pre_rackhd.sh&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash 
set -­e

sudo apt-get -y update
sudo apt-get -y dist-upgrade
sudo apt-get autoremove
sudo apt-get install -y nodejs nodejs-legacy npm

# Runtime Dependencies
sudo apt-get install -y rabbitmq-server mongodb isc-dhcp-server
sudo apt-get install -y snmp ipmitool ansible amtterm apt-mirror unzip libkrb5-dev

# upstart will be installed after Ubuntu15.04.
# sudo apt-get -y install upstart­sysv
sudo update-initramfs -u

# amttool
wget http://downloads.sourceforge.net/project/amttooltng/1.7/amttool
sudo chmod 777 amttool
sudo mv amttool /usr/bin/amttooltng

# Compile Dependencies
sudo apt-get install -y git openssh-server pbuilder dh-make devscripts ubuntu-dev-tools

# Git clone all of the repositories
RACKHD_INSTALL_DIR=~;cd $RACKHD_INSTALL_DIR
git clone https://github.com/RackHD/RackHD
RACKHD_PROJECT_DIR=${RACKHD_INSTALL_DIR}/RackHD
cd $RACKHD_PROJECT_DIR
git submodule update --init --recursive
git submodule foreach git pull origin master

# Configuration files
sudo touch /etc/default/on-http
sudo touch /etc/default/on-dhcp-proxy
sudo touch /etc/default/on-taskgraph
sudo touch /etc/default/on-syslog
sudo touch /etc/default/on-tftp

# Build And Install
cd ${RACKHD_PROJECT_DIR}/on-http
./HWIMO-BUILD
sudo dpkg -i on-http_*.deb
 
cd ${RACKHD_PROJECT_DIR}/on-dhcp-proxy
./HWIMO-BUILD
sudo dpkg -i on-dhcp-proxy_*.deb

cd ${RACKHD_PROJECT_DIR}/on-taskgraph
./HWIMO-BUILD
sudo dpkg -i on-taskgraph_*.deb

cd ${RACKHD_PROJECT_DIR}/on-syslog
./HWIMO-BUILD
sudo dpkg -i on-syslog_*.deb

cd ${RACKHD_PROJECT_DIR}/on-tftp
./HWIMO-BUILD
sudo dpkg -i on-tftp_*.deb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now shutdown the vm, add one networking interface, because we want to add PXE in this
network apdater.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim Vagrantfile
config.vm.network &amp;quot;private_network&amp;quot;, ip: &amp;quot;172.31.128.1&amp;quot;, virtualbox__intnet: &amp;quot;closednet&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now startup the vagrant vm again. continue to configure the PXE.&lt;/p&gt;

&lt;h3 id=&#34;configuration&#34;&gt;Configuration&lt;/h3&gt;

&lt;p&gt;Examine the eth1 IP Configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vagrant@ubuntu-1404:~$ ifconfig eth1
eth1      Link encap:Ethernet  HWaddr 08:00:27:c2:cf:3e  
          inet addr:172.31.128.1  Bcast:172.31.128.255  Mask:255.255.255.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure the isc-dhcp:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vim /etc/default/isc-dhcp-server
INTERFACES=&amp;quot;eth1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add the following configuration into &lt;code&gt;/etc/dhcp/dhcp.conf&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# RackHD Added Lines
deny duplicates;

ignore-client-uids true;

subnet 172.31.128.0 netmask 255.255.252.0 {
    range 172.31.128.2 172.31.131.254;
    # Use this option to signal to the PXE client that we are doing proxy DHCP
    option vendor-class-identifier &amp;quot;PXEClient&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download the config.json for monorail usage, and modify its tftpRoot Configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd /opt/monorail/
$ sudo wget https://raw.githubusercontent.com/RackHD/RackHD/master/packer/ansible/roles/monorail/files/config.json
$ sudo vim config.json
    &amp;quot;tftpRoot&amp;quot;: &amp;quot;/opt/monorail/static/tftp&amp;quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prepare the http and tftp folder:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /opt/monorail/static/http/common/
$ sudo mkdir -p /opt/monorail/static/tftp/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download the tftp and http static files:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd /opt/monorail/static/tftp
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/ipxe/monorail.ipxe
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/ipxe/monorail-undionly.kpxe
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/ipxe/monorail-efi32-snponly.efi
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/ipxe/monorail-efi64-snponly.efi
$ cd /opt/monorail/static/http/common/
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/builds/discovery.overlay.cpio.gz
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/builds/base.trusty.3.16.0-25-generic.squashfs.img
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/builds/initrd.img-3.16.0-25-generic
$ sudo wget https://bintray.com/artifact/download/rackhd/binary/builds/vmlinuz-3.16.0-25-generic
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now reboot the vm again, next step we will test the PXE boot.&lt;/p&gt;

&lt;h3 id=&#34;pxe-clients&#34;&gt;PXE Clients&lt;/h3&gt;

&lt;p&gt;The PXE will be avaiable and after it finishes, the vm will look like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_06_01_11_47_57_712x236.jpg&#34; alt=&#34;/images/2016_06_01_11_47_57_712x236.jpg&#34; /&gt;&lt;br /&gt;
Now you could get the node info via following RESTFUL api call:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:8080/api/1.1/nodes | python -m json.tool
        &amp;quot;createdAt&amp;quot;: &amp;quot;2016-06-01T03:44:09.064Z&amp;quot;,
        &amp;quot;id&amp;quot;: &amp;quot;574e5a0944ff724a05284005&amp;quot;,
        &amp;quot;identifiers&amp;quot;: [
            &amp;quot;08:00:27:02:5f:7a&amp;quot;
        ],
        &amp;quot;name&amp;quot;: &amp;quot;08:00:27:02:5f:7a&amp;quot;,

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Examine the mac correponding node ID &lt;code&gt;574e5a0944ff724a05284005&lt;/code&gt;, later we wil use this id for deploying CentOS.&lt;/p&gt;

&lt;h3 id=&#34;add-centos7-deployment&#34;&gt;Add CentOS7 Deployment&lt;/h3&gt;

&lt;p&gt;Add CentOS7 DVD into the deployment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo python ~/RackHD/on-tools/scripts/setup_iso.py /mnt/CentOS-7-x86_64-Everything-1511.iso  /opt/monorail/static/http --link=/home/vagrant/RackHD
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will takes around 10 mins for importing the iso into the RackHD.&lt;/p&gt;

&lt;p&gt;Configure the node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data @samples/noop_body.json http://localhost:8080/api/1.1/nodes/574e5a0944ff724a05284005/obm | python -m json.tool
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data @samples/centos_iso_boot.json http://localhost:8080/api/1.1/nodes/574e5a517c6c03440553dd0f/workflows | python -m json.tool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_06_01_14_12_33_449x503.jpg&#34; alt=&#34;/images/2016_06_01_14_12_33_449x503.jpg&#34; /&gt;&lt;br /&gt;
Then added the configuration for deploying CentOS7 via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd ~/RackHD/example/
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data @samples/noop_body.json http://localhost:8080/api/1.1/nodes/574e6516224a4449056183e7/obm | python -m json.tool
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data @samples/centos_iso_boot.json http://localhost:8080/api/1.1/nodes/574e6516224a4449056183e7/workflows | python -m json.tool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PXE the node, thus you will get a CentOS7 installed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setup LXD On Ubuntu1604</title>
      <link>http://purplepalmdash.github.io/2016/05/11/setup-lxd-on-ubuntu1604/</link>
      <pubDate>Wed, 11 May 2016 15:38:23 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/05/11/setup-lxd-on-ubuntu1604/</guid>
      <description>

&lt;h3 id=&#34;preparation&#34;&gt;Preparation&lt;/h3&gt;

&lt;p&gt;By default the lxd is installed in ubuntu1604.&lt;/p&gt;

&lt;h3 id=&#34;image&#34;&gt;Image&lt;/h3&gt;

&lt;p&gt;The image file are downloaded before we actually install it, install the image via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ lxc image import ubuntu-16.04-server-cloudimg-amd64-lxd.tar.xz ubuntu-16.04-server-cloudimg-amd64-root.tar.xz --alias ubuntu1604
$ lxc image list
+--------------+--------------+--------+--------------------------------------+--------+----------+------------------------------+
|    ALIAS     | FINGERPRINT  | PUBLIC |             DESCRIPTION              |  ARCH  |   SIZE   |         UPLOAD DATE          |
+--------------+--------------+--------+--------------------------------------+--------+----------+------------------------------+
| ubuntu1604   | f4c4c60a6b75 | no     | Ubuntu 16.04 LTS server (20160420.3) | x86_64 | 137.54MB | May 10, 2016 at 2:18pm (UTC) 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;start-container&#34;&gt;Start Container&lt;/h3&gt;

&lt;p&gt;Start the container via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ lxc launch ubuntu1604 first1404
$ lxc list
+------------+---------+------+------+------------+-----------+
|    NAME    |  STATE  | IPV4 | IPV6 |    TYPE    | SNAPSHOTS |
+------------+---------+------+------+------------+-----------+
| first1404  | RUNNING |      |      | PERSISTENT | 0         |
+------------+---------+------+------+------------+-----------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Attach to the running container via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ lxc exec first1404 /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this container you could do anything, for your customization of the container.&lt;/p&gt;

&lt;h3 id=&#34;more-images&#34;&gt;More Images&lt;/h3&gt;

&lt;p&gt;After your modification is done, shutdown the running container, and submit your
modification to a new container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ lxc publish second1604 --alias my-new-image
$ lxc image list
+--------------+--------------+--------+--------------------------------------+--------+----------+------------------------------+
|    ALIAS     | FINGERPRINT  | PUBLIC |             DESCRIPTION              |  ARCH  |   SIZE   |         UPLOAD DATE          |
+--------------+--------------+--------+--------------------------------------+--------+----------+------------------------------+
| my-new-image | 67de38342bfa | no     |                                      | x86_64 | 192.29MB | May 11, 2016 at 7:07am (UTC) |
+--------------+--------------+--------+--------------------------------------+--------+----------+------------------------------+
| ubuntu1604   | f4c4c60a6b75 | no     | Ubuntu 16.04 LTS server (20160420.3) | x86_64 | 137.54MB | May 10, 2016 at 2:18pm (UTC) |
+--------------+--------------+--------+--------------------------------------+--------+----------+------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;container-networking&#34;&gt;Container Networking&lt;/h3&gt;

&lt;p&gt;The default networking is a seperated network, but we could set the lxd using the hosted
network, via following steps:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/network/interfaces

auto ens3
iface ens3 inet manual

auto containerbr 
iface containerbr inet static
address 192.168.10.193
netmask 255.255.0.0
gateway 192.168.0.176
dns-nameservers 180.76.76.76
bridge_ports ens3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reboot the machine, you have the running bridge &lt;code&gt;containerbr&lt;/code&gt;, now you could set your bridge to this
newly created bridge:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ lxc profile device set default eth0 parent containerbr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Via this you cuold set the same subnet networking address just as in &lt;code&gt;containerbr&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working Tips On Mesos/Ansible</title>
      <link>http://purplepalmdash.github.io/2016/05/09/working-tips-on-mesos-slash-ansible/</link>
      <pubDate>Mon, 09 May 2016 12:20:34 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/05/09/working-tips-on-mesos-slash-ansible/</guid>
      <description>

&lt;h3 id=&#34;package-prepare&#34;&gt;Package Prepare&lt;/h3&gt;

&lt;p&gt;We have the default vagrant box generated by bento, listed it via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  mesos vagrant box list | grep -i centos | grep -i virtualbox
centos72                                     (virtualbox, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we want to generate a new box from it, and added our own configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant init centos72
$ vagrant up
$ vagrant ssh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit for keeping the cache:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/yum.conf  | more
[main]
cachedir=/home/vagrant/rpms/$basearch/$releasever
#keepcache=0
keepcache=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now poweroff the machine and export it to the new box:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant package --output centoslocalrpm.box
$ vagrant box add centoslocalrpm centoslocalrpm.box
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the new box, the rpm packages could be saved into the folder
&lt;code&gt;/home/vagrant/rpms&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;deploy-using-ansible&#34;&gt;Deploy Using Ansible&lt;/h3&gt;

&lt;p&gt;Refers to&lt;br /&gt;
&lt;a href=&#34;https://open.mesosphere.com/advanced-course/recreating-the-cluster-using-ansible/&#34;&gt;https://open.mesosphere.com/advanced-course/recreating-the-cluster-using-ansible/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working Tips on Ansible-cobbler(2)</title>
      <link>http://purplepalmdash.github.io/2016/05/06/working-tips-on-ansible-cobbler-2/</link>
      <pubDate>Fri, 06 May 2016 15:03:59 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/05/06/working-tips-on-ansible-cobbler-2/</guid>
      <description>

&lt;h3 id=&#34;aim&#34;&gt;AIM&lt;/h3&gt;

&lt;p&gt;Change the vagrant box to libvirt, and let this libvirt machine working properly.&lt;/p&gt;

&lt;h3 id=&#34;image-transformation&#34;&gt;Image Transformation&lt;/h3&gt;

&lt;p&gt;Transform the image via following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ VBoxManage clonehd /home/dash/VirtualBox\ VMs/ansible-cobbler_cobbler-ubuntu_1462410925173_15793/packer-virtualbox-iso-1454031074-disk1.vmdk /home/dash/output.img --format raw &amp;amp;&amp;amp; qemu-img convert -f raw /home/dash/output.img -O qcow2 /home/dash/ansible-cobbler.qcow2
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Clone medium created in format &#39;raw&#39;. UUID: 6fbb99be-8004-43b5-831b-ec794a001c10
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;qemu-virtual-machine&#34;&gt;Qemu Virtual Machine&lt;/h3&gt;

&lt;p&gt;Create a new machine, then configure the networking, edit the cobbler setting/dhcp setting, then &lt;code&gt;cobbler sync&lt;/code&gt;, now the cobbler is adjusting to new environment.&lt;/p&gt;

&lt;p&gt;More detailed info could be seen in:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://purplepalmdash.github.io/blog/2015/07/10/wh-worktips-9/&#34;&gt;http://purplepalmdash.github.io/blog/2015/07/10/wh-worktips-9/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working Tips On ansible-cobbler</title>
      <link>http://purplepalmdash.github.io/2016/05/04/working-tips-on-ansible-cobbler/</link>
      <pubDate>Wed, 04 May 2016 15:36:55 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/05/04/working-tips-on-ansible-cobbler/</guid>
      <description>

&lt;h3 id=&#34;source&#34;&gt;Source&lt;/h3&gt;

&lt;p&gt;The source are downloaded from:&lt;br /&gt;
&lt;a href=&#34;https://github.com/signed8bit/ansible-cobbler&#34;&gt;https://github.com/signed8bit/ansible-cobbler&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Git clone it via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/signed8bit/ansible-cobbler.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;test&#34;&gt;Test&lt;/h3&gt;

&lt;p&gt;The test will be done via &lt;code&gt;vagrant up&lt;/code&gt;, while we met the problem: the cobbler version
in ansible playbooks are too old, thus the command &lt;code&gt;cobbler get-loaders&lt;/code&gt; won&amp;rsquo;t acts
well. we have to changing to the newest cobbler version which is available in&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://cobbler.github.io/&#34;&gt;http://cobbler.github.io/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;manually-steps-ubuntu&#34;&gt;Manually Steps(Ubuntu)&lt;/h3&gt;

&lt;p&gt;Install the newest cobbler via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget -qO - http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/xUbuntu_14.04/Release.key | sudo apt-key add -
$ sudo add-apt-repository &amp;quot;deb http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/xUbuntu_14.04/ ./&amp;quot;
$ sudo apt-get install -y cobbler 
$ cobbler --version
Cobbler 2.6.11
  source: ?, ?
  build time: Sat Jan 23 14:13:42 2016
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Change Password of the &lt;code&gt;cobbler&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Change the password for the &#39;cobbler&#39; username:
htdigest /etc/cobbler/users.digest &amp;quot;Cobbler&amp;quot; cobbler
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;visit the url of &lt;code&gt;http://xxx.xxx.xxx.xx/cobbler_web&lt;/code&gt; and you could access the management interface of cobbler.&lt;/p&gt;

&lt;h3 id=&#34;import-centos7-2&#34;&gt;Import CentOS7.2&lt;/h3&gt;

&lt;p&gt;Import the iso via following command&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mount -t iso9660 -o loop ./CentOS-7-x86_64-Everything-1511.iso /mnt1
$ sudo cobbler import --name=CentOS-7.2 --arch=x86_64 --path=/mnt1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Examine the imported iso:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@cobbler-ubuntu:~# cobbler profile list
   CentOS-7.2-x86_64
root@cobbler-ubuntu:~# cobbler distro list
   CentOS-7.2-x86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Change the default password of root:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# openssl passwd -1
# vim /etc/cobbler/settings 
- default_password_crypted: &amp;quot;$1$mF86/UHC$WvcIcX2t6crBz2onWxyac.&amp;quot;
+ default_password_crypted: &amp;quot;$awegwaegoguoweuouoeh/&amp;quot;
# cobbler sync
# service cobbler restart
# service cobblerd restart

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;todo&#34;&gt;Todo&lt;/h3&gt;

&lt;p&gt;How to automatically install the mate desktop via kickstart?&lt;/p&gt;

&lt;p&gt;First find out all of the pkgs in group, then add them into the kickstart file?&lt;/p&gt;

&lt;h3 id=&#34;for-making-mate&#34;&gt;For Making Mate&lt;/h3&gt;

&lt;p&gt;Steps are listed as following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# curl http://mirrors.aliyun.com/repo/epel-7.repo&amp;gt;/etc/yum.repos.d/epel-7.repo
# curl http://mirrors.aliyun.com/repo/Centos-7.repo&amp;gt;CentOS-Base.repo
# yum groupinstall &amp;quot;X Window system&amp;quot;
# yum groupinstall &amp;quot;MATE Desktop&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remain the yum cache:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat /etc/yum.conf 
[main]
#cachedir=/var/cache/yum/$basearch/$releasever
cachedir=/root/cache/$basearch/$releasever
keepcache=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For setting mate as the default desktop envs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# systemctl isolate graphical.target
# systemctl set-default graphical.target
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;repo-in-cobbler&#34;&gt;Repo In Cobbler&lt;/h3&gt;

&lt;p&gt;We could setup the cobbler&amp;rsquo;s repository via following steps:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_05_05_22_48_11_536x324.jpg&#34; alt=&#34;/images/2016_05_05_22_48_11_536x324.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The configuration of this repo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_05_05_22_48_58_718x444.jpg&#34; alt=&#34;/images/2016_05_05_22_48_58_718x444.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now you repo&amp;rsquo;s configuration file should be like following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@cobbler-ubuntu:/var/lib/cobbler/snippets# cat /srv/www/cobbler/repo_mirror/centos7_mate/config.repo 
[centos7_mate]
name=centos7_mate
baseurl=http://${http_server}/cobbler/repo_mirror/centos7_mate
enabled=1
priority=99
gpgcheck=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Copy the rpms into &lt;code&gt;/srv/www/cobbler/repo_mirror/centos7_mate/&lt;/code&gt;, and then &lt;code&gt;createrepo&lt;/code&gt; for generating the package informations.&lt;/p&gt;

&lt;p&gt;Now edit the existing profile&amp;rsquo;s repo configurations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# cobbler profile list
   CentOS-7.2-x86_64
# cobbler profile edit --name=CentOS-7.2-x86_64 --repo=&#39;centos7_mate&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Examine it via:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# cobbler repo report --name=centos7_mate
Name                           : centos7_mate
Apt Components (apt only)      : []
Apt Dist Names (apt only)      : []
Arch                           : x86_64
Breed                          : yum
Comment                        : This Repo is for installing MATE Desktop
Createrepo Flags               : &amp;lt;&amp;lt;inherit&amp;gt;&amp;gt;
Environment Variables          : {}
Keep Updated                   : False
Mirror                         : 
Mirror locally                 : True
Owners                         : [&#39;admin&#39;]
Priority                       : 99
External proxy URL             : 
RPM List                       : []
Yum Options                    : {}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;using-the-repo-in-kickstart&#34;&gt;Using the repo in kickstart&lt;/h3&gt;

&lt;p&gt;First define the snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@cobbler-ubuntu:/var/lib/cobbler/snippets# pwd
/var/lib/cobbler/snippets
root@cobbler-ubuntu:/var/lib/cobbler/snippets# cat mate
# Install mate
mkdir -p /etc/yum.repos.d/back
mv /etc/yum.repos.d/CentOS* /etc/yum.repos.d/back/
yum install -y abattis-cantarell-fonts abrt abrt-addon-ccpp abrt-addon-kerneloops abrt-addon-pstoreoops abrt-addon-python abrt-addon-vmcore abrt-addon-xorg abrt-dbus abrt-desktop abrt-gui abrt-gui-libs abrt-java-connector abrt-libs abrt-python abrt-retrace-client accountsservice adwaita-cursor-theme adwaita-gtk2-theme adwaita-icon-theme alsa-plugins-pulseaudio alsa-utils atk atkmm atril atril-caja atril-libs at-spi2-atk at-spi2-core audit-libs-python augeas-libs avahi-autoipd avahi-glib avahi-libs bind-libs-lite bind-license brasero brasero-libs bzip2 ca-certificates cairo cairo-gobject cairomm caja caja-extensions caja-extensions-common caja-image-converter caja-open-terminal caja-schemas caja-sendto cdparanoia cdparanoia-libs cdrdao centos-indexhtml check checkpolicy cjkuni-uming-fonts clutter clutter-gst2 clutter-gtk cogl colord-libs compat-libcogl12 compat-libcogl-pango12 compat-libcolord1 coreutils cpp crda cronie cronie-anacron cryptsetup cups-libs cyrus-sasl-lib dbus-x11 dconf dconf-editor dejavu-fonts-common dejavu-sans-fonts dejavu-sans-mono-fonts dejavu-serif-fonts desktop-file-utils device-mapper device-mapper-event device-mapper-event-libs device-mapper-libs djvulibre-libs dleyna-connector-dbus dleyna-core dleyna-server dosfstools dracut dracut-config-rescue dracut-network dvd+rw-tools elfutils emacs-filesystem enchant engrampa eom exempi fftw-libs-double filezilla firefox firewall-config flac-libs fontconfig fontpackages-filesystem fortune-mod fros fuse fuse-libs gamin GConf2 gcr gd gdb gdisk gdk-pixbuf2 genisoimage geoclue2 ghostscript ghostscript-fonts giflib glibc glibc-common glibmm24 glx-utils gmp gnome-abrt gnome-desktop3 gnome-icon-theme gnome-icon-theme-extras gnome-icon-theme-legacy gnome-keyring gnome-keyring-pam gnome-online-accounts gnome-python2 gnome-python2-canvas gnome-themes-standard gnote gnu-free-fonts-common gnu-free-mono-fonts gnu-free-sans-fonts gnu-free-serif-fonts gnutls gom google-crosextra-caladea-fonts google-crosextra-carlito-fonts gparted gpm-libs graphite2 grilo grilo-plugins grub2 grub2-tools gsm gssdp gstreamer gstreamer1 gstreamer1-plugins-bad-free gstreamer1-plugins-base gstreamer1-plugins-good gstreamer-plugins-bad-free gstreamer-plugins-base gstreamer-plugins-good gstreamer-tools gtk2 gtk2-engines gtk2-immodule-xim gtk3 gtk3-immodule-xim gtkmm24 gtkmm30 gtk-murrine-engine gtksourceview2 gtkspell3 gucharmap gupnp gupnp-av gupnp-dlna gvfs gvfs-afc gvfs-archive gvfs-fuse gvfs-gphoto2 gvfs-mtp gvfs-smb harfbuzz harfbuzz-icu hicolor-icon-theme hunspell hunspell-en-US ibus ibus-chewing ibus-gtk2 ibus-gtk3 ibus-hangul ibus-kkc ibus-libpinyin ibus-libs ibus-m17n ibus-rawcode ibus-sayura ibus-setup ibus-table ibus-table-chinese icedax ilmbase ImageMagick initscripts iso-codes iw jasper-libs jbigkit-libs jomolhari-fonts json-glib kernel kernel-tools kernel-tools-libs kexec-tools khmeros-base-fonts khmeros-fonts-common kpartx krb5-libs lcms2 libao libarchive libart_lgpl libasyncns libatasmart libavc1394 libblkid libbluray libburn libcanberra libcanberra-gtk2 libcanberra-gtk3 libcdio libcdio-paranoia libcgroup libchewing libdmapsharing libdmx libdnet libdv libdvdnav libdvdread libepoxy liberation-fonts-common liberation-mono-fonts liberation-sans-fonts liberation-serif-fonts libevdev libevent libexif libfontenc libgdata libgee06 libglade2 libgnomecanvas libgnome-keyring libgphoto2 libgpod libgsf libgtop2 libgudev1 libgusb libgxps libhangul libICE libicu libiec61883 libieee1284 libimobiledevice libiptcdata libisofs libjpeg-turbo libkkc libkkc-common libkkc-data libldb libmatekbd libmatemixer libmateweather libmateweather-data libmbim libmediaart libmount libmpc libmpcdec libmspack libmtp libmx libnatpmp libnl libnm-gtk libnotify libntlm liboauth libofa libogg libosinfo libpeas libpinyin libpinyin-data libplist libpng libqmi libraw1394 libreport libreport-centos libreport-filesystem libreport-gtk libreport-plugin-mantisbt libreport-plugin-reportuploader libreport-plugin-rhtsupport libreport-plugin-ureport libreport-python libreport-web librsvg2 libsamplerate libsecret libsemanage-python libsexy libshout libsigc++20 libSM libsmbclient libsndfile libspectre libsrtp libssh2 libtalloc libtar libtdb libteam libtevent libthai libtheora libtiff libtomcrypt libtommath libtool-ltdl libudisks2 libusal libusb libusbx libuser-python libuuid libv4l libvisual libvorbis libvpx libwbclient libwebp libwmf-lite libwnck libwnck3 libwvstreams libX11 libX11-common libXau libxcb libXcomposite libXcursor libXdamage libXdmcp libXevie libXext libXfixes libXfont libXft libXi libXinerama libxkbfile libxklavier libxml2 libxml2-python libXmu libXpm libXrandr libXrender libXres libXScrnSaver libxshmfence libxslt libXt libXtst libXv libXvMC libXxf86dga libXxf86misc libXxf86vm lightdm lightdm-gobject lightdm-gtk lightdm-gtk-common lklug-fonts lockdev logrotate lohit-assamese-fonts lohit-bengali-fonts lohit-devanagari-fonts lohit-gujarati-fonts lohit-kannada-fonts lohit-malayalam-fonts lohit-marathi-fonts lohit-nepali-fonts lohit-oriya-fonts lohit-punjabi-fonts lohit-tamil-fonts lohit-telugu-fonts lrzsz lvm2 lvm2-libs lz4 m17n-contrib m17n-db m17n-lib madan-fonts marco mariadb-libs marisa mate-applets mate-backgrounds mate-calc mate-control-center mate-control-center-filesystem mate-desktop mate-desktop-libs mate-dictionary mate-disk-usage-analyzer mate-icon-theme mate-media mate-menus mate-menus-libs mate-menus-preferences-category-menu mate-netspeed mate-notification-daemon mate-panel mate-panel-libs mate-polkit mate-power-manager mate-screensaver mate-screenshot mate-search-tool mate-session-manager mate-settings-daemon mate-system-log mate-system-monitor mate-terminal mate-themes mate-user-guide mate-utils-common mathjax mathjax-ams-fonts mathjax-caligraphic-fonts mathjax-fraktur-fonts mathjax-main-fonts mathjax-math-fonts mathjax-sansserif-fonts mathjax-script-fonts mathjax-size1-fonts mathjax-size2-fonts mathjax-size3-fonts mathjax-size4-fonts mathjax-typewriter-fonts mathjax-winchrome-fonts mathjax-winie6-fonts mdadm media-player-info mesa-dri-drivers mesa-filesystem mesa-libEGL mesa-libgbm mesa-libGL mesa-libglapi mesa-libGLU mesa-libxatracker mesa-private-llvm mobile-broadband-provider-info ModemManager ModemManager-glib mozilla-filesystem mozo mpfr mtdev net-tools NetworkManager NetworkManager-adsl network-manager-applet NetworkManager-glib NetworkManager-libnm NetworkManager-openconnect NetworkManager-openvpn NetworkManager-pptp NetworkManager-team NetworkManager-tui NetworkManager-vpnc NetworkManager-vpnc-gnome nhn-nanum-fonts-common nhn-nanum-gothic-fonts nm-connection-editor nspr nss nss-softokn nss-softokn-freebl nss-sysinit nss-tools nss-util numactl-libs oddjob oddjob-mkhomedir opencc openconnect OpenEXR-libs openjpeg-libs openldap open-sans-fonts openssh openssh-clients openssh-server openssl openssl-libs open-vm-tools open-vm-tools-desktop openvpn opus orc overpass-fonts PackageKit-glib PackageKit-gstreamer-plugin paktype-naskh-basic-fonts pango pangomm paratype-pt-sans-fonts pcsc-lite-libs perl perl-Carp perl-constant perl-Encode perl-Exporter perl-File-Path perl-File-Temp perl-Filter perl-Getopt-Long perl-HTTP-Tiny perl-libs perl-macros perl-parent perl-PathTools perl-Pod-Escapes perl-podlators perl-Pod-Perldoc perl-Pod-Simple perl-Pod-Usage perl-Scalar-List-Utils perl-Socket perl-Storable perl-Text-ParseWords perl-threads perl-threads-shared perl-Time-HiRes perl-Time-Local pexpect pinentry-gtk pixman pkcs11-helper pluma pluma-data plymouth-graphics-libs plymouth-plugin-label plymouth-plugin-two-step plymouth-system-theme plymouth-theme-charge policycoreutils-python polkit polkit-gnome poppler poppler-data poppler-glib pptp procps-ng psmisc pulseaudio pulseaudio-libs pulseaudio-libs-glib2 pulseaudio-module-x11 pulseaudio-utils pycairo pygobject2 pygobject3 pygtk2 pygtk2-libglade pygtksourceview pyOpenSSL pytalloc python-augeas python-backports python-backports-ssl_match_hostname python-beaker python-chardet python-cups python-dmidecode python-inotify python-IPy python-kitchen python-mako python-markupsafe python-paste python-perf python-pwquality python-pyudev python-setuptools python-six python-tempita pyxdg qemu-guest-agent rarian rarian-compat rdma realmd recode redhat-menus rest rhythmbox rtkit samba-client-libs samba-common samba-common-libs samba-common-tools samba-libs sane-backends-libs satyr SDL seahorse selinux-policy selinux-policy-targeted setools-libs setroubleshoot setroubleshoot-plugins setroubleshoot-server sg3_utils-libs sil-abyssinica-fonts sil-nuosu-fonts sil-padauk-fonts simple-scan skkdic smc-fonts-common smc-meera-fonts sos sound-theme-freedesktop soundtouch speex spice-vdagent startup-notification stix-fonts stoken-libs sudo system-config-date system-config-date-docs system-config-language system-config-printer system-config-printer-libs system-config-users system-config-users-docs systemd systemd-libs systemd-python systemd-sysv taglib teamd telepathy-glib texlive-kpathsea-lib thai-scalable-fonts-common thai-scalable-waree-fonts totem totem-pl-parser tracker transmission-common transmission-gtk tuned tzdata ucs-miscfixed-fonts udisks2 unique upower urw-fonts usb_modeswitch usb_modeswitch-data usbmuxd usermode usermode-gtk util-linux vim-common vim-enhanced vim-filesystem vlgothic-fonts vorbis-tools vpnc vpnc-script vte wavpack web-assets-filesystem webkitgtk webkitgtk3 webrtc-audio-processing wireless-tools wodim wqy-microhei-fonts wqy-zenhei-fonts wvdial wxBase wxGTK xcb-util xchat xdg-user-dirs xdg-user-dirs-gtk xdg-utils xkeyboard-config xml-common xmlrpc-c xmlrpc-c-client xorg-x11-drivers xorg-x11-drv-ati xorg-x11-drv-dummy xorg-x11-drv-evdev xorg-x11-drv-fbdev xorg-x11-drv-intel xorg-x11-drv-nouveau xorg-x11-drv-qxl xorg-x11-drv-synaptics xorg-x11-drv-v4l xorg-x11-drv-vesa xorg-x11-drv-vmmouse xorg-x11-drv-vmware xorg-x11-drv-void xorg-x11-drv-wacom xorg-x11-font-utils xorg-x11-server-common xorg-x11-server-utils xorg-x11-server-Xorg xorg-x11-utils xorg-x11-xauth xorg-x11-xinit xorg-x11-xkb-utils xvattr yelp yelp-libs yelp-xsl yumex zenity
systemctl isolate graphical.target
systemctl set-default graphical.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now involved this snippet in &lt;code&gt;ks_end&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# pwd
/var/lib/cobbler/kickstarts
# vim sample_end.ks
    # Insert a key
    $SNIPPET(&#39;publickey&#39;)
    # Instal mate
    $SNIPPET(&#39;mate&#39;)
    # End final steps
    %end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now run &lt;code&gt;cobbler sync&lt;/code&gt; for syncing your configurations.&lt;/p&gt;

&lt;p&gt;Next time you bootstrap a machine, it will automatically runs into MATE desktop.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_05_05_22_56_57_672x489.jpg&#34; alt=&#34;/images/2016_05_05_22_56_57_672x489.jpg&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TipsOnOSExperiment</title>
      <link>http://purplepalmdash.github.io/2016/04/24/tipsonosexperiment/</link>
      <pubDate>Sun, 24 Apr 2016 17:32:12 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/04/24/tipsonosexperiment/</guid>
      <description>

&lt;p&gt;为了在家里验证一下DevStack的网络配置，组建了一个网络，涉及到的点比较多，以下是
具体记录。&lt;/p&gt;

&lt;h3 id=&#34;交换机配置&#34;&gt;交换机配置&lt;/h3&gt;

&lt;p&gt;前段时间从美国亚马逊买回来一个TP-LINK的千兆交换机一直没用起来，型号是TL-SG108E
，8口可网管交换机。但前面有写过文章可以用来参考:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://purplepalmdash.github.io/blog/2015/12/12/ba-wan-tl-sg108e/&#34;&gt;http://purplepalmdash.github.io/blog/2015/12/12/ba-wan-tl-sg108e/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;但这篇文章里讲的主要还是ovs后虚拟机的vlan，和最近要做的DevStack的FloatIP配置稍
微有点差异。&lt;/p&gt;

&lt;h3 id=&#34;网络规划&#34;&gt;网络规划&lt;/h3&gt;

&lt;p&gt;家里已有网络192.168.177.0/24, 这个网络是可以访问Internet的。所以DevStack机器上
的eth0将连接到这个网段，并在其上分配floating IP.&lt;/p&gt;

&lt;p&gt;另外我们需要创建一个VLAN隔离的private network，用于给DevStack里的虚拟机默认启
动后分配IP地址。将DevStack机器上的eth1连接到此网络。&lt;/p&gt;

&lt;h3 id=&#34;配置交换机&#34;&gt;配置交换机&lt;/h3&gt;

&lt;p&gt;TP-LINK的DEB-100网卡是比较皮实，奈何win10驱动需要找，随便找了个淘宝9.9包邮的
USB转10兆网卡连上SurfacePro，开始配置交换机。&lt;/p&gt;

&lt;p&gt;步骤:&lt;br /&gt;
打开桌面的&lt;code&gt;Easy Smart Configuration Utility&lt;/code&gt;，开始自动发现局域网内的交换机，如
下图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_04_24_17_58_49.jpg&#34; alt=&#34;/images/2016_04_24_17_58_49.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;需要重新配置下USB有线网卡的IP地址才能连接上交换机:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_04_24_18_02_45.jpg&#34; alt=&#34;/images/2016_04_24_18_02_45.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;双击发现的交换机，用&lt;code&gt;admin/admin&lt;/code&gt;登录后的界面如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/iamges/2016_04_24_18_08_04.jpg&#34; alt=&#34;/images/2016_04_24_18_08_04.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以前我曾经把这个交换机配置成802.1Q VLAN, 这次基于端口来隔离，所以要配置成&lt;code&gt;Port
Based VLAN&lt;/code&gt;, 配置完毕后的画面如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_04_24_18_20_36.jpg&#34; alt=&#34;/images/2016_04_24_18_20_36.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这种基于端口VLAN的验证方法很简单，将上网机和宽带路由器分别插在1～4和5～8口，即
可测试出VLAN被端口隔离。但这好像不是DevStack中需要设置的。&lt;/p&gt;

&lt;p&gt;还是继续配置802.1Q VLAN. 值得注意的是，如果之前配置端口VLAN时将SurfacePro的连
接和交换机网段隔离了，那可能会连接不上，换回同一VLAN即可连接上。&lt;/p&gt;

&lt;p&gt;配置vlan100如以下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://purplepalmdash.github.io/images/2016_04_24_19_51_15.jpg&#34; alt=&#34;/images/2016_04_24_19_51_15.jpg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;测试vlan&#34;&gt;测试VLAN&lt;/h3&gt;

&lt;p&gt;将两台PC连接在5~8口上，VLAN100。&lt;/p&gt;

&lt;p&gt;PC1, ArchLinux, Systemd配置VLAN:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat enp0s25.100.network
[Match]
Name=enp0s25.100

[Network]
DNS=192.168.2.1
Address=192.168.2.1/24
$ cat enp0s25.100.netdev 
[NetDev]
Name=enp0s25.100
Kind=vlan

[VLAN]
Id=100

[Network]
DNS=192.168.2.1
Address=192.168.2.1/24
Gateway=192.168.2.1
$ pwd
/etc/systemd/network
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新启动PC1后，&lt;code&gt;192.168.2.1&lt;/code&gt;将成为VLAN100口的地址。作为&lt;code&gt;192.168.2.1&lt;/code&gt;,我们在这
个端口上启动dhcp服务及路由转发等服务。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo pacman -S dhcp
$ sudo systemctl enable dhcpd4.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;干掉冗余的默认dhcpd.conf文件，写一个最小的配置文件:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vim /etc/dhcpd.conf.example 
$ sudo vim /etc/dhcpd.conf         
option domain-name-servers 180.76.76.76,223.5.5.5;
option subnet-mask 255.255.255.0;
option routers 192.168.2.1;
subnet 192.168.2.0 netmask 255.255.255.0 {
  range 192.168.2.150 192.168.2.250;

  host macbookpro{
   hardware ethernet 70:56:81:22:33:44;
   fixed-address 192.168.2.199;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;开启dhcpd服务:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo systemctl start dhcpd4.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PC2, 用openvswitch的vlan配置, libvirt的XML配置如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;interface type=&#39;bridge&#39;&amp;gt;
      &amp;lt;mac address=&#39;52:54:00:fd:03:e9&#39;/&amp;gt;
      &amp;lt;source bridge=&#39;ovsbr0&#39;/&amp;gt;
      &amp;lt;vlan trunk=&#39;yes&#39;&amp;gt;
        &amp;lt;tag id=&#39;100&#39; nativeMode=&#39;untagged&#39;/&amp;gt;
      &amp;lt;/vlan&amp;gt;
      &amp;lt;virtualport type=&#39;openvswitch&#39;&amp;gt;
        &amp;lt;parameters interfaceid=&#39;fb3e7f34-6fcd-41dc-8fed-c3ffe0d54b18&#39;/&amp;gt;
      &amp;lt;/virtualport&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;测试，即启动PC2上的虚拟机，若虚拟机能获得IP地址，则说明VLAN配置成功。&lt;/p&gt;

&lt;h3 id=&#34;devstack网络配置&#34;&gt;DevStack网络配置&lt;/h3&gt;

&lt;p&gt;操作系统为Ubuntu14.04, 网卡为eth0(192.168.177.100)和eth1(vlan 100)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在DevStack中使用Packer</title>
      <link>http://purplepalmdash.github.io/2016/04/24/zai-devstackzhong-shi-yong-packer/</link>
      <pubDate>Sun, 24 Apr 2016 10:16:39 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/04/24/zai-devstackzhong-shi-yong-packer/</guid>
      <description>

&lt;h3 id=&#34;导入源镜像&#34;&gt;导入源镜像&lt;/h3&gt;

&lt;p&gt;源镜像可以从ubuntu.com下载到，并使用以下命令导入:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://cloud-images.ubuntu.com/trusty/current/trusty-server-cloudimg-amd64-disk1.img
$ glance image-create --name ubuntu-trusty --disk-format qcow2 \
--container-format bare --file trusty-server-cloudimg-amd64-disk1.img
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;openstack-json文件&#34;&gt;openstack.json文件&lt;/h3&gt;

&lt;p&gt;github上有现成的，克隆到本地:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/Thingee/packer-devstack.git
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>rsync the vault.centos.com</title>
      <link>http://purplepalmdash.github.io/2016/04/22/rsync-the-vault-dot-centos-dot-com/</link>
      <pubDate>Fri, 22 Apr 2016 19:39:58 +0000</pubDate>
      
      <guid>http://purplepalmdash.github.io/2016/04/22/rsync-the-vault-dot-centos-dot-com/</guid>
      <description>

&lt;p&gt;For I want to do some configuration workings on old distribution of CentOS, I have to
use lots of materials which from vault.centos.com, following are the steps for syncing
them.&lt;/p&gt;

&lt;p&gt;First, rsync in &lt;code&gt;vault.centos.com&lt;/code&gt; is closed, thus we have to choose
&lt;code&gt;http://archive.kernel.org/centos/&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;rsync-scripts&#34;&gt;Rsync Scripts&lt;/h3&gt;

&lt;p&gt;Refers to:&lt;br /&gt;
&lt;a href=&#34;https://www.totalnetsolutions.net/2013/10/02/setting-up-a-corporate-yum-repository-mirror-for-bandwidth-and-staged-update-management/&#34;&gt;https://www.totalnetsolutions.net/2013/10/02/setting-up-a-corporate-yum-repository-mirror-for-bandwidth-and-staged-update-management/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;make-repository&#34;&gt;Make Repository&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.centos.org/HowTos/CreateLocalMirror&#34;&gt;https://wiki.centos.org/HowTos/CreateLocalMirror&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>